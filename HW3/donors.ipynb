{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Chi Nguyen\n",
    "\n",
    "\n",
    "Machine Learning for Public Policy\n",
    "\n",
    "\n",
    "HW3 - Applying a machine learning pipeline to the donors dataset\n",
    "\n",
    "\n",
    "Pipeline codes are in the files preprocess.py and build_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocess\n",
    "import build_models\n",
    "import mlhelperfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, process and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_district</th>\n",
       "      <th>...</th>\n",
       "      <th>secondary_focus_subject</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>datefullyfunded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ccc0e81598c4bd86bacb94d7acb</td>\n",
       "      <td>96963218e74e10c3764a5cfb153e6fea</td>\n",
       "      <td>9f3f9f2c2da7edda5648ccd10554ed8c</td>\n",
       "      <td>1.709930e+11</td>\n",
       "      <td>41.807654</td>\n",
       "      <td>-87.673257</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Pershing Elem Network</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4/14/13</td>\n",
       "      <td>5/2/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000fa3aa8f6649abab23615b546016d</td>\n",
       "      <td>2a578595fe351e7fce057e048c409b18</td>\n",
       "      <td>3432ed3d4466fac2f2ead83ab354e333</td>\n",
       "      <td>6.409801e+10</td>\n",
       "      <td>34.296596</td>\n",
       "      <td>-119.296596</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Ventura Unif School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "      <td>4/7/12</td>\n",
       "      <td>4/18/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000134f07d4b30140d63262c871748ff</td>\n",
       "      <td>26bd60377bdbffb53a644a16c5308e82</td>\n",
       "      <td>dc8dcb501c3b2bb0b10e9c6ee2cd8afd</td>\n",
       "      <td>6.227100e+10</td>\n",
       "      <td>34.078625</td>\n",
       "      <td>-118.257834</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/30/12</td>\n",
       "      <td>4/15/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001f2d0b3827bba67cdbeaa248b832d</td>\n",
       "      <td>15d900805d9d716c051c671827109f45</td>\n",
       "      <td>8bea7e8c6e4279fca6276128db89292e</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.687286</td>\n",
       "      <td>-73.988217</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/11/12</td>\n",
       "      <td>12/5/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004536db996ba697ca72c9e058bfe69</td>\n",
       "      <td>400f8b82bb0143f6a40b217a517fe311</td>\n",
       "      <td>fbdefab6fe41e12c55886c610c110753</td>\n",
       "      <td>3.606870e+11</td>\n",
       "      <td>40.793018</td>\n",
       "      <td>-73.205635</td>\n",
       "      <td>Central Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Central Islip Union Free SD</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/8/13</td>\n",
       "      <td>3/25/13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid                    teacher_acctid  \\\n",
       "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
       "1  0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
       "2  000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
       "3  0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
       "4  0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
       "\n",
       "                           schoolid  school_ncesid  school_latitude  \\\n",
       "0  9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
       "1  3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
       "2  dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
       "3  8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
       "4  fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
       "\n",
       "   school_longitude    school_city school_state school_metro  \\\n",
       "0        -87.673257        Chicago           IL        urban   \n",
       "1       -119.296596        Ventura           CA        urban   \n",
       "2       -118.257834    Los Angeles           CA        urban   \n",
       "3        -73.988217       Brooklyn           NY        urban   \n",
       "4        -73.205635  Central Islip           NY     suburban   \n",
       "\n",
       "                school_district  ... secondary_focus_subject  \\\n",
       "0         Pershing Elem Network  ...             Visual Arts   \n",
       "1  Ventura Unif School District  ...    Literature & Writing   \n",
       "2     Los Angeles Unif Sch Dist  ...         Social Sciences   \n",
       "3      New York City Dept Of Ed  ...                     NaN   \n",
       "4   Central Islip Union Free SD  ...    Literature & Writing   \n",
       "\n",
       "  secondary_focus_area resource_type    poverty_level    grade_level  \\\n",
       "0     Music & The Arts      Supplies  highest poverty  Grades PreK-2   \n",
       "1  Literacy & Language         Books  highest poverty     Grades 3-5   \n",
       "2     History & Civics    Technology     high poverty     Grades 3-5   \n",
       "3                  NaN         Books     high poverty  Grades PreK-2   \n",
       "4  Literacy & Language    Technology     high poverty  Grades PreK-2   \n",
       "\n",
       "  total_price_including_optional_support students_reached  \\\n",
       "0                                1498.61             31.0   \n",
       "1                                 282.47             28.0   \n",
       "2                                1012.38             56.0   \n",
       "3                                 175.33             23.0   \n",
       "4                                3591.11            150.0   \n",
       "\n",
       "  eligible_double_your_impact_match date_posted datefullyfunded  \n",
       "0                                 f     4/14/13          5/2/13  \n",
       "1                                 t      4/7/12         4/18/12  \n",
       "2                                 f     1/30/12         4/15/12  \n",
       "3                                 f    10/11/12         12/5/12  \n",
       "4                                 f      1/8/13         3/25/13  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors = preprocess.import_csv(\"projects_2012_2013.csv\")\n",
    "donors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's take a look at the first 10 lines of the dataframe!\n",
      "\n",
      "                          projectid                    teacher_acctid  \\\n",
      "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
      "1  0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
      "2  000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
      "3  0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
      "4  0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
      "5  00049ec8ca1f2d08cb13cab31b0b85ec  7149611553c700de9a6099f8a9ce598b   \n",
      "6  0004d2fdbb571237fa53a97e7691440b  926671e209fb977bd5123145c1848ad1   \n",
      "7  0004ee26667e751dd51384eb9f30c72e  abe4dabb7864f4c548d230cf9070e03f   \n",
      "8  0006a31d45f8d52d217e7c5b55c11f37  3b5fada1ad0e339acc669829071320c4   \n",
      "9  0008ac907bf237a15a959244205d3ee5  92527a5ac5fe946ed1961fb2e1de8cc5   \n",
      "\n",
      "                           schoolid  school_ncesid  school_latitude  \\\n",
      "0  9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
      "1  3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
      "2  dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
      "3  8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
      "4  fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
      "5  462a5fd93cf9fb5d41eecfd2ea860b19   2.621150e+11        42.740157   \n",
      "6  1a994778027ab086dc58ec3b47f74ff0   4.047200e+10        33.059361   \n",
      "7  8409f70bcd81bc06e4b9efca68eed8f6   6.280501e+10        37.761958   \n",
      "8  c6a033f9349ea70659c1891b119680ed   2.307320e+11        44.096641   \n",
      "9  23e34f5d2e2940684269cffe35741598   6.271800e+10        34.381832   \n",
      "\n",
      "   school_longitude    school_city school_state school_metro  \\\n",
      "0        -87.673257        Chicago           IL        urban   \n",
      "1       -119.296596        Ventura           CA        urban   \n",
      "2       -118.257834    Los Angeles           CA        urban   \n",
      "3        -73.988217       Brooklyn           NY        urban   \n",
      "4        -73.205635  Central Islip           NY     suburban   \n",
      "5        -84.525821        Lansing           MI        urban   \n",
      "6       -112.037727       Maricopa           AZ        rural   \n",
      "7       -122.193209        Oakland           CA        urban   \n",
      "8        -70.191734       Lewiston           ME        urban   \n",
      "9       -118.531837        Newhall           CA     suburban   \n",
      "\n",
      "                 school_district  ... secondary_focus_subject  \\\n",
      "0          Pershing Elem Network  ...             Visual Arts   \n",
      "1   Ventura Unif School District  ...    Literature & Writing   \n",
      "2      Los Angeles Unif Sch Dist  ...         Social Sciences   \n",
      "3       New York City Dept Of Ed  ...                     NaN   \n",
      "4    Central Islip Union Free SD  ...    Literature & Writing   \n",
      "5        Lansing School District  ...                     NaN   \n",
      "6  Maricopa Unif Sch District 20  ...                     NaN   \n",
      "7    Oakland Unified School Dist  ...                     NaN   \n",
      "8        Lewiston Public Schools  ...                     NaN   \n",
      "9        Newhall School District  ...                Literacy   \n",
      "\n",
      "  secondary_focus_area resource_type    poverty_level    grade_level  \\\n",
      "0     Music & The Arts      Supplies  highest poverty  Grades PreK-2   \n",
      "1  Literacy & Language         Books  highest poverty     Grades 3-5   \n",
      "2     History & Civics    Technology     high poverty     Grades 3-5   \n",
      "3                  NaN         Books     high poverty  Grades PreK-2   \n",
      "4  Literacy & Language    Technology     high poverty  Grades PreK-2   \n",
      "5                  NaN         Other  highest poverty     Grades 3-5   \n",
      "6                  NaN      Supplies     high poverty     Grades 3-5   \n",
      "7                  NaN         Books  highest poverty    Grades 9-12   \n",
      "8                  NaN    Technology     high poverty     Grades 3-5   \n",
      "9  Literacy & Language    Technology  highest poverty  Grades PreK-2   \n",
      "\n",
      "  total_price_including_optional_support students_reached  \\\n",
      "0                                1498.61             31.0   \n",
      "1                                 282.47             28.0   \n",
      "2                                1012.38             56.0   \n",
      "3                                 175.33             23.0   \n",
      "4                                3591.11            150.0   \n",
      "5                                 475.85             15.0   \n",
      "6                                 390.65             37.0   \n",
      "7                                3877.20             30.0   \n",
      "8                                 838.75             25.0   \n",
      "9                                1477.44             24.0   \n",
      "\n",
      "  eligible_double_your_impact_match date_posted datefullyfunded  \n",
      "0                                 f     4/14/13          5/2/13  \n",
      "1                                 t      4/7/12         4/18/12  \n",
      "2                                 f     1/30/12         4/15/12  \n",
      "3                                 f    10/11/12         12/5/12  \n",
      "4                                 f      1/8/13         3/25/13  \n",
      "5                                 f    11/30/12         2/26/13  \n",
      "6                                 f     3/26/13         4/17/13  \n",
      "7                                 f     2/28/13         3/10/13  \n",
      "8                                 f     8/21/13         9/13/13  \n",
      "9                                 f     10/3/12         11/3/12  \n",
      "\n",
      "[10 rows x 26 columns]\n",
      "\n",
      "\n",
      "\n",
      "Dataframe's shape: (124976, 26)\n",
      "\n",
      "\n",
      "\n",
      "Data types:\n",
      "\n",
      "projectid                                  object\n",
      "teacher_acctid                             object\n",
      "schoolid                                   object\n",
      "school_ncesid                             float64\n",
      "school_latitude                           float64\n",
      "school_longitude                          float64\n",
      "school_city                                object\n",
      "school_state                               object\n",
      "school_metro                               object\n",
      "school_district                            object\n",
      "school_county                              object\n",
      "school_charter                             object\n",
      "school_magnet                              object\n",
      "teacher_prefix                             object\n",
      "primary_focus_subject                      object\n",
      "primary_focus_area                         object\n",
      "secondary_focus_subject                    object\n",
      "secondary_focus_area                       object\n",
      "resource_type                              object\n",
      "poverty_level                              object\n",
      "grade_level                                object\n",
      "total_price_including_optional_support    float64\n",
      "students_reached                          float64\n",
      "eligible_double_your_impact_match          object\n",
      "date_posted                                object\n",
      "datefullyfunded                            object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Distribution of the variables in the dataframe:\n",
      "\n",
      "       school_ncesid  school_latitude  school_longitude  \\\n",
      "count   1.157430e+05    124976.000000     124976.000000   \n",
      "mean    2.448448e+11        36.827284        -95.859299   \n",
      "std     1.644728e+11         4.963669         18.392876   \n",
      "min     1.000050e+10        18.249140       -171.690554   \n",
      "25%     6.344101e+10        33.872504       -117.806418   \n",
      "50%     2.200870e+11        36.617410        -90.101563   \n",
      "75%     3.704880e+11        40.676156        -80.713740   \n",
      "max     6.100010e+11        65.672562        -66.628036   \n",
      "\n",
      "       total_price_including_optional_support  students_reached  \n",
      "count                           124976.000000     124917.000000  \n",
      "mean                               654.011811         95.445760  \n",
      "std                               1098.015854        163.481912  \n",
      "min                                 92.000000          1.000000  \n",
      "25%                                345.810000         23.000000  \n",
      "50%                                510.500000         30.000000  \n",
      "75%                                752.960000        100.000000  \n",
      "max                             164382.840000      12143.000000  \n"
     ]
    }
   ],
   "source": [
    "preprocess.explore_data(donors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brief overview of the number of missingobservations for each column:\n",
      "\n",
      "secondary_focus_area                      40556\n",
      "secondary_focus_subject                   40556\n",
      "school_metro                              15224\n",
      "school_ncesid                              9233\n",
      "school_district                             172\n",
      "students_reached                             59\n",
      "resource_type                                17\n",
      "primary_focus_area                           15\n",
      "primary_focus_subject                        15\n",
      "grade_level                                   3\n",
      "schoolid                                      0\n",
      "teacher_acctid                                0\n",
      "school_latitude                               0\n",
      "school_longitude                              0\n",
      "school_city                                   0\n",
      "school_state                                  0\n",
      "datefullyfunded                               0\n",
      "school_magnet                                 0\n",
      "school_county                                 0\n",
      "school_charter                                0\n",
      "date_posted                                   0\n",
      "teacher_prefix                                0\n",
      "poverty_level                                 0\n",
      "total_price_including_optional_support        0\n",
      "eligible_double_your_impact_match             0\n",
      "projectid                                     0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "List of columns that contain missing data:\n",
      "\n",
      "['school_ncesid', 'school_metro', 'school_district', 'primary_focus_subject', 'primary_focus_area', 'secondary_focus_subject', 'secondary_focus_area', 'resource_type', 'grade_level', 'students_reached']\n",
      "\n",
      "\n",
      "\n",
      "Can't fill missing values for non-numeric column school_metro\n",
      "Can't fill missing values for non-numeric column school_district\n",
      "Can't fill missing values for non-numeric column primary_focus_subject\n",
      "Can't fill missing values for non-numeric column primary_focus_area\n",
      "Can't fill missing values for non-numeric column secondary_focus_subject\n",
      "Can't fill missing values for non-numeric column secondary_focus_area\n",
      "Can't fill missing values for non-numeric column resource_type\n",
      "Can't fill missing values for non-numeric column grade_level\n",
      "Brief overview of the data distribution after pre-processing:\n",
      "\n",
      "       school_ncesid  school_latitude  school_longitude  \\\n",
      "count   1.249760e+05    124976.000000     124976.000000   \n",
      "mean    2.430157e+11        36.827284        -95.859299   \n",
      "std     1.584131e+11         4.963669         18.392876   \n",
      "min     1.000050e+10        18.249140       -171.690554   \n",
      "25%     6.401501e+10        33.872504       -117.806418   \n",
      "50%     2.200870e+11        36.617410        -90.101563   \n",
      "75%     3.702970e+11        40.676156        -80.713740   \n",
      "max     6.100010e+11        65.672562        -66.628036   \n",
      "\n",
      "       total_price_including_optional_support  students_reached  \n",
      "count                           124976.000000     124976.000000  \n",
      "mean                               654.011811         95.414864  \n",
      "std                               1098.015854        163.449500  \n",
      "min                                 92.000000          1.000000  \n",
      "25%                                345.810000         23.000000  \n",
      "50%                                510.500000         30.000000  \n",
      "75%                                752.960000        100.000000  \n",
      "max                             164382.840000      12143.000000  \n"
     ]
    }
   ],
   "source": [
    "preprocess.pre_process(donors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess.create_hist(donors, 'students_reached', 'Students Reached', \n",
    "                       'frequency', \"Histogram of number of students reached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess.create_hist(donors, 'total_price_including_optional_support', 'Total Price', \n",
    "                       'frequency', \"Histogram of total price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess.create_boxplot(donors, 'students_reached', 'resource_type', \n",
    "                          'Number of students reached', 'Resource type',\n",
    "                          'Boxplot of number of students reached by resource type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_district</th>\n",
       "      <th>...</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>datefullyfunded</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ccc0e81598c4bd86bacb94d7acb</td>\n",
       "      <td>96963218e74e10c3764a5cfb153e6fea</td>\n",
       "      <td>9f3f9f2c2da7edda5648ccd10554ed8c</td>\n",
       "      <td>1.709930e+11</td>\n",
       "      <td>41.807654</td>\n",
       "      <td>-87.673257</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Pershing Elem Network</td>\n",
       "      <td>...</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4/14/13</td>\n",
       "      <td>5/2/13</td>\n",
       "      <td>POINT (-87.67325699999999 41.807654)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000fa3aa8f6649abab23615b546016d</td>\n",
       "      <td>2a578595fe351e7fce057e048c409b18</td>\n",
       "      <td>3432ed3d4466fac2f2ead83ab354e333</td>\n",
       "      <td>6.409801e+10</td>\n",
       "      <td>34.296596</td>\n",
       "      <td>-119.296596</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Ventura Unif School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "      <td>4/7/12</td>\n",
       "      <td>4/18/12</td>\n",
       "      <td>POINT (-119.296596 34.296596)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000134f07d4b30140d63262c871748ff</td>\n",
       "      <td>26bd60377bdbffb53a644a16c5308e82</td>\n",
       "      <td>dc8dcb501c3b2bb0b10e9c6ee2cd8afd</td>\n",
       "      <td>6.227100e+10</td>\n",
       "      <td>34.078625</td>\n",
       "      <td>-118.257834</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/30/12</td>\n",
       "      <td>4/15/12</td>\n",
       "      <td>POINT (-118.257834 34.078625)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001f2d0b3827bba67cdbeaa248b832d</td>\n",
       "      <td>15d900805d9d716c051c671827109f45</td>\n",
       "      <td>8bea7e8c6e4279fca6276128db89292e</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.687286</td>\n",
       "      <td>-73.988217</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/11/12</td>\n",
       "      <td>12/5/12</td>\n",
       "      <td>POINT (-73.98821700000001 40.687286)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004536db996ba697ca72c9e058bfe69</td>\n",
       "      <td>400f8b82bb0143f6a40b217a517fe311</td>\n",
       "      <td>fbdefab6fe41e12c55886c610c110753</td>\n",
       "      <td>3.606870e+11</td>\n",
       "      <td>40.793018</td>\n",
       "      <td>-73.205635</td>\n",
       "      <td>Central Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Central Islip Union Free SD</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/8/13</td>\n",
       "      <td>3/25/13</td>\n",
       "      <td>POINT (-73.205635 40.793018)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid                    teacher_acctid  \\\n",
       "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
       "1  0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
       "2  000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
       "3  0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
       "4  0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
       "\n",
       "                           schoolid  school_ncesid  school_latitude  \\\n",
       "0  9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
       "1  3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
       "2  dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
       "3  8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
       "4  fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
       "\n",
       "   school_longitude    school_city school_state school_metro  \\\n",
       "0        -87.673257        Chicago           IL        urban   \n",
       "1       -119.296596        Ventura           CA        urban   \n",
       "2       -118.257834    Los Angeles           CA        urban   \n",
       "3        -73.988217       Brooklyn           NY        urban   \n",
       "4        -73.205635  Central Islip           NY     suburban   \n",
       "\n",
       "                school_district  ... secondary_focus_area resource_type  \\\n",
       "0         Pershing Elem Network  ...     Music & The Arts      Supplies   \n",
       "1  Ventura Unif School District  ...  Literacy & Language         Books   \n",
       "2     Los Angeles Unif Sch Dist  ...     History & Civics    Technology   \n",
       "3      New York City Dept Of Ed  ...                  NaN         Books   \n",
       "4   Central Islip Union Free SD  ...  Literacy & Language    Technology   \n",
       "\n",
       "     poverty_level    grade_level total_price_including_optional_support  \\\n",
       "0  highest poverty  Grades PreK-2                                1498.61   \n",
       "1  highest poverty     Grades 3-5                                 282.47   \n",
       "2     high poverty     Grades 3-5                                1012.38   \n",
       "3     high poverty  Grades PreK-2                                 175.33   \n",
       "4     high poverty  Grades PreK-2                                3591.11   \n",
       "\n",
       "  students_reached eligible_double_your_impact_match date_posted  \\\n",
       "0             31.0                                 f     4/14/13   \n",
       "1             28.0                                 t      4/7/12   \n",
       "2             56.0                                 f     1/30/12   \n",
       "3             23.0                                 f    10/11/12   \n",
       "4            150.0                                 f      1/8/13   \n",
       "\n",
       "  datefullyfunded                              geometry  \n",
       "0          5/2/13  POINT (-87.67325699999999 41.807654)  \n",
       "1         4/18/12         POINT (-119.296596 34.296596)  \n",
       "2         4/15/12         POINT (-118.257834 34.078625)  \n",
       "3         12/5/12  POINT (-73.98821700000001 40.687286)  \n",
       "4         3/25/13          POINT (-73.205635 40.793018)  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry = [Point(xy) for xy in zip(donors['school_longitude'], donors['school_latitude'])]\n",
    "crs = {'init': 'epsg:4326'}\n",
    "geo_df = gpd.GeoDataFrame(donors, crs=crs, geometry = geometry)\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1766413409817781"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors['students_reached'].corr(donors['total_price_including_optional_support'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectid                                         object\n",
       "teacher_acctid                                    object\n",
       "schoolid                                          object\n",
       "school_ncesid                                    float64\n",
       "school_latitude                                  float64\n",
       "school_longitude                                 float64\n",
       "school_city                                       object\n",
       "school_state                                      object\n",
       "school_metro                                      object\n",
       "school_district                                   object\n",
       "school_county                                     object\n",
       "school_charter                                    object\n",
       "school_magnet                                     object\n",
       "teacher_prefix                                    object\n",
       "primary_focus_subject                             object\n",
       "primary_focus_area                                object\n",
       "secondary_focus_subject                           object\n",
       "secondary_focus_area                              object\n",
       "resource_type                                     object\n",
       "poverty_level                                     object\n",
       "grade_level                                       object\n",
       "total_price_including_optional_support           float64\n",
       "students_reached                                 float64\n",
       "eligible_double_your_impact_match                 object\n",
       "date_posted                               datetime64[ns]\n",
       "datefullyfunded                           datetime64[ns]\n",
       "geometry                                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_transform_to_datetime = ['date_posted', 'datefullyfunded']\n",
    "preprocess.convert_to_datetime(donors, cols_to_transform_to_datetime)\n",
    "donors.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.convert_to_categorical_using_qcut(donors, 'students_reached',\n",
    "                                             'students_reached_group', 3, \n",
    "                                             ['low', 'medium', 'high'])\n",
    "preprocess.convert_to_categorical_using_qcut(donors, 'total_price_including_optional_support',\n",
    "                                             'price_group', 3, \n",
    "                                             ['low', 'medium', 'high'])\n",
    "cols_to_transform_to_binary = ['school_state', 'school_metro',\n",
    "                               'school_charter', 'school_magnet',\n",
    "                               'primary_focus_subject', 'resource_type',\n",
    "                               'poverty_level', 'grade_level', 'students_reached_group', 'price_group']\n",
    "donors = preprocess.convert_to_binary(donors, cols_to_transform_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors['time_to_fund'] = donors['datefullyfunded'] - donors['date_posted']\n",
    "donors['fund_within_60'] = np.where(donors['time_to_fund'] <= pd.to_timedelta(60, unit='D'), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school_metro_suburban',\n",
       " 'school_metro_urban',\n",
       " 'school_metro_nan',\n",
       " 'school_charter_f',\n",
       " 'school_charter_t',\n",
       " 'school_charter_nan',\n",
       " 'school_magnet_f',\n",
       " 'school_magnet_t',\n",
       " 'school_magnet_nan',\n",
       " 'primary_focus_subject_Applied Sciences',\n",
       " 'primary_focus_subject_Character Education',\n",
       " 'primary_focus_subject_Civics & Government',\n",
       " 'primary_focus_subject_College & Career Prep',\n",
       " 'primary_focus_subject_Community Service',\n",
       " 'primary_focus_subject_ESL',\n",
       " 'primary_focus_subject_Early Development',\n",
       " 'primary_focus_subject_Economics',\n",
       " 'primary_focus_subject_Environmental Science',\n",
       " 'primary_focus_subject_Extracurricular',\n",
       " 'primary_focus_subject_Foreign Languages',\n",
       " 'primary_focus_subject_Gym & Fitness',\n",
       " 'primary_focus_subject_Health & Life Science',\n",
       " 'primary_focus_subject_Health & Wellness',\n",
       " 'primary_focus_subject_History & Geography',\n",
       " 'primary_focus_subject_Literacy',\n",
       " 'primary_focus_subject_Literature & Writing',\n",
       " 'primary_focus_subject_Mathematics',\n",
       " 'primary_focus_subject_Music',\n",
       " 'primary_focus_subject_Nutrition',\n",
       " 'primary_focus_subject_Other',\n",
       " 'primary_focus_subject_Parent Involvement',\n",
       " 'primary_focus_subject_Performing Arts',\n",
       " 'primary_focus_subject_Social Sciences',\n",
       " 'primary_focus_subject_Special Needs',\n",
       " 'primary_focus_subject_Sports',\n",
       " 'primary_focus_subject_Visual Arts',\n",
       " 'primary_focus_subject_nan',\n",
       " 'resource_type_Books',\n",
       " 'resource_type_Other',\n",
       " 'resource_type_Supplies',\n",
       " 'resource_type_Technology',\n",
       " 'resource_type_Trips',\n",
       " 'resource_type_Visitors',\n",
       " 'resource_type_nan',\n",
       " 'poverty_level_high poverty',\n",
       " 'poverty_level_highest poverty',\n",
       " 'poverty_level_low poverty',\n",
       " 'poverty_level_moderate poverty',\n",
       " 'poverty_level_nan',\n",
       " 'grade_level_Grades 3-5',\n",
       " 'grade_level_Grades 6-8',\n",
       " 'grade_level_Grades 9-12',\n",
       " 'grade_level_Grades PreK-2',\n",
       " 'grade_level_nan',\n",
       " 'students_reached_group_low',\n",
       " 'students_reached_group_medium',\n",
       " 'students_reached_group_high',\n",
       " 'students_reached_group_nan',\n",
       " 'price_group_low',\n",
       " 'price_group_medium',\n",
       " 'price_group_high',\n",
       " 'price_group_nan']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = donors.columns.tolist()\n",
    "selected_features = l[72:134]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models and create a dataframe to store evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 'mini'\n",
    "clfs, grid = mlhelperfunctions.define_clfs_params(grid_size)\n",
    "models_to_run = ['RF', 'AB', 'LR', 'DT', 'GB', 'SVM', 'KNN']\n",
    "clean_df = donors\n",
    "predictors = selected_features\n",
    "outcome = 'fund_within_60'\n",
    "date_col = 'date_posted'\n",
    "prediction_windows = [6]\n",
    "start_time = '2012-01-01'\n",
    "end_time = '2013-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "Added row 1\n",
      "Added row 2\n",
      "Added row 3\n",
      "Added row 4\n",
      "Added row 5\n",
      "Added row 6\n",
      "Added row 7\n",
      "Added row 8\n",
      "AB\n",
      "Added row 9\n",
      "Added row 10\n",
      "Added row 11\n",
      "Added row 12\n",
      "Added row 13\n",
      "Added row 14\n",
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 22\n",
      "DT\n",
      "Added row 23\n",
      "Added row 24\n",
      "Added row 25\n",
      "Added row 26\n",
      "Added row 27\n",
      "Added row 28\n",
      "Added row 29\n",
      "Added row 30\n",
      "Added row 31\n",
      "Added row 32\n",
      "Added row 33\n",
      "Added row 34\n",
      "Added row 35\n",
      "Added row 36\n",
      "Added row 37\n",
      "Added row 38\n",
      "Added row 39\n",
      "Added row 40\n",
      "Added row 41\n",
      "Added row 42\n",
      "Added row 43\n",
      "Added row 44\n",
      "Added row 45\n",
      "Added row 46\n",
      "Added row 47\n",
      "Added row 48\n",
      "Added row 49\n",
      "Added row 50\n",
      "Added row 51\n",
      "Added row 52\n",
      "Added row 53\n",
      "Added row 54\n",
      "Added row 55\n",
      "Added row 56\n",
      "Added row 57\n",
      "Added row 58\n",
      "Added row 59\n",
      "Added row 60\n",
      "Added row 61\n",
      "Added row 62\n",
      "Added row 63\n",
      "Added row 64\n",
      "Added row 65\n",
      "Added row 66\n",
      "Added row 67\n",
      "Added row 68\n",
      "Added row 69\n",
      "Added row 70\n",
      "Added row 71\n",
      "Added row 72\n",
      "Added row 73\n",
      "Added row 74\n",
      "Added row 75\n",
      "Added row 76\n",
      "Added row 77\n",
      "Added row 78\n",
      "Added row 79\n",
      "Added row 80\n",
      "Added row 81\n",
      "Added row 82\n",
      "Added row 83\n",
      "Added row 84\n",
      "Added row 85\n",
      "Added row 86\n",
      "Added row 87\n",
      "Added row 88\n",
      "Added row 89\n",
      "Added row 90\n",
      "Added row 91\n",
      "Added row 92\n",
      "Added row 93\n",
      "Added row 94\n",
      "GB\n",
      "Added row 95\n",
      "Added row 96\n",
      "Added row 97\n",
      "Added row 98\n",
      "Added row 99\n",
      "Added row 100\n",
      "Added row 101\n",
      "Added row 102\n",
      "Added row 103\n",
      "Added row 104\n",
      "Added row 105\n",
      "Added row 106\n",
      "Added row 107\n",
      "Added row 108\n",
      "Added row 109\n",
      "Added row 110\n",
      "SVM\n",
      "Added row 111\n",
      "Added row 112\n",
      "Added row 113\n",
      "Added row 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 115\n",
      "KNN\n",
      "Added row 116\n",
      "RF\n",
      "Added row 117\n",
      "Added row 118\n",
      "Added row 119\n",
      "Added row 120\n",
      "Added row 121\n",
      "Added row 122\n",
      "Added row 123\n",
      "Added row 124\n",
      "AB\n",
      "Added row 125\n",
      "Added row 126\n",
      "Added row 127\n",
      "Added row 128\n",
      "Added row 129\n",
      "Added row 130\n",
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 138\n",
      "DT\n",
      "Added row 139\n",
      "Added row 140\n",
      "Added row 141\n",
      "Added row 142\n",
      "Added row 143\n",
      "Added row 144\n",
      "Added row 145\n",
      "Added row 146\n",
      "Added row 147\n",
      "Added row 148\n",
      "Added row 149\n",
      "Added row 150\n",
      "Added row 151\n",
      "Added row 152\n",
      "Added row 153\n",
      "Added row 154\n",
      "Added row 155\n",
      "Added row 156\n",
      "Added row 157\n",
      "Added row 158\n",
      "Added row 159\n",
      "Added row 160\n",
      "Added row 161\n",
      "Added row 162\n",
      "Added row 163\n",
      "Added row 164\n",
      "Added row 165\n",
      "Added row 166\n",
      "Added row 167\n",
      "Added row 168\n",
      "Added row 169\n",
      "Added row 170\n",
      "Added row 171\n",
      "Added row 172\n",
      "Added row 173\n",
      "Added row 174\n",
      "Added row 175\n",
      "Added row 176\n",
      "Added row 177\n",
      "Added row 178\n",
      "Added row 179\n",
      "Added row 180\n",
      "Added row 181\n",
      "Added row 182\n",
      "Added row 183\n",
      "Added row 184\n",
      "Added row 185\n",
      "Added row 186\n",
      "Added row 187\n",
      "Added row 188\n",
      "Added row 189\n",
      "Added row 190\n",
      "Added row 191\n",
      "Added row 192\n",
      "Added row 193\n",
      "Added row 194\n",
      "Added row 195\n",
      "Added row 196\n",
      "Added row 197\n",
      "Added row 198\n",
      "Added row 199\n",
      "Added row 200\n",
      "Added row 201\n",
      "Added row 202\n",
      "Added row 203\n",
      "Added row 204\n",
      "Added row 205\n",
      "Added row 206\n",
      "Added row 207\n",
      "Added row 208\n",
      "Added row 209\n",
      "Added row 210\n",
      "GB\n",
      "Added row 211\n",
      "Added row 212\n",
      "Added row 213\n",
      "Added row 214\n",
      "Added row 215\n",
      "Added row 216\n",
      "Added row 217\n",
      "Added row 218\n",
      "Added row 219\n",
      "Added row 220\n",
      "Added row 221\n",
      "Added row 222\n",
      "Added row 223\n",
      "Added row 224\n",
      "Added row 225\n",
      "Added row 226\n",
      "SVM\n",
      "Added row 227\n",
      "Added row 228\n",
      "Added row 229\n",
      "Added row 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 231\n",
      "KNN\n",
      "Added row 232\n",
      "RF\n",
      "Added row 233\n",
      "Added row 234\n",
      "Added row 235\n",
      "Added row 236\n",
      "Added row 237\n",
      "Added row 238\n",
      "Added row 239\n",
      "Added row 240\n",
      "AB\n",
      "Added row 241\n",
      "Added row 242\n",
      "Added row 243\n",
      "Added row 244\n",
      "Added row 245\n",
      "Added row 246\n",
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 254\n",
      "DT\n",
      "Added row 255\n",
      "Added row 256\n",
      "Added row 257\n",
      "Added row 258\n",
      "Added row 259\n",
      "Added row 260\n",
      "Added row 261\n",
      "Added row 262\n",
      "Added row 263\n",
      "Added row 264\n",
      "Added row 265\n",
      "Added row 266\n",
      "Added row 267\n",
      "Added row 268\n",
      "Added row 269\n",
      "Added row 270\n",
      "Added row 271\n",
      "Added row 272\n",
      "Added row 273\n",
      "Added row 274\n",
      "Added row 275\n",
      "Added row 276\n",
      "Added row 277\n",
      "Added row 278\n",
      "Added row 279\n",
      "Added row 280\n",
      "Added row 281\n",
      "Added row 282\n",
      "Added row 283\n",
      "Added row 284\n",
      "Added row 285\n",
      "Added row 286\n",
      "Added row 287\n",
      "Added row 288\n",
      "Added row 289\n",
      "Added row 290\n",
      "Added row 291\n",
      "Added row 292\n",
      "Added row 293\n",
      "Added row 294\n",
      "Added row 295\n",
      "Added row 296\n",
      "Added row 297\n",
      "Added row 298\n",
      "Added row 299\n",
      "Added row 300\n",
      "Added row 301\n",
      "Added row 302\n",
      "Added row 303\n",
      "Added row 304\n",
      "Added row 305\n",
      "Added row 306\n",
      "Added row 307\n",
      "Added row 308\n",
      "Added row 309\n",
      "Added row 310\n",
      "Added row 311\n",
      "Added row 312\n",
      "Added row 313\n",
      "Added row 314\n",
      "Added row 315\n",
      "Added row 316\n",
      "Added row 317\n",
      "Added row 318\n",
      "Added row 319\n",
      "Added row 320\n",
      "Added row 321\n",
      "Added row 322\n",
      "Added row 323\n",
      "Added row 324\n",
      "Added row 325\n",
      "Added row 326\n",
      "GB\n",
      "Added row 327\n",
      "Added row 328\n",
      "Added row 329\n",
      "Added row 330\n",
      "Added row 331\n",
      "Added row 332\n",
      "Added row 333\n",
      "Added row 334\n",
      "Added row 335\n",
      "Added row 336\n",
      "Added row 337\n",
      "Added row 338\n",
      "Added row 339\n",
      "Added row 340\n",
      "Added row 341\n",
      "Added row 342\n",
      "SVM\n",
      "Added row 343\n",
      "Added row 344\n",
      "Added row 345\n",
      "Added row 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 347\n",
      "KNN\n",
      "Added row 348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>split_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_50</th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>target_threshold_top_5_percent</th>\n",
       "      <th>precision_at_target</th>\n",
       "      <th>recall_at_target</th>\n",
       "      <th>f1_at_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772923</td>\n",
       "      <td>0.786078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359557</td>\n",
       "      <td>0.639146</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.343514</td>\n",
       "      <td>0.752384</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.832046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011614</td>\n",
       "      <td>0.022961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.977324</td>\n",
       "      <td>0.899207</td>\n",
       "      <td>0.884964</td>\n",
       "      <td>0.911705</td>\n",
       "      <td>0.880362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>0.574177</td>\n",
       "      <td>0.115594</td>\n",
       "      <td>0.384716</td>\n",
       "      <td>0.675905</td>\n",
       "      <td>0.659267</td>\n",
       "      <td>0.737191</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982337</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.580419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254589</td>\n",
       "      <td>0.534177</td>\n",
       "      <td>0.128313</td>\n",
       "      <td>0.253642</td>\n",
       "      <td>0.628818</td>\n",
       "      <td>0.537678</td>\n",
       "      <td>0.733548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.020298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.818594</td>\n",
       "      <td>0.908267</td>\n",
       "      <td>0.910326</td>\n",
       "      <td>0.861897</td>\n",
       "      <td>0.883305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362278</td>\n",
       "      <td>0.567627</td>\n",
       "      <td>0.118907</td>\n",
       "      <td>0.386002</td>\n",
       "      <td>0.668194</td>\n",
       "      <td>0.655112</td>\n",
       "      <td>0.753928</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>0.020355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.848245</td>\n",
       "      <td>0.864130</td>\n",
       "      <td>0.828164</td>\n",
       "      <td>0.876853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357089</td>\n",
       "      <td>0.571835</td>\n",
       "      <td>0.112873</td>\n",
       "      <td>0.383183</td>\n",
       "      <td>0.673149</td>\n",
       "      <td>0.650998</td>\n",
       "      <td>0.890756</td>\n",
       "      <td>0.788804</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.019379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.941043</td>\n",
       "      <td>0.932050</td>\n",
       "      <td>0.924819</td>\n",
       "      <td>0.910573</td>\n",
       "      <td>0.887380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362848</td>\n",
       "      <td>0.572247</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.387783</td>\n",
       "      <td>0.673633</td>\n",
       "      <td>0.669569</td>\n",
       "      <td>0.861312</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.022514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.877717</td>\n",
       "      <td>0.846502</td>\n",
       "      <td>0.875156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360854</td>\n",
       "      <td>0.566962</td>\n",
       "      <td>0.114647</td>\n",
       "      <td>0.382441</td>\n",
       "      <td>0.667412</td>\n",
       "      <td>0.650445</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.821883</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>0.020192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.935447</td>\n",
       "      <td>0.928442</td>\n",
       "      <td>0.909667</td>\n",
       "      <td>0.888851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.571487</td>\n",
       "      <td>0.121273</td>\n",
       "      <td>0.388426</td>\n",
       "      <td>0.672739</td>\n",
       "      <td>0.669207</td>\n",
       "      <td>0.855489</td>\n",
       "      <td>0.949602</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>0.022391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772923</td>\n",
       "      <td>0.786078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359557</td>\n",
       "      <td>0.639146</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.343514</td>\n",
       "      <td>0.752384</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.658718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.018188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 10}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794384</td>\n",
       "      <td>0.841295</td>\n",
       "      <td>0.860441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359557</td>\n",
       "      <td>0.588165</td>\n",
       "      <td>0.103762</td>\n",
       "      <td>0.376011</td>\n",
       "      <td>0.692371</td>\n",
       "      <td>0.652152</td>\n",
       "      <td>0.603400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.016695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 100}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.920725</td>\n",
       "      <td>0.931159</td>\n",
       "      <td>0.911705</td>\n",
       "      <td>0.887493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362468</td>\n",
       "      <td>0.570759</td>\n",
       "      <td>0.121628</td>\n",
       "      <td>0.387832</td>\n",
       "      <td>0.671882</td>\n",
       "      <td>0.664776</td>\n",
       "      <td>0.555101</td>\n",
       "      <td>0.910204</td>\n",
       "      <td>0.007057</td>\n",
       "      <td>0.014005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 1}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772923</td>\n",
       "      <td>0.786078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359557</td>\n",
       "      <td>0.639146</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.343514</td>\n",
       "      <td>0.752384</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.828794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.022899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 10}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.875283</td>\n",
       "      <td>0.890147</td>\n",
       "      <td>0.925272</td>\n",
       "      <td>0.901970</td>\n",
       "      <td>0.879909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363418</td>\n",
       "      <td>0.570918</td>\n",
       "      <td>0.120859</td>\n",
       "      <td>0.384518</td>\n",
       "      <td>0.672068</td>\n",
       "      <td>0.663397</td>\n",
       "      <td>0.547042</td>\n",
       "      <td>0.867220</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>0.013128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 100}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>0.916195</td>\n",
       "      <td>0.911232</td>\n",
       "      <td>0.906271</td>\n",
       "      <td>0.886701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363323</td>\n",
       "      <td>0.572120</td>\n",
       "      <td>0.119025</td>\n",
       "      <td>0.387486</td>\n",
       "      <td>0.673484</td>\n",
       "      <td>0.670781</td>\n",
       "      <td>0.504800</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.012381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793931</td>\n",
       "      <td>0.896989</td>\n",
       "      <td>0.870628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359557</td>\n",
       "      <td>0.589146</td>\n",
       "      <td>0.103703</td>\n",
       "      <td>0.380462</td>\n",
       "      <td>0.693526</td>\n",
       "      <td>0.648040</td>\n",
       "      <td>0.807432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.022281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.925255</td>\n",
       "      <td>0.920743</td>\n",
       "      <td>0.910573</td>\n",
       "      <td>0.888851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363449</td>\n",
       "      <td>0.572089</td>\n",
       "      <td>0.120267</td>\n",
       "      <td>0.388426</td>\n",
       "      <td>0.673447</td>\n",
       "      <td>0.668947</td>\n",
       "      <td>0.838598</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.021520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>0.919592</td>\n",
       "      <td>0.910779</td>\n",
       "      <td>0.906045</td>\n",
       "      <td>0.887380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363228</td>\n",
       "      <td>0.572215</td>\n",
       "      <td>0.118966</td>\n",
       "      <td>0.387783</td>\n",
       "      <td>0.673596</td>\n",
       "      <td>0.671326</td>\n",
       "      <td>0.868064</td>\n",
       "      <td>0.903394</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.021636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.909297</td>\n",
       "      <td>0.919592</td>\n",
       "      <td>0.908967</td>\n",
       "      <td>0.906271</td>\n",
       "      <td>0.886135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363291</td>\n",
       "      <td>0.572278</td>\n",
       "      <td>0.118729</td>\n",
       "      <td>0.387239</td>\n",
       "      <td>0.673670</td>\n",
       "      <td>0.671049</td>\n",
       "      <td>0.869078</td>\n",
       "      <td>0.908616</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>0.021762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.916195</td>\n",
       "      <td>0.908514</td>\n",
       "      <td>0.905818</td>\n",
       "      <td>0.886814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363101</td>\n",
       "      <td>0.572152</td>\n",
       "      <td>0.118670</td>\n",
       "      <td>0.387536</td>\n",
       "      <td>0.673521</td>\n",
       "      <td>0.670834</td>\n",
       "      <td>0.869486</td>\n",
       "      <td>0.901042</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.021636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.900227</td>\n",
       "      <td>0.916195</td>\n",
       "      <td>0.910326</td>\n",
       "      <td>0.905366</td>\n",
       "      <td>0.886474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363228</td>\n",
       "      <td>0.572089</td>\n",
       "      <td>0.118907</td>\n",
       "      <td>0.387387</td>\n",
       "      <td>0.673447</td>\n",
       "      <td>0.670778</td>\n",
       "      <td>0.869593</td>\n",
       "      <td>0.901042</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.021636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.912797</td>\n",
       "      <td>0.910326</td>\n",
       "      <td>0.905592</td>\n",
       "      <td>0.886135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>0.572152</td>\n",
       "      <td>0.118907</td>\n",
       "      <td>0.387239</td>\n",
       "      <td>0.673521</td>\n",
       "      <td>0.670748</td>\n",
       "      <td>0.869636</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.021511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.912797</td>\n",
       "      <td>0.910326</td>\n",
       "      <td>0.905592</td>\n",
       "      <td>0.886135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363228</td>\n",
       "      <td>0.572215</td>\n",
       "      <td>0.118907</td>\n",
       "      <td>0.387239</td>\n",
       "      <td>0.673596</td>\n",
       "      <td>0.670742</td>\n",
       "      <td>0.869660</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.021511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772923</td>\n",
       "      <td>0.786078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359557</td>\n",
       "      <td>0.639146</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.343514</td>\n",
       "      <td>0.752384</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.828794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.022899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772923</td>\n",
       "      <td>0.786078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359557</td>\n",
       "      <td>0.639146</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.343514</td>\n",
       "      <td>0.752384</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.828794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.022899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772923</td>\n",
       "      <td>0.786078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359557</td>\n",
       "      <td>0.639146</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.343514</td>\n",
       "      <td>0.752384</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.828794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011582</td>\n",
       "      <td>0.022899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754132</td>\n",
       "      <td>0.655235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322975</td>\n",
       "      <td>0.602563</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.286336</td>\n",
       "      <td>0.709321</td>\n",
       "      <td>0.541365</td>\n",
       "      <td>0.742469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010348</td>\n",
       "      <td>0.020484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.927438</td>\n",
       "      <td>0.963760</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.992755</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418354</td>\n",
       "      <td>0.697943</td>\n",
       "      <td>0.128727</td>\n",
       "      <td>0.435415</td>\n",
       "      <td>0.821599</td>\n",
       "      <td>0.500405</td>\n",
       "      <td>0.708722</td>\n",
       "      <td>0.897764</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.017610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982337</td>\n",
       "      <td>0.991170</td>\n",
       "      <td>0.580419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254589</td>\n",
       "      <td>0.534177</td>\n",
       "      <td>0.128313</td>\n",
       "      <td>0.253642</td>\n",
       "      <td>0.628818</td>\n",
       "      <td>0.537678</td>\n",
       "      <td>0.734872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.020298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419367</td>\n",
       "      <td>0.698987</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.822828</td>\n",
       "      <td>0.507385</td>\n",
       "      <td>0.714022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.019740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419367</td>\n",
       "      <td>0.698987</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.822828</td>\n",
       "      <td>0.507385</td>\n",
       "      <td>0.714022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.019740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894096</td>\n",
       "      <td>0.625380</td>\n",
       "      <td>0.795953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330603</td>\n",
       "      <td>0.546091</td>\n",
       "      <td>0.112731</td>\n",
       "      <td>0.337582</td>\n",
       "      <td>0.652860</td>\n",
       "      <td>0.595817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.729763</td>\n",
       "      <td>0.713634</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330931</td>\n",
       "      <td>0.546337</td>\n",
       "      <td>0.092011</td>\n",
       "      <td>0.344100</td>\n",
       "      <td>0.653154</td>\n",
       "      <td>0.602226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864881</td>\n",
       "      <td>0.604382</td>\n",
       "      <td>0.781345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328556</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>0.109048</td>\n",
       "      <td>0.331387</td>\n",
       "      <td>0.650070</td>\n",
       "      <td>0.593655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766890</td>\n",
       "      <td>0.695374</td>\n",
       "      <td>0.821059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335517</td>\n",
       "      <td>0.544085</td>\n",
       "      <td>0.096693</td>\n",
       "      <td>0.348230</td>\n",
       "      <td>0.650461</td>\n",
       "      <td>0.600331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672550</td>\n",
       "      <td>0.830493</td>\n",
       "      <td>0.842818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339613</td>\n",
       "      <td>0.551988</td>\n",
       "      <td>0.084798</td>\n",
       "      <td>0.357459</td>\n",
       "      <td>0.659910</td>\n",
       "      <td>0.615008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894096</td>\n",
       "      <td>0.579732</td>\n",
       "      <td>0.779367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323805</td>\n",
       "      <td>0.539375</td>\n",
       "      <td>0.112731</td>\n",
       "      <td>0.330548</td>\n",
       "      <td>0.644831</td>\n",
       "      <td>0.580181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695679</td>\n",
       "      <td>0.698722</td>\n",
       "      <td>0.817559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333593</td>\n",
       "      <td>0.542487</td>\n",
       "      <td>0.087714</td>\n",
       "      <td>0.346746</td>\n",
       "      <td>0.648552</td>\n",
       "      <td>0.594094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637858</td>\n",
       "      <td>0.802495</td>\n",
       "      <td>0.829884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334576</td>\n",
       "      <td>0.543061</td>\n",
       "      <td>0.080424</td>\n",
       "      <td>0.351973</td>\n",
       "      <td>0.649237</td>\n",
       "      <td>0.600006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843579</td>\n",
       "      <td>0.762021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339695</td>\n",
       "      <td>0.608829</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.323191</td>\n",
       "      <td>0.727865</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>0.701135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843579</td>\n",
       "      <td>0.762021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339695</td>\n",
       "      <td>0.608829</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.323191</td>\n",
       "      <td>0.727865</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>0.700400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>0.018662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.920852</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.887705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349728</td>\n",
       "      <td>0.564806</td>\n",
       "      <td>0.099916</td>\n",
       "      <td>0.376496</td>\n",
       "      <td>0.675234</td>\n",
       "      <td>0.646298</td>\n",
       "      <td>0.775496</td>\n",
       "      <td>0.933071</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>0.019211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732806</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.826993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350096</td>\n",
       "      <td>0.569229</td>\n",
       "      <td>0.092395</td>\n",
       "      <td>0.350747</td>\n",
       "      <td>0.680522</td>\n",
       "      <td>0.644931</td>\n",
       "      <td>0.773567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.020589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740718</td>\n",
       "      <td>0.665247</td>\n",
       "      <td>0.804778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329620</td>\n",
       "      <td>0.551783</td>\n",
       "      <td>0.093393</td>\n",
       "      <td>0.341325</td>\n",
       "      <td>0.659666</td>\n",
       "      <td>0.587716</td>\n",
       "      <td>0.719325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>0.019144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.736682</td>\n",
       "      <td>0.837492</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>0.860012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.562349</td>\n",
       "      <td>0.105594</td>\n",
       "      <td>0.364751</td>\n",
       "      <td>0.672297</td>\n",
       "      <td>0.629572</td>\n",
       "      <td>0.711405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.018903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.945122</td>\n",
       "      <td>0.936073</td>\n",
       "      <td>0.912355</td>\n",
       "      <td>0.885575</td>\n",
       "      <td>0.865338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340268</td>\n",
       "      <td>0.546255</td>\n",
       "      <td>0.115033</td>\n",
       "      <td>0.367010</td>\n",
       "      <td>0.653056</td>\n",
       "      <td>0.621233</td>\n",
       "      <td>0.866725</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.021698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.911585</td>\n",
       "      <td>0.890411</td>\n",
       "      <td>0.893488</td>\n",
       "      <td>0.894096</td>\n",
       "      <td>0.882228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349277</td>\n",
       "      <td>0.556124</td>\n",
       "      <td>0.112654</td>\n",
       "      <td>0.374173</td>\n",
       "      <td>0.664855</td>\n",
       "      <td>0.641782</td>\n",
       "      <td>0.867657</td>\n",
       "      <td>0.919298</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.021211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843579</td>\n",
       "      <td>0.762021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339695</td>\n",
       "      <td>0.608829</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.323191</td>\n",
       "      <td>0.727865</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>0.745880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.019867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843579</td>\n",
       "      <td>0.762021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339695</td>\n",
       "      <td>0.608829</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.323191</td>\n",
       "      <td>0.727865</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>0.743072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>0.019787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.945122</td>\n",
       "      <td>0.926941</td>\n",
       "      <td>0.900183</td>\n",
       "      <td>0.911138</td>\n",
       "      <td>0.890749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351407</td>\n",
       "      <td>0.564151</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>0.377787</td>\n",
       "      <td>0.674451</td>\n",
       "      <td>0.651955</td>\n",
       "      <td>0.828515</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.020574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.923780</td>\n",
       "      <td>0.920852</td>\n",
       "      <td>0.917833</td>\n",
       "      <td>0.898052</td>\n",
       "      <td>0.886640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350260</td>\n",
       "      <td>0.561899</td>\n",
       "      <td>0.115724</td>\n",
       "      <td>0.376045</td>\n",
       "      <td>0.671758</td>\n",
       "      <td>0.650671</td>\n",
       "      <td>0.818077</td>\n",
       "      <td>0.944030</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.020497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.685976</td>\n",
       "      <td>0.773212</td>\n",
       "      <td>0.909312</td>\n",
       "      <td>0.737371</td>\n",
       "      <td>0.797322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329661</td>\n",
       "      <td>0.557967</td>\n",
       "      <td>0.114650</td>\n",
       "      <td>0.338163</td>\n",
       "      <td>0.667058</td>\n",
       "      <td>0.590123</td>\n",
       "      <td>0.820769</td>\n",
       "      <td>0.776952</td>\n",
       "      <td>0.008559</td>\n",
       "      <td>0.016931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.881098</td>\n",
       "      <td>0.738204</td>\n",
       "      <td>0.838101</td>\n",
       "      <td>0.868533</td>\n",
       "      <td>0.860164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345141</td>\n",
       "      <td>0.562349</td>\n",
       "      <td>0.105671</td>\n",
       "      <td>0.364816</td>\n",
       "      <td>0.672297</td>\n",
       "      <td>0.629531</td>\n",
       "      <td>0.790357</td>\n",
       "      <td>0.949807</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>0.019937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806697</td>\n",
       "      <td>0.688984</td>\n",
       "      <td>0.760499</td>\n",
       "      <td>0.776628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316024</td>\n",
       "      <td>0.525984</td>\n",
       "      <td>0.086870</td>\n",
       "      <td>0.329386</td>\n",
       "      <td>0.628822</td>\n",
       "      <td>0.548836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.887195</td>\n",
       "      <td>0.875190</td>\n",
       "      <td>0.868533</td>\n",
       "      <td>0.846926</td>\n",
       "      <td>0.846622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337196</td>\n",
       "      <td>0.546173</td>\n",
       "      <td>0.109508</td>\n",
       "      <td>0.359072</td>\n",
       "      <td>0.652958</td>\n",
       "      <td>0.610690</td>\n",
       "      <td>0.954340</td>\n",
       "      <td>0.884984</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.0001}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.920852</td>\n",
       "      <td>0.926354</td>\n",
       "      <td>0.910834</td>\n",
       "      <td>0.886184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349769</td>\n",
       "      <td>0.557271</td>\n",
       "      <td>0.116798</td>\n",
       "      <td>0.375851</td>\n",
       "      <td>0.666226</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>0.582730</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.014628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.923780</td>\n",
       "      <td>0.922374</td>\n",
       "      <td>0.915399</td>\n",
       "      <td>0.913573</td>\n",
       "      <td>0.891205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351693</td>\n",
       "      <td>0.560670</td>\n",
       "      <td>0.115417</td>\n",
       "      <td>0.377981</td>\n",
       "      <td>0.670290</td>\n",
       "      <td>0.658982</td>\n",
       "      <td>0.727439</td>\n",
       "      <td>0.949791</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.018412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>0.928463</td>\n",
       "      <td>0.914181</td>\n",
       "      <td>0.909617</td>\n",
       "      <td>0.890140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351325</td>\n",
       "      <td>0.560465</td>\n",
       "      <td>0.115264</td>\n",
       "      <td>0.377529</td>\n",
       "      <td>0.670045</td>\n",
       "      <td>0.658579</td>\n",
       "      <td>0.735239</td>\n",
       "      <td>0.946058</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.018491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.942073</td>\n",
       "      <td>0.928463</td>\n",
       "      <td>0.909921</td>\n",
       "      <td>0.907486</td>\n",
       "      <td>0.890292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351243</td>\n",
       "      <td>0.560424</td>\n",
       "      <td>0.114726</td>\n",
       "      <td>0.377593</td>\n",
       "      <td>0.669996</td>\n",
       "      <td>0.658493</td>\n",
       "      <td>0.735616</td>\n",
       "      <td>0.946058</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.018491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.942073</td>\n",
       "      <td>0.929985</td>\n",
       "      <td>0.911138</td>\n",
       "      <td>0.908704</td>\n",
       "      <td>0.889075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350997</td>\n",
       "      <td>0.560670</td>\n",
       "      <td>0.114880</td>\n",
       "      <td>0.377077</td>\n",
       "      <td>0.670290</td>\n",
       "      <td>0.658450</td>\n",
       "      <td>0.735016</td>\n",
       "      <td>0.950207</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.018573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866707</td>\n",
       "      <td>0.687462</td>\n",
       "      <td>0.843731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298620</td>\n",
       "      <td>0.532249</td>\n",
       "      <td>0.109278</td>\n",
       "      <td>0.357846</td>\n",
       "      <td>0.636312</td>\n",
       "      <td>0.573257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_type                                                clf  \\\n",
       "0           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "1           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "2           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "3           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "4           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "5           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "6           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "7           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "8           AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "9           AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "10          AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "11          AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "12          AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "13          AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "14          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "15          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "16          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "17          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "18          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "19          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "20          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "21          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "22          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "29          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "..         ...                                                ...   \n",
       "318         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "319         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "320         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "321         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "322         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "323         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "324         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "325         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "326         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "327         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "328         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "329         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "330         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "331         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "332         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "333         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "334         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "335         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "336         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "337         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "338         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "339         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "340         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "341         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "342        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "343        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "344        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "345        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "346        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "347        KNN  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "\n",
       "                                            parameters split_date  baseline  \\\n",
       "0    {'max_depth': 1, 'max_features': 'sqrt', 'min_... 2013-06-30  0.715321   \n",
       "1    {'max_depth': 1, 'max_features': 'sqrt', 'min_... 2013-06-30  0.715321   \n",
       "2    {'max_depth': 1, 'max_features': 'sqrt', 'min_... 2013-06-30  0.715321   \n",
       "3    {'max_depth': 1, 'max_features': 'sqrt', 'min_... 2013-06-30  0.715321   \n",
       "4    {'max_depth': 10, 'max_features': 'sqrt', 'min... 2013-06-30  0.715321   \n",
       "5    {'max_depth': 10, 'max_features': 'sqrt', 'min... 2013-06-30  0.715321   \n",
       "6    {'max_depth': 10, 'max_features': 'sqrt', 'min... 2013-06-30  0.715321   \n",
       "7    {'max_depth': 10, 'max_features': 'sqrt', 'min... 2013-06-30  0.715321   \n",
       "8            {'algorithm': 'SAMME', 'n_estimators': 1} 2013-06-30  0.715321   \n",
       "9           {'algorithm': 'SAMME', 'n_estimators': 10} 2013-06-30  0.715321   \n",
       "10         {'algorithm': 'SAMME', 'n_estimators': 100} 2013-06-30  0.715321   \n",
       "11         {'algorithm': 'SAMME.R', 'n_estimators': 1} 2013-06-30  0.715321   \n",
       "12        {'algorithm': 'SAMME.R', 'n_estimators': 10} 2013-06-30  0.715321   \n",
       "13       {'algorithm': 'SAMME.R', 'n_estimators': 100} 2013-06-30  0.715321   \n",
       "14                       {'C': 0.001, 'penalty': 'l1'} 2013-06-30  0.715321   \n",
       "15                       {'C': 0.001, 'penalty': 'l2'} 2013-06-30  0.715321   \n",
       "16                         {'C': 0.1, 'penalty': 'l1'} 2013-06-30  0.715321   \n",
       "17                         {'C': 0.1, 'penalty': 'l2'} 2013-06-30  0.715321   \n",
       "18                           {'C': 1, 'penalty': 'l1'} 2013-06-30  0.715321   \n",
       "19                           {'C': 1, 'penalty': 'l2'} 2013-06-30  0.715321   \n",
       "20                          {'C': 10, 'penalty': 'l1'} 2013-06-30  0.715321   \n",
       "21                          {'C': 10, 'penalty': 'l2'} 2013-06-30  0.715321   \n",
       "22   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.715321   \n",
       "23   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.715321   \n",
       "24   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.715321   \n",
       "25   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.715321   \n",
       "26   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.715321   \n",
       "27   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.715321   \n",
       "28   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.715321   \n",
       "29   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.715321   \n",
       "..                                                 ...        ...       ...   \n",
       "318  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.743032   \n",
       "319  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.743032   \n",
       "320  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.743032   \n",
       "321  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.743032   \n",
       "322  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.743032   \n",
       "323  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.743032   \n",
       "324  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.743032   \n",
       "325  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.743032   \n",
       "326  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30  0.743032   \n",
       "327  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30  0.743032   \n",
       "328  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30  0.743032   \n",
       "329  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30  0.743032   \n",
       "330  {'learning_rate': 0.1, 'max_depth': 10, 'n_est... 2012-06-30  0.743032   \n",
       "331  {'learning_rate': 0.1, 'max_depth': 10, 'n_est... 2012-06-30  0.743032   \n",
       "332  {'learning_rate': 0.1, 'max_depth': 10, 'n_est... 2012-06-30  0.743032   \n",
       "333  {'learning_rate': 0.1, 'max_depth': 10, 'n_est... 2012-06-30  0.743032   \n",
       "334  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30  0.743032   \n",
       "335  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30  0.743032   \n",
       "336  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30  0.743032   \n",
       "337  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30  0.743032   \n",
       "338  {'learning_rate': 0.5, 'max_depth': 10, 'n_est... 2012-06-30  0.743032   \n",
       "339  {'learning_rate': 0.5, 'max_depth': 10, 'n_est... 2012-06-30  0.743032   \n",
       "340  {'learning_rate': 0.5, 'max_depth': 10, 'n_est... 2012-06-30  0.743032   \n",
       "341  {'learning_rate': 0.5, 'max_depth': 10, 'n_est... 2012-06-30  0.743032   \n",
       "342                                      {'C': 0.0001} 2012-06-30  0.743032   \n",
       "343                                        {'C': 0.01} 2012-06-30  0.743032   \n",
       "344                                         {'C': 0.1} 2012-06-30  0.743032   \n",
       "345                                           {'C': 1} 2012-06-30  0.743032   \n",
       "346                                          {'C': 10} 2012-06-30  0.743032   \n",
       "347  {'algorithm': 'auto', 'n_neighbors': 5, 'weigh... 2012-06-30  0.743032   \n",
       "\n",
       "       p_at_1    p_at_2    p_at_5   p_at_10   p_at_20  ...  recall_at_30  \\\n",
       "0    1.000000  1.000000  1.000000  0.772923  0.786078  ...      0.359557   \n",
       "1    0.977324  0.899207  0.884964  0.911705  0.880362  ...      0.363133   \n",
       "2    1.000000  1.000000  0.982337  0.991170  0.580419  ...      0.254589   \n",
       "3    0.818594  0.908267  0.910326  0.861897  0.883305  ...      0.362278   \n",
       "4    0.802721  0.848245  0.864130  0.828164  0.876853  ...      0.357089   \n",
       "5    0.941043  0.932050  0.924819  0.910573  0.887380  ...      0.362848   \n",
       "6    0.829932  0.864100  0.877717  0.846502  0.875156  ...      0.360854   \n",
       "7    0.952381  0.935447  0.928442  0.909667  0.888851  ...      0.363354   \n",
       "8    1.000000  1.000000  1.000000  0.772923  0.786078  ...      0.359557   \n",
       "9    1.000000  1.000000  0.794384  0.841295  0.860441  ...      0.359557   \n",
       "10   0.920635  0.920725  0.931159  0.911705  0.887493  ...      0.362468   \n",
       "11   1.000000  1.000000  1.000000  0.772923  0.786078  ...      0.359557   \n",
       "12   0.875283  0.890147  0.925272  0.901970  0.879909  ...      0.363418   \n",
       "13   0.911565  0.916195  0.911232  0.906271  0.886701  ...      0.363323   \n",
       "14   1.000000  1.000000  0.793931  0.896989  0.870628  ...      0.359557   \n",
       "15   0.920635  0.925255  0.920743  0.910573  0.888851  ...      0.363449   \n",
       "16   0.911565  0.919592  0.910779  0.906045  0.887380  ...      0.363228   \n",
       "17   0.909297  0.919592  0.908967  0.906271  0.886135  ...      0.363291   \n",
       "18   0.904762  0.916195  0.908514  0.905818  0.886814  ...      0.363101   \n",
       "19   0.900227  0.916195  0.910326  0.905366  0.886474  ...      0.363228   \n",
       "20   0.904762  0.912797  0.910326  0.905592  0.886135  ...      0.363133   \n",
       "21   0.904762  0.912797  0.910326  0.905592  0.886135  ...      0.363228   \n",
       "22   1.000000  1.000000  1.000000  0.772923  0.786078  ...      0.359557   \n",
       "23   1.000000  1.000000  1.000000  0.772923  0.786078  ...      0.359557   \n",
       "24   1.000000  1.000000  1.000000  0.772923  0.786078  ...      0.359557   \n",
       "25   1.000000  1.000000  1.000000  0.754132  0.655235  ...      0.322975   \n",
       "26   0.927438  0.963760  0.985507  0.992755  0.996378  ...      0.418354   \n",
       "27   1.000000  1.000000  0.982337  0.991170  0.580419  ...      0.254589   \n",
       "28   1.000000  1.000000  1.000000  1.000000  1.000000  ...      0.419367   \n",
       "29   1.000000  1.000000  1.000000  1.000000  1.000000  ...      0.419367   \n",
       "..        ...       ...       ...       ...       ...  ...           ...   \n",
       "318  1.000000  1.000000  0.894096  0.625380  0.795953  ...      0.330603   \n",
       "319  1.000000  1.000000  0.729763  0.713634  0.811321  ...      0.330931   \n",
       "320  1.000000  1.000000  0.864881  0.604382  0.781345  ...      0.328556   \n",
       "321  1.000000  1.000000  0.766890  0.695374  0.821059  ...      0.335517   \n",
       "322  1.000000  1.000000  0.672550  0.830493  0.842818  ...      0.339613   \n",
       "323  1.000000  1.000000  0.894096  0.579732  0.779367  ...      0.323805   \n",
       "324  1.000000  1.000000  0.695679  0.698722  0.817559  ...      0.333593   \n",
       "325  1.000000  1.000000  0.637858  0.802495  0.829884  ...      0.334576   \n",
       "326  1.000000  1.000000  1.000000  0.843579  0.762021  ...      0.339695   \n",
       "327  1.000000  1.000000  1.000000  0.843579  0.762021  ...      0.339695   \n",
       "328  0.914634  0.920852  0.792453  0.896226  0.887705  ...      0.349728   \n",
       "329  1.000000  1.000000  0.732806  0.858491  0.826993  ...      0.350096   \n",
       "330  1.000000  1.000000  0.740718  0.665247  0.804778  ...      0.329620   \n",
       "331  0.737805  0.736682  0.837492  0.868229  0.860012  ...      0.345100   \n",
       "332  0.945122  0.936073  0.912355  0.885575  0.865338  ...      0.340268   \n",
       "333  0.911585  0.890411  0.893488  0.894096  0.882228  ...      0.349277   \n",
       "334  1.000000  1.000000  1.000000  0.843579  0.762021  ...      0.339695   \n",
       "335  1.000000  1.000000  1.000000  0.843579  0.762021  ...      0.339695   \n",
       "336  0.945122  0.926941  0.900183  0.911138  0.890749  ...      0.351407   \n",
       "337  0.923780  0.920852  0.917833  0.898052  0.886640  ...      0.350260   \n",
       "338  0.685976  0.773212  0.909312  0.737371  0.797322  ...      0.329661   \n",
       "339  0.881098  0.738204  0.838101  0.868533  0.860164  ...      0.345141   \n",
       "340  1.000000  0.806697  0.688984  0.760499  0.776628  ...      0.316024   \n",
       "341  0.887195  0.875190  0.868533  0.846926  0.846622  ...      0.337196   \n",
       "342  0.939024  0.920852  0.926354  0.910834  0.886184  ...      0.349769   \n",
       "343  0.923780  0.922374  0.915399  0.913573  0.891205  ...      0.351693   \n",
       "344  0.932927  0.928463  0.914181  0.909617  0.890140  ...      0.351325   \n",
       "345  0.942073  0.928463  0.909921  0.907486  0.890292  ...      0.351243   \n",
       "346  0.942073  0.929985  0.911138  0.908704  0.889075  ...      0.350997   \n",
       "347  1.000000  1.000000  0.866707  0.687462  0.843731  ...      0.298620   \n",
       "\n",
       "     recall_at_50   f1_at_5  f1_at_20  f1_at_50   auc-roc  \\\n",
       "0        0.639146  0.130620  0.343514  0.752384  0.610885   \n",
       "1        0.574177  0.115594  0.384716  0.675905  0.659267   \n",
       "2        0.534177  0.128313  0.253642  0.628818  0.537678   \n",
       "3        0.567627  0.118907  0.386002  0.668194  0.655112   \n",
       "4        0.571835  0.112873  0.383183  0.673149  0.650998   \n",
       "5        0.572247  0.120800  0.387783  0.673633  0.669569   \n",
       "6        0.566962  0.114647  0.382441  0.667412  0.650445   \n",
       "7        0.571487  0.121273  0.388426  0.672739  0.669207   \n",
       "8        0.639146  0.130620  0.343514  0.752384  0.610885   \n",
       "9        0.588165  0.103762  0.376011  0.692371  0.652152   \n",
       "10       0.570759  0.121628  0.387832  0.671882  0.664776   \n",
       "11       0.639146  0.130620  0.343514  0.752384  0.610885   \n",
       "12       0.570918  0.120859  0.384518  0.672068  0.663397   \n",
       "13       0.572120  0.119025  0.387486  0.673484  0.670781   \n",
       "14       0.589146  0.103703  0.380462  0.693526  0.648040   \n",
       "15       0.572089  0.120267  0.388426  0.673447  0.668947   \n",
       "16       0.572215  0.118966  0.387783  0.673596  0.671326   \n",
       "17       0.572278  0.118729  0.387239  0.673670  0.671049   \n",
       "18       0.572152  0.118670  0.387536  0.673521  0.670834   \n",
       "19       0.572089  0.118907  0.387387  0.673447  0.670778   \n",
       "20       0.572152  0.118907  0.387239  0.673521  0.670748   \n",
       "21       0.572215  0.118907  0.387239  0.673596  0.670742   \n",
       "22       0.639146  0.130620  0.343514  0.752384  0.610885   \n",
       "23       0.639146  0.130620  0.343514  0.752384  0.610885   \n",
       "24       0.639146  0.130620  0.343514  0.752384  0.610885   \n",
       "25       0.602563  0.130620  0.286336  0.709321  0.541365   \n",
       "26       0.697943  0.128727  0.435415  0.821599  0.500405   \n",
       "27       0.534177  0.128313  0.253642  0.628818  0.537678   \n",
       "28       0.698987  0.130620  0.436998  0.822828  0.507385   \n",
       "29       0.698987  0.130620  0.436998  0.822828  0.507385   \n",
       "..            ...       ...       ...       ...       ...   \n",
       "318      0.546091  0.112731  0.337582  0.652860  0.595817   \n",
       "319      0.546337  0.092011  0.344100  0.653154  0.602226   \n",
       "320      0.543757  0.109048  0.331387  0.650070  0.593655   \n",
       "321      0.544085  0.096693  0.348230  0.650461  0.600331   \n",
       "322      0.551988  0.084798  0.357459  0.659910  0.615008   \n",
       "323      0.539375  0.112731  0.330548  0.644831  0.580181   \n",
       "324      0.542487  0.087714  0.346746  0.648552  0.594094   \n",
       "325      0.543061  0.080424  0.351973  0.649237  0.600006   \n",
       "326      0.608829  0.126084  0.323191  0.727865  0.602229   \n",
       "327      0.608829  0.126084  0.323191  0.727865  0.602229   \n",
       "328      0.564806  0.099916  0.376496  0.675234  0.646298   \n",
       "329      0.569229  0.092395  0.350747  0.680522  0.644931   \n",
       "330      0.551783  0.093393  0.341325  0.659666  0.587716   \n",
       "331      0.562349  0.105594  0.364751  0.672297  0.629572   \n",
       "332      0.546255  0.115033  0.367010  0.653056  0.621233   \n",
       "333      0.556124  0.112654  0.374173  0.664855  0.641782   \n",
       "334      0.608829  0.126084  0.323191  0.727865  0.602229   \n",
       "335      0.608829  0.126084  0.323191  0.727865  0.602229   \n",
       "336      0.564151  0.113499  0.377787  0.674451  0.651955   \n",
       "337      0.561899  0.115724  0.376045  0.671758  0.650671   \n",
       "338      0.557967  0.114650  0.338163  0.667058  0.590123   \n",
       "339      0.562349  0.105671  0.364816  0.672297  0.629531   \n",
       "340      0.525984  0.086870  0.329386  0.628822  0.548836   \n",
       "341      0.546173  0.109508  0.359072  0.652958  0.610690   \n",
       "342      0.557271  0.116798  0.375851  0.666226  0.650574   \n",
       "343      0.560670  0.115417  0.377981  0.670290  0.658982   \n",
       "344      0.560465  0.115264  0.377529  0.670045  0.658579   \n",
       "345      0.560424  0.114726  0.377593  0.669996  0.658493   \n",
       "346      0.560670  0.114880  0.377077  0.670290  0.658450   \n",
       "347      0.532249  0.109278  0.357846  0.636312  0.573257   \n",
       "\n",
       "     target_threshold_top_5_percent  precision_at_target  recall_at_target  \\\n",
       "0                          0.832046             1.000000          0.011614   \n",
       "1                          0.737191             0.969231          0.009968   \n",
       "2                          0.733548             1.000000          0.010253   \n",
       "3                          0.753928             0.975976          0.010285   \n",
       "4                          0.890756             0.788804          0.009810   \n",
       "5                          0.861312             0.947368          0.011392   \n",
       "6                          0.890187             0.821883          0.010222   \n",
       "7                          0.855489             0.949602          0.011329   \n",
       "8                          0.658718             1.000000          0.009177   \n",
       "9                          0.603400             1.000000          0.008418   \n",
       "10                         0.555101             0.910204          0.007057   \n",
       "11                         0.828794             1.000000          0.011582   \n",
       "12                         0.547042             0.867220          0.006614   \n",
       "13                         0.504800             0.883408          0.006234   \n",
       "14                         0.807432             1.000000          0.011266   \n",
       "15                         0.838598             0.929730          0.010886   \n",
       "16                         0.868064             0.903394          0.010949   \n",
       "17                         0.869078             0.908616          0.011013   \n",
       "18                         0.869486             0.901042          0.010949   \n",
       "19                         0.869593             0.901042          0.010949   \n",
       "20                         0.869636             0.895833          0.010886   \n",
       "21                         0.869660             0.895833          0.010886   \n",
       "22                         0.828794             1.000000          0.011582   \n",
       "23                         0.828794             1.000000          0.011582   \n",
       "24                         0.828794             1.000000          0.011582   \n",
       "25                         0.742469             1.000000          0.010348   \n",
       "26                         0.708722             0.897764          0.008892   \n",
       "27                         0.734872             1.000000          0.010253   \n",
       "28                         0.714022             1.000000          0.009968   \n",
       "29                         0.714022             1.000000          0.009968   \n",
       "..                              ...                  ...               ...   \n",
       "318                        1.000000             1.000000          0.013432   \n",
       "319                        1.000000             1.000000          0.013432   \n",
       "320                        1.000000             1.000000          0.013432   \n",
       "321                        1.000000             1.000000          0.013432   \n",
       "322                        1.000000             1.000000          0.013432   \n",
       "323                        1.000000             1.000000          0.013432   \n",
       "324                        1.000000             1.000000          0.013432   \n",
       "325                        1.000000             1.000000          0.013432   \n",
       "326                        0.701135             1.000000          0.009419   \n",
       "327                        0.700400             1.000000          0.009419   \n",
       "328                        0.775496             0.933071          0.009706   \n",
       "329                        0.773567             1.000000          0.010402   \n",
       "330                        0.719325             1.000000          0.009665   \n",
       "331                        0.711405             1.000000          0.009542   \n",
       "332                        0.866725             0.943662          0.010975   \n",
       "333                        0.867657             0.919298          0.010729   \n",
       "334                        0.745880             1.000000          0.010033   \n",
       "335                        0.743072             1.000000          0.009992   \n",
       "336                        0.828515             0.933824          0.010402   \n",
       "337                        0.818077             0.944030          0.010361   \n",
       "338                        0.820769             0.776952          0.008559   \n",
       "339                        0.790357             0.949807          0.010074   \n",
       "340                        1.000000             1.000000          0.013432   \n",
       "341                        0.954340             0.884984          0.011344   \n",
       "342                        0.582730             0.942408          0.007371   \n",
       "343                        0.727439             0.949791          0.009296   \n",
       "344                        0.735239             0.946058          0.009337   \n",
       "345                        0.735616             0.946058          0.009337   \n",
       "346                        0.735016             0.950207          0.009378   \n",
       "347                        1.000000             1.000000          0.013432   \n",
       "\n",
       "     f1_at_target  \n",
       "0        0.022961  \n",
       "1        0.019734  \n",
       "2        0.020298  \n",
       "3        0.020355  \n",
       "4        0.019379  \n",
       "5        0.022514  \n",
       "6        0.020192  \n",
       "7        0.022391  \n",
       "8        0.018188  \n",
       "9        0.016695  \n",
       "10       0.014005  \n",
       "11       0.022899  \n",
       "12       0.013128  \n",
       "13       0.012381  \n",
       "14       0.022281  \n",
       "15       0.021520  \n",
       "16       0.021636  \n",
       "17       0.021762  \n",
       "18       0.021636  \n",
       "19       0.021636  \n",
       "20       0.021511  \n",
       "21       0.021511  \n",
       "22       0.022899  \n",
       "23       0.022899  \n",
       "24       0.022899  \n",
       "25       0.020484  \n",
       "26       0.017610  \n",
       "27       0.020298  \n",
       "28       0.019740  \n",
       "29       0.019740  \n",
       "..            ...  \n",
       "318      0.026508  \n",
       "319      0.026508  \n",
       "320      0.026508  \n",
       "321      0.026508  \n",
       "322      0.026508  \n",
       "323      0.026508  \n",
       "324      0.026508  \n",
       "325      0.026508  \n",
       "326      0.018662  \n",
       "327      0.018662  \n",
       "328      0.019211  \n",
       "329      0.020589  \n",
       "330      0.019144  \n",
       "331      0.018903  \n",
       "332      0.021698  \n",
       "333      0.021211  \n",
       "334      0.019867  \n",
       "335      0.019787  \n",
       "336      0.020574  \n",
       "337      0.020497  \n",
       "338      0.016931  \n",
       "339      0.019937  \n",
       "340      0.026508  \n",
       "341      0.022400  \n",
       "342      0.014628  \n",
       "343      0.018412  \n",
       "344      0.018491  \n",
       "345      0.018491  \n",
       "346      0.018573  \n",
       "347      0.026508  \n",
       "\n",
       "[348 rows x 27 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = build_models.clf_loop_cross_validation(models_to_run, clfs, grid, clean_df, predictors, outcome,\n",
    "                                                    date_col, prediction_windows, start_time, end_time)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('ml_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.pivot_table(results_df,\n",
    "                         index=['model_type', 'split_date'],\n",
    "                         aggfunc='mean',\n",
    "                         fill_value=0)\n",
    "f1_list = ['f1_at_5', 'f1_at_20', 'f1_at_50']\n",
    "p_list = ['p_at_1', 'p_at_2', 'p_at_5', \n",
    "          'p_at_10', 'p_at_20', 'p_at_30', 'p_at_50']\n",
    "recall_list = ['recall_at_1', 'recall_at_2', 'recall_at_5', \n",
    "               'recall_at_10', 'recall_at_20', 'recall_at_30', 'recall_at_50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>baseline</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>f1_at_target</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>...</th>\n",
       "      <th>precision_at_target</th>\n",
       "      <th>recall_at_1</th>\n",
       "      <th>recall_at_10</th>\n",
       "      <th>recall_at_2</th>\n",
       "      <th>recall_at_20</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_5</th>\n",
       "      <th>recall_at_50</th>\n",
       "      <th>recall_at_target</th>\n",
       "      <th>target_threshold_top_5_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.632256</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.349628</td>\n",
       "      <td>0.119855</td>\n",
       "      <td>0.698196</td>\n",
       "      <td>0.015540</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>0.875735</td>\n",
       "      <td>0.951801</td>\n",
       "      <td>0.824356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958705</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.117845</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.221863</td>\n",
       "      <td>0.345291</td>\n",
       "      <td>0.063960</td>\n",
       "      <td>0.584012</td>\n",
       "      <td>0.007835</td>\n",
       "      <td>0.606221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.639311</td>\n",
       "      <td>0.685265</td>\n",
       "      <td>0.357432</td>\n",
       "      <td>0.125538</td>\n",
       "      <td>0.692647</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.947773</td>\n",
       "      <td>0.855991</td>\n",
       "      <td>0.949693</td>\n",
       "      <td>0.791167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940505</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>0.124891</td>\n",
       "      <td>0.027712</td>\n",
       "      <td>0.230866</td>\n",
       "      <td>0.352103</td>\n",
       "      <td>0.067348</td>\n",
       "      <td>0.599016</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.618554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.645480</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.370479</td>\n",
       "      <td>0.121086</td>\n",
       "      <td>0.702429</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.951247</td>\n",
       "      <td>0.851181</td>\n",
       "      <td>0.954511</td>\n",
       "      <td>0.847783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943472</td>\n",
       "      <td>0.013275</td>\n",
       "      <td>0.118977</td>\n",
       "      <td>0.026672</td>\n",
       "      <td>0.237031</td>\n",
       "      <td>0.361313</td>\n",
       "      <td>0.064773</td>\n",
       "      <td>0.596709</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.616309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DT</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.598047</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.357609</td>\n",
       "      <td>0.110571</td>\n",
       "      <td>0.692126</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>0.898797</td>\n",
       "      <td>0.832619</td>\n",
       "      <td>0.913728</td>\n",
       "      <td>0.843173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901552</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.112043</td>\n",
       "      <td>0.024584</td>\n",
       "      <td>0.226927</td>\n",
       "      <td>0.345674</td>\n",
       "      <td>0.059005</td>\n",
       "      <td>0.578936</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.860020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.606762</td>\n",
       "      <td>0.685265</td>\n",
       "      <td>0.351607</td>\n",
       "      <td>0.106765</td>\n",
       "      <td>0.679054</td>\n",
       "      <td>0.022170</td>\n",
       "      <td>0.877368</td>\n",
       "      <td>0.800627</td>\n",
       "      <td>0.878712</td>\n",
       "      <td>0.778274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877607</td>\n",
       "      <td>0.012801</td>\n",
       "      <td>0.116813</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.227103</td>\n",
       "      <td>0.347293</td>\n",
       "      <td>0.057277</td>\n",
       "      <td>0.587261</td>\n",
       "      <td>0.011228</td>\n",
       "      <td>0.880515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.612850</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.367046</td>\n",
       "      <td>0.109087</td>\n",
       "      <td>0.692733</td>\n",
       "      <td>0.022120</td>\n",
       "      <td>0.921139</td>\n",
       "      <td>0.845389</td>\n",
       "      <td>0.917343</td>\n",
       "      <td>0.839926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923181</td>\n",
       "      <td>0.012855</td>\n",
       "      <td>0.118167</td>\n",
       "      <td>0.025633</td>\n",
       "      <td>0.234834</td>\n",
       "      <td>0.354503</td>\n",
       "      <td>0.058354</td>\n",
       "      <td>0.588473</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>0.867888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.616391</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.350783</td>\n",
       "      <td>0.110578</td>\n",
       "      <td>0.680277</td>\n",
       "      <td>0.020286</td>\n",
       "      <td>0.927020</td>\n",
       "      <td>0.841544</td>\n",
       "      <td>0.907820</td>\n",
       "      <td>0.827079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955352</td>\n",
       "      <td>0.012452</td>\n",
       "      <td>0.113244</td>\n",
       "      <td>0.024425</td>\n",
       "      <td>0.222596</td>\n",
       "      <td>0.340785</td>\n",
       "      <td>0.059009</td>\n",
       "      <td>0.569024</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.801045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.626390</td>\n",
       "      <td>0.685265</td>\n",
       "      <td>0.362346</td>\n",
       "      <td>0.111347</td>\n",
       "      <td>0.683810</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>0.858583</td>\n",
       "      <td>0.845593</td>\n",
       "      <td>0.900346</td>\n",
       "      <td>0.802045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874647</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.123374</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.234040</td>\n",
       "      <td>0.357590</td>\n",
       "      <td>0.059735</td>\n",
       "      <td>0.591374</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.822311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.636728</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.368066</td>\n",
       "      <td>0.114392</td>\n",
       "      <td>0.687179</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.843078</td>\n",
       "      <td>0.912727</td>\n",
       "      <td>0.842261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898874</td>\n",
       "      <td>0.012674</td>\n",
       "      <td>0.117844</td>\n",
       "      <td>0.025504</td>\n",
       "      <td>0.235487</td>\n",
       "      <td>0.356762</td>\n",
       "      <td>0.061193</td>\n",
       "      <td>0.583754</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.813337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.573257</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.357846</td>\n",
       "      <td>0.109278</td>\n",
       "      <td>0.636312</td>\n",
       "      <td>0.026508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.092510</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>0.227077</td>\n",
       "      <td>0.298620</td>\n",
       "      <td>0.058315</td>\n",
       "      <td>0.532249</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.585313</td>\n",
       "      <td>0.685265</td>\n",
       "      <td>0.328840</td>\n",
       "      <td>0.135982</td>\n",
       "      <td>0.713547</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727880</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.090903</td>\n",
       "      <td>0.029180</td>\n",
       "      <td>0.212398</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.072951</td>\n",
       "      <td>0.617091</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.596646</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.353258</td>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.666555</td>\n",
       "      <td>0.027527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.091487</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.226013</td>\n",
       "      <td>0.338766</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.566234</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.650080</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.370317</td>\n",
       "      <td>0.116443</td>\n",
       "      <td>0.677254</td>\n",
       "      <td>0.020636</td>\n",
       "      <td>0.943979</td>\n",
       "      <td>0.900829</td>\n",
       "      <td>0.927321</td>\n",
       "      <td>0.873136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943852</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>0.121222</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>0.234991</td>\n",
       "      <td>0.349656</td>\n",
       "      <td>0.062139</td>\n",
       "      <td>0.566495</td>\n",
       "      <td>0.010432</td>\n",
       "      <td>0.823844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.655252</td>\n",
       "      <td>0.685265</td>\n",
       "      <td>0.382449</td>\n",
       "      <td>0.117935</td>\n",
       "      <td>0.673868</td>\n",
       "      <td>0.022875</td>\n",
       "      <td>0.923387</td>\n",
       "      <td>0.867454</td>\n",
       "      <td>0.915035</td>\n",
       "      <td>0.846544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921075</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>0.126563</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>0.247025</td>\n",
       "      <td>0.363309</td>\n",
       "      <td>0.063269</td>\n",
       "      <td>0.582776</td>\n",
       "      <td>0.011581</td>\n",
       "      <td>0.864783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.667808</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.386664</td>\n",
       "      <td>0.117132</td>\n",
       "      <td>0.676040</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.919501</td>\n",
       "      <td>0.905281</td>\n",
       "      <td>0.927803</td>\n",
       "      <td>0.884819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916936</td>\n",
       "      <td>0.012832</td>\n",
       "      <td>0.126539</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>0.247385</td>\n",
       "      <td>0.362777</td>\n",
       "      <td>0.062658</td>\n",
       "      <td>0.574292</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.857693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.614893</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.357241</td>\n",
       "      <td>0.114295</td>\n",
       "      <td>0.678851</td>\n",
       "      <td>0.018546</td>\n",
       "      <td>0.884527</td>\n",
       "      <td>0.831900</td>\n",
       "      <td>0.907344</td>\n",
       "      <td>0.842304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876513</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.111947</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>0.226693</td>\n",
       "      <td>0.343611</td>\n",
       "      <td>0.060992</td>\n",
       "      <td>0.567831</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.802764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.615069</td>\n",
       "      <td>0.685265</td>\n",
       "      <td>0.368318</td>\n",
       "      <td>0.117230</td>\n",
       "      <td>0.690845</td>\n",
       "      <td>0.020382</td>\n",
       "      <td>0.885945</td>\n",
       "      <td>0.755242</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.815265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871966</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>0.110191</td>\n",
       "      <td>0.024230</td>\n",
       "      <td>0.237898</td>\n",
       "      <td>0.360990</td>\n",
       "      <td>0.062891</td>\n",
       "      <td>0.597458</td>\n",
       "      <td>0.010312</td>\n",
       "      <td>0.821513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.637895</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.363713</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.676529</td>\n",
       "      <td>0.020978</td>\n",
       "      <td>0.915249</td>\n",
       "      <td>0.879075</td>\n",
       "      <td>0.923414</td>\n",
       "      <td>0.832301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931608</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.122876</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.232702</td>\n",
       "      <td>0.347963</td>\n",
       "      <td>0.064395</td>\n",
       "      <td>0.574707</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>0.819307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.657016</td>\n",
       "      <td>0.743032</td>\n",
       "      <td>0.377206</td>\n",
       "      <td>0.115417</td>\n",
       "      <td>0.669369</td>\n",
       "      <td>0.017719</td>\n",
       "      <td>0.935976</td>\n",
       "      <td>0.910043</td>\n",
       "      <td>0.926027</td>\n",
       "      <td>0.889379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946905</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>0.122462</td>\n",
       "      <td>0.024915</td>\n",
       "      <td>0.239363</td>\n",
       "      <td>0.351005</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.703208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.659019</td>\n",
       "      <td>0.685265</td>\n",
       "      <td>0.384177</td>\n",
       "      <td>0.121043</td>\n",
       "      <td>0.664956</td>\n",
       "      <td>0.020848</td>\n",
       "      <td>0.928111</td>\n",
       "      <td>0.871797</td>\n",
       "      <td>0.910599</td>\n",
       "      <td>0.850369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929358</td>\n",
       "      <td>0.013541</td>\n",
       "      <td>0.127197</td>\n",
       "      <td>0.026572</td>\n",
       "      <td>0.248141</td>\n",
       "      <td>0.364930</td>\n",
       "      <td>0.064936</td>\n",
       "      <td>0.575069</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>0.779705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.670526</td>\n",
       "      <td>0.715321</td>\n",
       "      <td>0.387526</td>\n",
       "      <td>0.119321</td>\n",
       "      <td>0.673067</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.907041</td>\n",
       "      <td>0.920951</td>\n",
       "      <td>0.886791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911220</td>\n",
       "      <td>0.012848</td>\n",
       "      <td>0.126785</td>\n",
       "      <td>0.025734</td>\n",
       "      <td>0.247937</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>0.063829</td>\n",
       "      <td>0.571766</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.756099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        auc-roc  baseline  f1_at_20   f1_at_5  f1_at_50  \\\n",
       "model_type split_date                                                     \n",
       "AB         2012-06-30  0.632256  0.743032  0.349628  0.119855  0.698196   \n",
       "           2012-12-30  0.639311  0.685265  0.357432  0.125538  0.692647   \n",
       "           2013-06-30  0.645480  0.715321  0.370479  0.121086  0.702429   \n",
       "DT         2012-06-30  0.598047  0.743032  0.357609  0.110571  0.692126   \n",
       "           2012-12-30  0.606762  0.685265  0.351607  0.106765  0.679054   \n",
       "           2013-06-30  0.612850  0.715321  0.367046  0.109087  0.692733   \n",
       "GB         2012-06-30  0.616391  0.743032  0.350783  0.110578  0.680277   \n",
       "           2012-12-30  0.626390  0.685265  0.362346  0.111347  0.683810   \n",
       "           2013-06-30  0.636728  0.715321  0.368066  0.114392  0.687179   \n",
       "KNN        2012-06-30  0.573257  0.743032  0.357846  0.109278  0.636312   \n",
       "           2012-12-30  0.585313  0.685265  0.328840  0.135982  0.713547   \n",
       "           2013-06-30  0.596646  0.715321  0.353258  0.130620  0.666555   \n",
       "LR         2012-06-30  0.650080  0.743032  0.370317  0.116443  0.677254   \n",
       "           2012-12-30  0.655252  0.685265  0.382449  0.117935  0.673868   \n",
       "           2013-06-30  0.667808  0.715321  0.386664  0.117132  0.676040   \n",
       "RF         2012-06-30  0.614893  0.743032  0.357241  0.114295  0.678851   \n",
       "           2012-12-30  0.615069  0.685265  0.368318  0.117230  0.690845   \n",
       "           2013-06-30  0.637895  0.715321  0.363713  0.120378  0.676529   \n",
       "SVM        2012-06-30  0.657016  0.743032  0.377206  0.115417  0.669369   \n",
       "           2012-12-30  0.659019  0.685265  0.384177  0.121043  0.664956   \n",
       "           2013-06-30  0.670526  0.715321  0.387526  0.119321  0.673067   \n",
       "\n",
       "                       f1_at_target    p_at_1   p_at_10    p_at_2   p_at_20  \\\n",
       "model_type split_date                                                         \n",
       "AB         2012-06-30      0.015540  0.968496  0.875735  0.951801  0.824356   \n",
       "           2012-12-30      0.016898  0.947773  0.855991  0.949693  0.791167   \n",
       "           2013-06-30      0.016216  0.951247  0.851181  0.954511  0.847783   \n",
       "DT         2012-06-30      0.020608  0.898797  0.832619  0.913728  0.843173   \n",
       "           2012-12-30      0.022170  0.877368  0.800627  0.878712  0.778274   \n",
       "           2013-06-30      0.022120  0.921139  0.845389  0.917343  0.839926   \n",
       "GB         2012-06-30      0.020286  0.927020  0.841544  0.907820  0.827079   \n",
       "           2012-12-30      0.020481  0.858583  0.845593  0.900346  0.802045   \n",
       "           2013-06-30      0.020011  0.908163  0.843078  0.912727  0.842261   \n",
       "KNN        2012-06-30      0.026508  1.000000  0.687462  1.000000  0.843731   \n",
       "           2012-12-30      0.028761  1.000000  0.623041  1.000000  0.727880   \n",
       "           2013-06-30      0.027527  1.000000  0.654517  1.000000  0.808376   \n",
       "LR         2012-06-30      0.020636  0.943979  0.900829  0.927321  0.873136   \n",
       "           2012-12-30      0.022875  0.923387  0.867454  0.915035  0.846544   \n",
       "           2013-06-30      0.021687  0.919501  0.905281  0.927803  0.884819   \n",
       "RF         2012-06-30      0.018546  0.884527  0.831900  0.907344  0.842304   \n",
       "           2012-12-30      0.020382  0.885945  0.755242  0.830357  0.815265   \n",
       "           2013-06-30      0.020978  0.915249  0.879075  0.923414  0.832301   \n",
       "SVM        2012-06-30      0.017719  0.935976  0.910043  0.926027  0.889379   \n",
       "           2012-12-30      0.020848  0.928111  0.871797  0.910599  0.850369   \n",
       "           2013-06-30      0.019014  0.920635  0.907041  0.920951  0.886791   \n",
       "\n",
       "                       ...  precision_at_target  recall_at_1  recall_at_10  \\\n",
       "model_type split_date  ...                                                   \n",
       "AB         2012-06-30  ...             0.958705     0.013009      0.117845   \n",
       "           2012-12-30  ...             0.940505     0.013828      0.124891   \n",
       "           2013-06-30  ...             0.943472     0.013275      0.118977   \n",
       "DT         2012-06-30  ...             0.901552     0.012073      0.112043   \n",
       "           2012-12-30  ...             0.877607     0.012801      0.116813   \n",
       "           2013-06-30  ...             0.923181     0.012855      0.118167   \n",
       "GB         2012-06-30  ...             0.955352     0.012452      0.113244   \n",
       "           2012-12-30  ...             0.874647     0.012527      0.123374   \n",
       "           2013-06-30  ...             0.898874     0.012674      0.117844   \n",
       "KNN        2012-06-30  ...             1.000000     0.013432      0.092510   \n",
       "           2012-12-30  ...             1.000000     0.014590      0.090903   \n",
       "           2013-06-30  ...             1.000000     0.013956      0.091487   \n",
       "LR         2012-06-30  ...             0.943852     0.012680      0.121222   \n",
       "           2012-12-30  ...             0.921075     0.013472      0.126563   \n",
       "           2013-06-30  ...             0.916936     0.012832      0.126539   \n",
       "RF         2012-06-30  ...             0.876513     0.011881      0.111947   \n",
       "           2012-12-30  ...             0.871966     0.012926      0.110191   \n",
       "           2013-06-30  ...             0.931608     0.012773      0.122876   \n",
       "SVM        2012-06-30  ...             0.946905     0.012572      0.122462   \n",
       "           2012-12-30  ...             0.929358     0.013541      0.127197   \n",
       "           2013-06-30  ...             0.911220     0.012848      0.126785   \n",
       "\n",
       "                       recall_at_2  recall_at_20  recall_at_30  recall_at_5  \\\n",
       "model_type split_date                                                         \n",
       "AB         2012-06-30     0.025608      0.221863      0.345291     0.063960   \n",
       "           2012-12-30     0.027712      0.230866      0.352103     0.067348   \n",
       "           2013-06-30     0.026672      0.237031      0.361313     0.064773   \n",
       "DT         2012-06-30     0.024584      0.226927      0.345674     0.059005   \n",
       "           2012-12-30     0.025641      0.227103      0.347293     0.057277   \n",
       "           2013-06-30     0.025633      0.234834      0.354503     0.058354   \n",
       "GB         2012-06-30     0.024425      0.222596      0.340785     0.059009   \n",
       "           2012-12-30     0.026272      0.234040      0.357590     0.059735   \n",
       "           2013-06-30     0.025504      0.235487      0.356762     0.061193   \n",
       "KNN        2012-06-30     0.026905      0.227077      0.298620     0.058315   \n",
       "           2012-12-30     0.029180      0.212398      0.358368     0.072951   \n",
       "           2013-06-30     0.027943      0.226013      0.338766     0.069873   \n",
       "LR         2012-06-30     0.024950      0.234991      0.349656     0.062139   \n",
       "           2012-12-30     0.026701      0.247025      0.363309     0.063269   \n",
       "           2013-06-30     0.025926      0.247385      0.362777     0.062658   \n",
       "RF         2012-06-30     0.024412      0.226693      0.343611     0.060992   \n",
       "           2012-12-30     0.024230      0.237898      0.360990     0.062891   \n",
       "           2013-06-30     0.025803      0.232702      0.347963     0.064395   \n",
       "SVM        2012-06-30     0.024915      0.239363      0.351005     0.061591   \n",
       "           2012-12-30     0.026572      0.248141      0.364930     0.064936   \n",
       "           2013-06-30     0.025734      0.247937      0.363158     0.063829   \n",
       "\n",
       "                       recall_at_50  recall_at_target  \\\n",
       "model_type split_date                                   \n",
       "AB         2012-06-30      0.584012          0.007835   \n",
       "           2012-12-30      0.599016          0.008528   \n",
       "           2013-06-30      0.596709          0.008180   \n",
       "DT         2012-06-30      0.578936          0.010425   \n",
       "           2012-12-30      0.587261          0.011228   \n",
       "           2013-06-30      0.588473          0.011196   \n",
       "GB         2012-06-30      0.569024          0.010253   \n",
       "           2012-12-30      0.591374          0.010363   \n",
       "           2013-06-30      0.583754          0.010119   \n",
       "KNN        2012-06-30      0.532249          0.013432   \n",
       "           2012-12-30      0.617091          0.014590   \n",
       "           2013-06-30      0.566234          0.013956   \n",
       "LR         2012-06-30      0.566495          0.010432   \n",
       "           2012-12-30      0.582776          0.011581   \n",
       "           2013-06-30      0.574292          0.010973   \n",
       "RF         2012-06-30      0.567831          0.009373   \n",
       "           2012-12-30      0.597458          0.010312   \n",
       "           2013-06-30      0.574707          0.010609   \n",
       "SVM        2012-06-30      0.559900          0.008944   \n",
       "           2012-12-30      0.575069          0.010543   \n",
       "           2013-06-30      0.571766          0.009608   \n",
       "\n",
       "                       target_threshold_top_5_percent  \n",
       "model_type split_date                                  \n",
       "AB         2012-06-30                        0.606221  \n",
       "           2012-12-30                        0.618554  \n",
       "           2013-06-30                        0.616309  \n",
       "DT         2012-06-30                        0.860020  \n",
       "           2012-12-30                        0.880515  \n",
       "           2013-06-30                        0.867888  \n",
       "GB         2012-06-30                        0.801045  \n",
       "           2012-12-30                        0.822311  \n",
       "           2013-06-30                        0.813337  \n",
       "KNN        2012-06-30                        1.000000  \n",
       "           2012-12-30                        1.000000  \n",
       "           2013-06-30                        1.000000  \n",
       "LR         2012-06-30                        0.823844  \n",
       "           2012-12-30                        0.864783  \n",
       "           2013-06-30                        0.857693  \n",
       "RF         2012-06-30                        0.802764  \n",
       "           2012-12-30                        0.821513  \n",
       "           2013-06-30                        0.819307  \n",
       "SVM        2012-06-30                        0.703208  \n",
       "           2012-12-30                        0.779705  \n",
       "           2013-06-30                        0.756099  \n",
       "\n",
       "[21 rows x 23 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>f1_at_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.119855</td>\n",
       "      <td>0.349628</td>\n",
       "      <td>0.698196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.125538</td>\n",
       "      <td>0.357432</td>\n",
       "      <td>0.692647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.121086</td>\n",
       "      <td>0.370479</td>\n",
       "      <td>0.702429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DT</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.110571</td>\n",
       "      <td>0.357609</td>\n",
       "      <td>0.692126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.106765</td>\n",
       "      <td>0.351607</td>\n",
       "      <td>0.679054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.109087</td>\n",
       "      <td>0.367046</td>\n",
       "      <td>0.692733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.110578</td>\n",
       "      <td>0.350783</td>\n",
       "      <td>0.680277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.111347</td>\n",
       "      <td>0.362346</td>\n",
       "      <td>0.683810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.114392</td>\n",
       "      <td>0.368066</td>\n",
       "      <td>0.687179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.109278</td>\n",
       "      <td>0.357846</td>\n",
       "      <td>0.636312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.135982</td>\n",
       "      <td>0.328840</td>\n",
       "      <td>0.713547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.130620</td>\n",
       "      <td>0.353258</td>\n",
       "      <td>0.666555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.116443</td>\n",
       "      <td>0.370317</td>\n",
       "      <td>0.677254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.117935</td>\n",
       "      <td>0.382449</td>\n",
       "      <td>0.673868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.117132</td>\n",
       "      <td>0.386664</td>\n",
       "      <td>0.676040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.114295</td>\n",
       "      <td>0.357241</td>\n",
       "      <td>0.678851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.117230</td>\n",
       "      <td>0.368318</td>\n",
       "      <td>0.690845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.363713</td>\n",
       "      <td>0.676529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.115417</td>\n",
       "      <td>0.377206</td>\n",
       "      <td>0.669369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.121043</td>\n",
       "      <td>0.384177</td>\n",
       "      <td>0.664956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.119321</td>\n",
       "      <td>0.387526</td>\n",
       "      <td>0.673067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        f1_at_5  f1_at_20  f1_at_50\n",
       "model_type split_date                              \n",
       "AB         2012-06-30  0.119855  0.349628  0.698196\n",
       "           2012-12-30  0.125538  0.357432  0.692647\n",
       "           2013-06-30  0.121086  0.370479  0.702429\n",
       "DT         2012-06-30  0.110571  0.357609  0.692126\n",
       "           2012-12-30  0.106765  0.351607  0.679054\n",
       "           2013-06-30  0.109087  0.367046  0.692733\n",
       "GB         2012-06-30  0.110578  0.350783  0.680277\n",
       "           2012-12-30  0.111347  0.362346  0.683810\n",
       "           2013-06-30  0.114392  0.368066  0.687179\n",
       "KNN        2012-06-30  0.109278  0.357846  0.636312\n",
       "           2012-12-30  0.135982  0.328840  0.713547\n",
       "           2013-06-30  0.130620  0.353258  0.666555\n",
       "LR         2012-06-30  0.116443  0.370317  0.677254\n",
       "           2012-12-30  0.117935  0.382449  0.673868\n",
       "           2013-06-30  0.117132  0.386664  0.676040\n",
       "RF         2012-06-30  0.114295  0.357241  0.678851\n",
       "           2012-12-30  0.117230  0.368318  0.690845\n",
       "           2013-06-30  0.120378  0.363713  0.676529\n",
       "SVM        2012-06-30  0.115417  0.377206  0.669369\n",
       "           2012-12-30  0.121043  0.384177  0.664956\n",
       "           2013-06-30  0.119321  0.387526  0.673067"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[f1_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.968496</td>\n",
       "      <td>0.951801</td>\n",
       "      <td>0.950598</td>\n",
       "      <td>0.875735</td>\n",
       "      <td>0.824356</td>\n",
       "      <td>0.855225</td>\n",
       "      <td>0.867880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.947773</td>\n",
       "      <td>0.949693</td>\n",
       "      <td>0.923195</td>\n",
       "      <td>0.855991</td>\n",
       "      <td>0.791167</td>\n",
       "      <td>0.804306</td>\n",
       "      <td>0.820970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.951247</td>\n",
       "      <td>0.954511</td>\n",
       "      <td>0.927008</td>\n",
       "      <td>0.851181</td>\n",
       "      <td>0.847783</td>\n",
       "      <td>0.861568</td>\n",
       "      <td>0.853676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DT</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.898797</td>\n",
       "      <td>0.913728</td>\n",
       "      <td>0.876961</td>\n",
       "      <td>0.832619</td>\n",
       "      <td>0.843173</td>\n",
       "      <td>0.856173</td>\n",
       "      <td>0.860335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.877368</td>\n",
       "      <td>0.878712</td>\n",
       "      <td>0.785138</td>\n",
       "      <td>0.800627</td>\n",
       "      <td>0.778274</td>\n",
       "      <td>0.793318</td>\n",
       "      <td>0.804859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.921139</td>\n",
       "      <td>0.917343</td>\n",
       "      <td>0.835145</td>\n",
       "      <td>0.845389</td>\n",
       "      <td>0.839926</td>\n",
       "      <td>0.845328</td>\n",
       "      <td>0.841893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.927020</td>\n",
       "      <td>0.907820</td>\n",
       "      <td>0.877016</td>\n",
       "      <td>0.841544</td>\n",
       "      <td>0.827079</td>\n",
       "      <td>0.844064</td>\n",
       "      <td>0.845606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.858583</td>\n",
       "      <td>0.900346</td>\n",
       "      <td>0.818836</td>\n",
       "      <td>0.845593</td>\n",
       "      <td>0.802045</td>\n",
       "      <td>0.816839</td>\n",
       "      <td>0.810496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.912727</td>\n",
       "      <td>0.875764</td>\n",
       "      <td>0.843078</td>\n",
       "      <td>0.842261</td>\n",
       "      <td>0.850716</td>\n",
       "      <td>0.835142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866707</td>\n",
       "      <td>0.687462</td>\n",
       "      <td>0.843731</td>\n",
       "      <td>0.739629</td>\n",
       "      <td>0.790957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623041</td>\n",
       "      <td>0.727880</td>\n",
       "      <td>0.818615</td>\n",
       "      <td>0.845743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.808376</td>\n",
       "      <td>0.807803</td>\n",
       "      <td>0.810078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.943979</td>\n",
       "      <td>0.927321</td>\n",
       "      <td>0.923539</td>\n",
       "      <td>0.900829</td>\n",
       "      <td>0.873136</td>\n",
       "      <td>0.866036</td>\n",
       "      <td>0.841848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.923387</td>\n",
       "      <td>0.915035</td>\n",
       "      <td>0.867281</td>\n",
       "      <td>0.867454</td>\n",
       "      <td>0.846544</td>\n",
       "      <td>0.829903</td>\n",
       "      <td>0.798712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.919501</td>\n",
       "      <td>0.927803</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.905281</td>\n",
       "      <td>0.884819</td>\n",
       "      <td>0.865058</td>\n",
       "      <td>0.821606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.884527</td>\n",
       "      <td>0.907344</td>\n",
       "      <td>0.906497</td>\n",
       "      <td>0.831900</td>\n",
       "      <td>0.842304</td>\n",
       "      <td>0.851062</td>\n",
       "      <td>0.843834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.885945</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.862097</td>\n",
       "      <td>0.755242</td>\n",
       "      <td>0.815265</td>\n",
       "      <td>0.824605</td>\n",
       "      <td>0.818835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.915249</td>\n",
       "      <td>0.923414</td>\n",
       "      <td>0.921592</td>\n",
       "      <td>0.879075</td>\n",
       "      <td>0.832301</td>\n",
       "      <td>0.829733</td>\n",
       "      <td>0.822200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.935976</td>\n",
       "      <td>0.926027</td>\n",
       "      <td>0.915399</td>\n",
       "      <td>0.910043</td>\n",
       "      <td>0.889379</td>\n",
       "      <td>0.869378</td>\n",
       "      <td>0.832047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.928111</td>\n",
       "      <td>0.910599</td>\n",
       "      <td>0.890138</td>\n",
       "      <td>0.871797</td>\n",
       "      <td>0.850369</td>\n",
       "      <td>0.833605</td>\n",
       "      <td>0.788150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.920951</td>\n",
       "      <td>0.913496</td>\n",
       "      <td>0.907041</td>\n",
       "      <td>0.886791</td>\n",
       "      <td>0.865967</td>\n",
       "      <td>0.817992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         p_at_1    p_at_2    p_at_5   p_at_10   p_at_20  \\\n",
       "model_type split_date                                                     \n",
       "AB         2012-06-30  0.968496  0.951801  0.950598  0.875735  0.824356   \n",
       "           2012-12-30  0.947773  0.949693  0.923195  0.855991  0.791167   \n",
       "           2013-06-30  0.951247  0.954511  0.927008  0.851181  0.847783   \n",
       "DT         2012-06-30  0.898797  0.913728  0.876961  0.832619  0.843173   \n",
       "           2012-12-30  0.877368  0.878712  0.785138  0.800627  0.778274   \n",
       "           2013-06-30  0.921139  0.917343  0.835145  0.845389  0.839926   \n",
       "GB         2012-06-30  0.927020  0.907820  0.877016  0.841544  0.827079   \n",
       "           2012-12-30  0.858583  0.900346  0.818836  0.845593  0.802045   \n",
       "           2013-06-30  0.908163  0.912727  0.875764  0.843078  0.842261   \n",
       "KNN        2012-06-30  1.000000  1.000000  0.866707  0.687462  0.843731   \n",
       "           2012-12-30  1.000000  1.000000  1.000000  0.623041  0.727880   \n",
       "           2013-06-30  1.000000  1.000000  1.000000  0.654517  0.808376   \n",
       "LR         2012-06-30  0.943979  0.927321  0.923539  0.900829  0.873136   \n",
       "           2012-12-30  0.923387  0.915035  0.867281  0.867454  0.846544   \n",
       "           2013-06-30  0.919501  0.927803  0.896739  0.905281  0.884819   \n",
       "RF         2012-06-30  0.884527  0.907344  0.906497  0.831900  0.842304   \n",
       "           2012-12-30  0.885945  0.830357  0.862097  0.755242  0.815265   \n",
       "           2013-06-30  0.915249  0.923414  0.921592  0.879075  0.832301   \n",
       "SVM        2012-06-30  0.935976  0.926027  0.915399  0.910043  0.889379   \n",
       "           2012-12-30  0.928111  0.910599  0.890138  0.871797  0.850369   \n",
       "           2013-06-30  0.920635  0.920951  0.913496  0.907041  0.886791   \n",
       "\n",
       "                        p_at_30   p_at_50  \n",
       "model_type split_date                      \n",
       "AB         2012-06-30  0.855225  0.867880  \n",
       "           2012-12-30  0.804306  0.820970  \n",
       "           2013-06-30  0.861568  0.853676  \n",
       "DT         2012-06-30  0.856173  0.860335  \n",
       "           2012-12-30  0.793318  0.804859  \n",
       "           2013-06-30  0.845328  0.841893  \n",
       "GB         2012-06-30  0.844064  0.845606  \n",
       "           2012-12-30  0.816839  0.810496  \n",
       "           2013-06-30  0.850716  0.835142  \n",
       "KNN        2012-06-30  0.739629  0.790957  \n",
       "           2012-12-30  0.818615  0.845743  \n",
       "           2013-06-30  0.807803  0.810078  \n",
       "LR         2012-06-30  0.866036  0.841848  \n",
       "           2012-12-30  0.829903  0.798712  \n",
       "           2013-06-30  0.865058  0.821606  \n",
       "RF         2012-06-30  0.851062  0.843834  \n",
       "           2012-12-30  0.824605  0.818835  \n",
       "           2013-06-30  0.829733  0.822200  \n",
       "SVM        2012-06-30  0.869378  0.832047  \n",
       "           2012-12-30  0.833605  0.788150  \n",
       "           2013-06-30  0.865967  0.817992  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[p_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>recall_at_1</th>\n",
       "      <th>recall_at_2</th>\n",
       "      <th>recall_at_5</th>\n",
       "      <th>recall_at_10</th>\n",
       "      <th>recall_at_20</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.063960</td>\n",
       "      <td>0.117845</td>\n",
       "      <td>0.221863</td>\n",
       "      <td>0.345291</td>\n",
       "      <td>0.584012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.013828</td>\n",
       "      <td>0.027712</td>\n",
       "      <td>0.067348</td>\n",
       "      <td>0.124891</td>\n",
       "      <td>0.230866</td>\n",
       "      <td>0.352103</td>\n",
       "      <td>0.599016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.013275</td>\n",
       "      <td>0.026672</td>\n",
       "      <td>0.064773</td>\n",
       "      <td>0.118977</td>\n",
       "      <td>0.237031</td>\n",
       "      <td>0.361313</td>\n",
       "      <td>0.596709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DT</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.024584</td>\n",
       "      <td>0.059005</td>\n",
       "      <td>0.112043</td>\n",
       "      <td>0.226927</td>\n",
       "      <td>0.345674</td>\n",
       "      <td>0.578936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.012801</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.057277</td>\n",
       "      <td>0.116813</td>\n",
       "      <td>0.227103</td>\n",
       "      <td>0.347293</td>\n",
       "      <td>0.587261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.012855</td>\n",
       "      <td>0.025633</td>\n",
       "      <td>0.058354</td>\n",
       "      <td>0.118167</td>\n",
       "      <td>0.234834</td>\n",
       "      <td>0.354503</td>\n",
       "      <td>0.588473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.012452</td>\n",
       "      <td>0.024425</td>\n",
       "      <td>0.059009</td>\n",
       "      <td>0.113244</td>\n",
       "      <td>0.222596</td>\n",
       "      <td>0.340785</td>\n",
       "      <td>0.569024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>0.059735</td>\n",
       "      <td>0.123374</td>\n",
       "      <td>0.234040</td>\n",
       "      <td>0.357590</td>\n",
       "      <td>0.591374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.012674</td>\n",
       "      <td>0.025504</td>\n",
       "      <td>0.061193</td>\n",
       "      <td>0.117844</td>\n",
       "      <td>0.235487</td>\n",
       "      <td>0.356762</td>\n",
       "      <td>0.583754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>0.058315</td>\n",
       "      <td>0.092510</td>\n",
       "      <td>0.227077</td>\n",
       "      <td>0.298620</td>\n",
       "      <td>0.532249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.029180</td>\n",
       "      <td>0.072951</td>\n",
       "      <td>0.090903</td>\n",
       "      <td>0.212398</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.617091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.069873</td>\n",
       "      <td>0.091487</td>\n",
       "      <td>0.226013</td>\n",
       "      <td>0.338766</td>\n",
       "      <td>0.566234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.012680</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>0.062139</td>\n",
       "      <td>0.121222</td>\n",
       "      <td>0.234991</td>\n",
       "      <td>0.349656</td>\n",
       "      <td>0.566495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.013472</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>0.063269</td>\n",
       "      <td>0.126563</td>\n",
       "      <td>0.247025</td>\n",
       "      <td>0.363309</td>\n",
       "      <td>0.582776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.012832</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>0.062658</td>\n",
       "      <td>0.126539</td>\n",
       "      <td>0.247385</td>\n",
       "      <td>0.362777</td>\n",
       "      <td>0.574292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>0.060992</td>\n",
       "      <td>0.111947</td>\n",
       "      <td>0.226693</td>\n",
       "      <td>0.343611</td>\n",
       "      <td>0.567831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.012926</td>\n",
       "      <td>0.024230</td>\n",
       "      <td>0.062891</td>\n",
       "      <td>0.110191</td>\n",
       "      <td>0.237898</td>\n",
       "      <td>0.360990</td>\n",
       "      <td>0.597458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.064395</td>\n",
       "      <td>0.122876</td>\n",
       "      <td>0.232702</td>\n",
       "      <td>0.347963</td>\n",
       "      <td>0.574707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.012572</td>\n",
       "      <td>0.024915</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.122462</td>\n",
       "      <td>0.239363</td>\n",
       "      <td>0.351005</td>\n",
       "      <td>0.559900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.013541</td>\n",
       "      <td>0.026572</td>\n",
       "      <td>0.064936</td>\n",
       "      <td>0.127197</td>\n",
       "      <td>0.248141</td>\n",
       "      <td>0.364930</td>\n",
       "      <td>0.575069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.012848</td>\n",
       "      <td>0.025734</td>\n",
       "      <td>0.063829</td>\n",
       "      <td>0.126785</td>\n",
       "      <td>0.247937</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>0.571766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       recall_at_1  recall_at_2  recall_at_5  recall_at_10  \\\n",
       "model_type split_date                                                        \n",
       "AB         2012-06-30     0.013009     0.025608     0.063960      0.117845   \n",
       "           2012-12-30     0.013828     0.027712     0.067348      0.124891   \n",
       "           2013-06-30     0.013275     0.026672     0.064773      0.118977   \n",
       "DT         2012-06-30     0.012073     0.024584     0.059005      0.112043   \n",
       "           2012-12-30     0.012801     0.025641     0.057277      0.116813   \n",
       "           2013-06-30     0.012855     0.025633     0.058354      0.118167   \n",
       "GB         2012-06-30     0.012452     0.024425     0.059009      0.113244   \n",
       "           2012-12-30     0.012527     0.026272     0.059735      0.123374   \n",
       "           2013-06-30     0.012674     0.025504     0.061193      0.117844   \n",
       "KNN        2012-06-30     0.013432     0.026905     0.058315      0.092510   \n",
       "           2012-12-30     0.014590     0.029180     0.072951      0.090903   \n",
       "           2013-06-30     0.013956     0.027943     0.069873      0.091487   \n",
       "LR         2012-06-30     0.012680     0.024950     0.062139      0.121222   \n",
       "           2012-12-30     0.013472     0.026701     0.063269      0.126563   \n",
       "           2013-06-30     0.012832     0.025926     0.062658      0.126539   \n",
       "RF         2012-06-30     0.011881     0.024412     0.060992      0.111947   \n",
       "           2012-12-30     0.012926     0.024230     0.062891      0.110191   \n",
       "           2013-06-30     0.012773     0.025803     0.064395      0.122876   \n",
       "SVM        2012-06-30     0.012572     0.024915     0.061591      0.122462   \n",
       "           2012-12-30     0.013541     0.026572     0.064936      0.127197   \n",
       "           2013-06-30     0.012848     0.025734     0.063829      0.126785   \n",
       "\n",
       "                       recall_at_20  recall_at_30  recall_at_50  \n",
       "model_type split_date                                            \n",
       "AB         2012-06-30      0.221863      0.345291      0.584012  \n",
       "           2012-12-30      0.230866      0.352103      0.599016  \n",
       "           2013-06-30      0.237031      0.361313      0.596709  \n",
       "DT         2012-06-30      0.226927      0.345674      0.578936  \n",
       "           2012-12-30      0.227103      0.347293      0.587261  \n",
       "           2013-06-30      0.234834      0.354503      0.588473  \n",
       "GB         2012-06-30      0.222596      0.340785      0.569024  \n",
       "           2012-12-30      0.234040      0.357590      0.591374  \n",
       "           2013-06-30      0.235487      0.356762      0.583754  \n",
       "KNN        2012-06-30      0.227077      0.298620      0.532249  \n",
       "           2012-12-30      0.212398      0.358368      0.617091  \n",
       "           2013-06-30      0.226013      0.338766      0.566234  \n",
       "LR         2012-06-30      0.234991      0.349656      0.566495  \n",
       "           2012-12-30      0.247025      0.363309      0.582776  \n",
       "           2013-06-30      0.247385      0.362777      0.574292  \n",
       "RF         2012-06-30      0.226693      0.343611      0.567831  \n",
       "           2012-12-30      0.237898      0.360990      0.597458  \n",
       "           2013-06-30      0.232702      0.347963      0.574707  \n",
       "SVM        2012-06-30      0.239363      0.351005      0.559900  \n",
       "           2012-12-30      0.248141      0.364930      0.575069  \n",
       "           2013-06-30      0.247937      0.363158      0.571766  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
