{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Chi Nguyen\n",
    "\n",
    "\n",
    "Machine Learning for Public Policy\n",
    "\n",
    "\n",
    "HW3 - Applying a machine learning pipeline to the donors dataset\n",
    "\n",
    "\n",
    "Pipeline codes are in the files preprocess.py and build_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocess\n",
    "import build_models\n",
    "import mlhelperfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, process and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_district</th>\n",
       "      <th>...</th>\n",
       "      <th>secondary_focus_subject</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>datefullyfunded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ccc0e81598c4bd86bacb94d7acb</td>\n",
       "      <td>96963218e74e10c3764a5cfb153e6fea</td>\n",
       "      <td>9f3f9f2c2da7edda5648ccd10554ed8c</td>\n",
       "      <td>1.709930e+11</td>\n",
       "      <td>41.807654</td>\n",
       "      <td>-87.673257</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Pershing Elem Network</td>\n",
       "      <td>...</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4/14/13</td>\n",
       "      <td>5/2/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000fa3aa8f6649abab23615b546016d</td>\n",
       "      <td>2a578595fe351e7fce057e048c409b18</td>\n",
       "      <td>3432ed3d4466fac2f2ead83ab354e333</td>\n",
       "      <td>6.409801e+10</td>\n",
       "      <td>34.296596</td>\n",
       "      <td>-119.296596</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Ventura Unif School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "      <td>4/7/12</td>\n",
       "      <td>4/18/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000134f07d4b30140d63262c871748ff</td>\n",
       "      <td>26bd60377bdbffb53a644a16c5308e82</td>\n",
       "      <td>dc8dcb501c3b2bb0b10e9c6ee2cd8afd</td>\n",
       "      <td>6.227100e+10</td>\n",
       "      <td>34.078625</td>\n",
       "      <td>-118.257834</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/30/12</td>\n",
       "      <td>4/15/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001f2d0b3827bba67cdbeaa248b832d</td>\n",
       "      <td>15d900805d9d716c051c671827109f45</td>\n",
       "      <td>8bea7e8c6e4279fca6276128db89292e</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.687286</td>\n",
       "      <td>-73.988217</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/11/12</td>\n",
       "      <td>12/5/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004536db996ba697ca72c9e058bfe69</td>\n",
       "      <td>400f8b82bb0143f6a40b217a517fe311</td>\n",
       "      <td>fbdefab6fe41e12c55886c610c110753</td>\n",
       "      <td>3.606870e+11</td>\n",
       "      <td>40.793018</td>\n",
       "      <td>-73.205635</td>\n",
       "      <td>Central Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Central Islip Union Free SD</td>\n",
       "      <td>...</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/8/13</td>\n",
       "      <td>3/25/13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid                    teacher_acctid  \\\n",
       "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
       "1  0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
       "2  000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
       "3  0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
       "4  0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
       "\n",
       "                           schoolid  school_ncesid  school_latitude  \\\n",
       "0  9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
       "1  3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
       "2  dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
       "3  8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
       "4  fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
       "\n",
       "   school_longitude    school_city school_state school_metro  \\\n",
       "0        -87.673257        Chicago           IL        urban   \n",
       "1       -119.296596        Ventura           CA        urban   \n",
       "2       -118.257834    Los Angeles           CA        urban   \n",
       "3        -73.988217       Brooklyn           NY        urban   \n",
       "4        -73.205635  Central Islip           NY     suburban   \n",
       "\n",
       "                school_district  ... secondary_focus_subject  \\\n",
       "0         Pershing Elem Network  ...             Visual Arts   \n",
       "1  Ventura Unif School District  ...    Literature & Writing   \n",
       "2     Los Angeles Unif Sch Dist  ...         Social Sciences   \n",
       "3      New York City Dept Of Ed  ...                     NaN   \n",
       "4   Central Islip Union Free SD  ...    Literature & Writing   \n",
       "\n",
       "  secondary_focus_area resource_type    poverty_level    grade_level  \\\n",
       "0     Music & The Arts      Supplies  highest poverty  Grades PreK-2   \n",
       "1  Literacy & Language         Books  highest poverty     Grades 3-5   \n",
       "2     History & Civics    Technology     high poverty     Grades 3-5   \n",
       "3                  NaN         Books     high poverty  Grades PreK-2   \n",
       "4  Literacy & Language    Technology     high poverty  Grades PreK-2   \n",
       "\n",
       "  total_price_including_optional_support students_reached  \\\n",
       "0                                1498.61             31.0   \n",
       "1                                 282.47             28.0   \n",
       "2                                1012.38             56.0   \n",
       "3                                 175.33             23.0   \n",
       "4                                3591.11            150.0   \n",
       "\n",
       "  eligible_double_your_impact_match date_posted datefullyfunded  \n",
       "0                                 f     4/14/13          5/2/13  \n",
       "1                                 t      4/7/12         4/18/12  \n",
       "2                                 f     1/30/12         4/15/12  \n",
       "3                                 f    10/11/12         12/5/12  \n",
       "4                                 f      1/8/13         3/25/13  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors = preprocess.import_csv(\"projects_2012_2013.csv\")\n",
    "donors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's take a look at the first 10 lines of the dataframe!\n",
      "\n",
      "                          projectid                    teacher_acctid  \\\n",
      "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
      "1  0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
      "2  000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
      "3  0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
      "4  0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
      "5  00049ec8ca1f2d08cb13cab31b0b85ec  7149611553c700de9a6099f8a9ce598b   \n",
      "6  0004d2fdbb571237fa53a97e7691440b  926671e209fb977bd5123145c1848ad1   \n",
      "7  0004ee26667e751dd51384eb9f30c72e  abe4dabb7864f4c548d230cf9070e03f   \n",
      "8  0006a31d45f8d52d217e7c5b55c11f37  3b5fada1ad0e339acc669829071320c4   \n",
      "9  0008ac907bf237a15a959244205d3ee5  92527a5ac5fe946ed1961fb2e1de8cc5   \n",
      "\n",
      "                           schoolid  school_ncesid  school_latitude  \\\n",
      "0  9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
      "1  3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
      "2  dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
      "3  8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
      "4  fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
      "5  462a5fd93cf9fb5d41eecfd2ea860b19   2.621150e+11        42.740157   \n",
      "6  1a994778027ab086dc58ec3b47f74ff0   4.047200e+10        33.059361   \n",
      "7  8409f70bcd81bc06e4b9efca68eed8f6   6.280501e+10        37.761958   \n",
      "8  c6a033f9349ea70659c1891b119680ed   2.307320e+11        44.096641   \n",
      "9  23e34f5d2e2940684269cffe35741598   6.271800e+10        34.381832   \n",
      "\n",
      "   school_longitude    school_city school_state school_metro  \\\n",
      "0        -87.673257        Chicago           IL        urban   \n",
      "1       -119.296596        Ventura           CA        urban   \n",
      "2       -118.257834    Los Angeles           CA        urban   \n",
      "3        -73.988217       Brooklyn           NY        urban   \n",
      "4        -73.205635  Central Islip           NY     suburban   \n",
      "5        -84.525821        Lansing           MI        urban   \n",
      "6       -112.037727       Maricopa           AZ        rural   \n",
      "7       -122.193209        Oakland           CA        urban   \n",
      "8        -70.191734       Lewiston           ME        urban   \n",
      "9       -118.531837        Newhall           CA     suburban   \n",
      "\n",
      "                 school_district  ... secondary_focus_subject  \\\n",
      "0          Pershing Elem Network  ...             Visual Arts   \n",
      "1   Ventura Unif School District  ...    Literature & Writing   \n",
      "2      Los Angeles Unif Sch Dist  ...         Social Sciences   \n",
      "3       New York City Dept Of Ed  ...                     NaN   \n",
      "4    Central Islip Union Free SD  ...    Literature & Writing   \n",
      "5        Lansing School District  ...                     NaN   \n",
      "6  Maricopa Unif Sch District 20  ...                     NaN   \n",
      "7    Oakland Unified School Dist  ...                     NaN   \n",
      "8        Lewiston Public Schools  ...                     NaN   \n",
      "9        Newhall School District  ...                Literacy   \n",
      "\n",
      "  secondary_focus_area resource_type    poverty_level    grade_level  \\\n",
      "0     Music & The Arts      Supplies  highest poverty  Grades PreK-2   \n",
      "1  Literacy & Language         Books  highest poverty     Grades 3-5   \n",
      "2     History & Civics    Technology     high poverty     Grades 3-5   \n",
      "3                  NaN         Books     high poverty  Grades PreK-2   \n",
      "4  Literacy & Language    Technology     high poverty  Grades PreK-2   \n",
      "5                  NaN         Other  highest poverty     Grades 3-5   \n",
      "6                  NaN      Supplies     high poverty     Grades 3-5   \n",
      "7                  NaN         Books  highest poverty    Grades 9-12   \n",
      "8                  NaN    Technology     high poverty     Grades 3-5   \n",
      "9  Literacy & Language    Technology  highest poverty  Grades PreK-2   \n",
      "\n",
      "  total_price_including_optional_support students_reached  \\\n",
      "0                                1498.61             31.0   \n",
      "1                                 282.47             28.0   \n",
      "2                                1012.38             56.0   \n",
      "3                                 175.33             23.0   \n",
      "4                                3591.11            150.0   \n",
      "5                                 475.85             15.0   \n",
      "6                                 390.65             37.0   \n",
      "7                                3877.20             30.0   \n",
      "8                                 838.75             25.0   \n",
      "9                                1477.44             24.0   \n",
      "\n",
      "  eligible_double_your_impact_match date_posted datefullyfunded  \n",
      "0                                 f     4/14/13          5/2/13  \n",
      "1                                 t      4/7/12         4/18/12  \n",
      "2                                 f     1/30/12         4/15/12  \n",
      "3                                 f    10/11/12         12/5/12  \n",
      "4                                 f      1/8/13         3/25/13  \n",
      "5                                 f    11/30/12         2/26/13  \n",
      "6                                 f     3/26/13         4/17/13  \n",
      "7                                 f     2/28/13         3/10/13  \n",
      "8                                 f     8/21/13         9/13/13  \n",
      "9                                 f     10/3/12         11/3/12  \n",
      "\n",
      "[10 rows x 26 columns]\n",
      "\n",
      "\n",
      "\n",
      "Dataframe's shape: (124976, 26)\n",
      "\n",
      "\n",
      "\n",
      "Data types:\n",
      "\n",
      "projectid                                  object\n",
      "teacher_acctid                             object\n",
      "schoolid                                   object\n",
      "school_ncesid                             float64\n",
      "school_latitude                           float64\n",
      "school_longitude                          float64\n",
      "school_city                                object\n",
      "school_state                               object\n",
      "school_metro                               object\n",
      "school_district                            object\n",
      "school_county                              object\n",
      "school_charter                             object\n",
      "school_magnet                              object\n",
      "teacher_prefix                             object\n",
      "primary_focus_subject                      object\n",
      "primary_focus_area                         object\n",
      "secondary_focus_subject                    object\n",
      "secondary_focus_area                       object\n",
      "resource_type                              object\n",
      "poverty_level                              object\n",
      "grade_level                                object\n",
      "total_price_including_optional_support    float64\n",
      "students_reached                          float64\n",
      "eligible_double_your_impact_match          object\n",
      "date_posted                                object\n",
      "datefullyfunded                            object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Distribution of the variables in the dataframe:\n",
      "\n",
      "       school_ncesid  school_latitude  school_longitude  \\\n",
      "count   1.157430e+05    124976.000000     124976.000000   \n",
      "mean    2.448448e+11        36.827284        -95.859299   \n",
      "std     1.644728e+11         4.963669         18.392876   \n",
      "min     1.000050e+10        18.249140       -171.690554   \n",
      "25%     6.344101e+10        33.872504       -117.806418   \n",
      "50%     2.200870e+11        36.617410        -90.101563   \n",
      "75%     3.704880e+11        40.676156        -80.713740   \n",
      "max     6.100010e+11        65.672562        -66.628036   \n",
      "\n",
      "       total_price_including_optional_support  students_reached  \n",
      "count                           124976.000000     124917.000000  \n",
      "mean                               654.011811         95.445760  \n",
      "std                               1098.015854        163.481912  \n",
      "min                                 92.000000          1.000000  \n",
      "25%                                345.810000         23.000000  \n",
      "50%                                510.500000         30.000000  \n",
      "75%                                752.960000        100.000000  \n",
      "max                             164382.840000      12143.000000  \n"
     ]
    }
   ],
   "source": [
    "preprocess.explore_data(donors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the median value to fill in missing values for students reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brief overview of the number of missingobservations for each column:\n",
      "\n",
      "secondary_focus_area                      40556\n",
      "secondary_focus_subject                   40556\n",
      "school_metro                              15224\n",
      "school_ncesid                              9233\n",
      "school_district                             172\n",
      "students_reached                             59\n",
      "resource_type                                17\n",
      "primary_focus_area                           15\n",
      "primary_focus_subject                        15\n",
      "grade_level                                   3\n",
      "schoolid                                      0\n",
      "teacher_acctid                                0\n",
      "school_latitude                               0\n",
      "school_longitude                              0\n",
      "school_city                                   0\n",
      "school_state                                  0\n",
      "datefullyfunded                               0\n",
      "school_magnet                                 0\n",
      "school_county                                 0\n",
      "school_charter                                0\n",
      "date_posted                                   0\n",
      "teacher_prefix                                0\n",
      "poverty_level                                 0\n",
      "total_price_including_optional_support        0\n",
      "eligible_double_your_impact_match             0\n",
      "projectid                                     0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "List of columns that contain missing data:\n",
      "\n",
      "['school_ncesid', 'school_metro', 'school_district', 'primary_focus_subject', 'primary_focus_area', 'secondary_focus_subject', 'secondary_focus_area', 'resource_type', 'grade_level', 'students_reached']\n",
      "\n",
      "\n",
      "\n",
      "Can't fill missing values for non-numeric column school_metro\n",
      "Can't fill missing values for non-numeric column school_district\n",
      "Can't fill missing values for non-numeric column primary_focus_subject\n",
      "Can't fill missing values for non-numeric column primary_focus_area\n",
      "Can't fill missing values for non-numeric column secondary_focus_subject\n",
      "Can't fill missing values for non-numeric column secondary_focus_area\n",
      "Can't fill missing values for non-numeric column resource_type\n",
      "Can't fill missing values for non-numeric column grade_level\n",
      "Brief overview of the data distribution after pre-processing:\n",
      "\n",
      "       school_ncesid  school_latitude  school_longitude  \\\n",
      "count   1.249760e+05    124976.000000     124976.000000   \n",
      "mean    2.430157e+11        36.827284        -95.859299   \n",
      "std     1.584131e+11         4.963669         18.392876   \n",
      "min     1.000050e+10        18.249140       -171.690554   \n",
      "25%     6.401501e+10        33.872504       -117.806418   \n",
      "50%     2.200870e+11        36.617410        -90.101563   \n",
      "75%     3.702970e+11        40.676156        -80.713740   \n",
      "max     6.100010e+11        65.672562        -66.628036   \n",
      "\n",
      "       total_price_including_optional_support  students_reached  \n",
      "count                           124976.000000     124976.000000  \n",
      "mean                               654.011811         95.414864  \n",
      "std                               1098.015854        163.449500  \n",
      "min                                 92.000000          1.000000  \n",
      "25%                                345.810000         23.000000  \n",
      "50%                                510.500000         30.000000  \n",
      "75%                                752.960000        100.000000  \n",
      "max                             164382.840000      12143.000000  \n"
     ]
    }
   ],
   "source": [
    "preprocess.pre_process(donors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess.create_hist(donors, 'students_reached', 'Students Reached', \n",
    "                       'frequency', \"Histogram of number of students reached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess.create_hist(donors, 'total_price_including_optional_support', 'Total Price', \n",
    "                       'frequency', \"Histogram of total price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocess.create_boxplot(donors, 'students_reached', 'resource_type', \n",
    "                          'Number of students reached', 'Resource type',\n",
    "                          'Boxplot of number of students reached by resource type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_district</th>\n",
       "      <th>...</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>datefullyfunded</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ccc0e81598c4bd86bacb94d7acb</td>\n",
       "      <td>96963218e74e10c3764a5cfb153e6fea</td>\n",
       "      <td>9f3f9f2c2da7edda5648ccd10554ed8c</td>\n",
       "      <td>1.709930e+11</td>\n",
       "      <td>41.807654</td>\n",
       "      <td>-87.673257</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Pershing Elem Network</td>\n",
       "      <td>...</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "      <td>4/14/13</td>\n",
       "      <td>5/2/13</td>\n",
       "      <td>POINT (-87.67325699999999 41.807654)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000fa3aa8f6649abab23615b546016d</td>\n",
       "      <td>2a578595fe351e7fce057e048c409b18</td>\n",
       "      <td>3432ed3d4466fac2f2ead83ab354e333</td>\n",
       "      <td>6.409801e+10</td>\n",
       "      <td>34.296596</td>\n",
       "      <td>-119.296596</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Ventura Unif School District</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "      <td>4/7/12</td>\n",
       "      <td>4/18/12</td>\n",
       "      <td>POINT (-119.296596 34.296596)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000134f07d4b30140d63262c871748ff</td>\n",
       "      <td>26bd60377bdbffb53a644a16c5308e82</td>\n",
       "      <td>dc8dcb501c3b2bb0b10e9c6ee2cd8afd</td>\n",
       "      <td>6.227100e+10</td>\n",
       "      <td>34.078625</td>\n",
       "      <td>-118.257834</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>...</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/30/12</td>\n",
       "      <td>4/15/12</td>\n",
       "      <td>POINT (-118.257834 34.078625)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001f2d0b3827bba67cdbeaa248b832d</td>\n",
       "      <td>15d900805d9d716c051c671827109f45</td>\n",
       "      <td>8bea7e8c6e4279fca6276128db89292e</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.687286</td>\n",
       "      <td>-73.988217</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>10/11/12</td>\n",
       "      <td>12/5/12</td>\n",
       "      <td>POINT (-73.98821700000001 40.687286)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004536db996ba697ca72c9e058bfe69</td>\n",
       "      <td>400f8b82bb0143f6a40b217a517fe311</td>\n",
       "      <td>fbdefab6fe41e12c55886c610c110753</td>\n",
       "      <td>3.606870e+11</td>\n",
       "      <td>40.793018</td>\n",
       "      <td>-73.205635</td>\n",
       "      <td>Central Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Central Islip Union Free SD</td>\n",
       "      <td>...</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "      <td>1/8/13</td>\n",
       "      <td>3/25/13</td>\n",
       "      <td>POINT (-73.205635 40.793018)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid                    teacher_acctid  \\\n",
       "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
       "1  0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
       "2  000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
       "3  0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
       "4  0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
       "\n",
       "                           schoolid  school_ncesid  school_latitude  \\\n",
       "0  9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
       "1  3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
       "2  dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
       "3  8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
       "4  fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
       "\n",
       "   school_longitude    school_city school_state school_metro  \\\n",
       "0        -87.673257        Chicago           IL        urban   \n",
       "1       -119.296596        Ventura           CA        urban   \n",
       "2       -118.257834    Los Angeles           CA        urban   \n",
       "3        -73.988217       Brooklyn           NY        urban   \n",
       "4        -73.205635  Central Islip           NY     suburban   \n",
       "\n",
       "                school_district  ... secondary_focus_area resource_type  \\\n",
       "0         Pershing Elem Network  ...     Music & The Arts      Supplies   \n",
       "1  Ventura Unif School District  ...  Literacy & Language         Books   \n",
       "2     Los Angeles Unif Sch Dist  ...     History & Civics    Technology   \n",
       "3      New York City Dept Of Ed  ...                  NaN         Books   \n",
       "4   Central Islip Union Free SD  ...  Literacy & Language    Technology   \n",
       "\n",
       "     poverty_level    grade_level total_price_including_optional_support  \\\n",
       "0  highest poverty  Grades PreK-2                                1498.61   \n",
       "1  highest poverty     Grades 3-5                                 282.47   \n",
       "2     high poverty     Grades 3-5                                1012.38   \n",
       "3     high poverty  Grades PreK-2                                 175.33   \n",
       "4     high poverty  Grades PreK-2                                3591.11   \n",
       "\n",
       "  students_reached eligible_double_your_impact_match date_posted  \\\n",
       "0             31.0                                 f     4/14/13   \n",
       "1             28.0                                 t      4/7/12   \n",
       "2             56.0                                 f     1/30/12   \n",
       "3             23.0                                 f    10/11/12   \n",
       "4            150.0                                 f      1/8/13   \n",
       "\n",
       "  datefullyfunded                              geometry  \n",
       "0          5/2/13  POINT (-87.67325699999999 41.807654)  \n",
       "1         4/18/12         POINT (-119.296596 34.296596)  \n",
       "2         4/15/12         POINT (-118.257834 34.078625)  \n",
       "3         12/5/12  POINT (-73.98821700000001 40.687286)  \n",
       "4         3/25/13          POINT (-73.205635 40.793018)  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry = [Point(xy) for xy in zip(donors['school_longitude'], donors['school_latitude'])]\n",
    "crs = {'init': 'epsg:4326'}\n",
    "geo_df = gpd.GeoDataFrame(donors, crs=crs, geometry = geometry)\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1766413409817781"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors['students_reached'].corr(donors['total_price_including_optional_support'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting date_posted and datefullyfunded into datetime type to make it easy for calculations later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectid                                         object\n",
       "teacher_acctid                                    object\n",
       "schoolid                                          object\n",
       "school_ncesid                                    float64\n",
       "school_latitude                                  float64\n",
       "school_longitude                                 float64\n",
       "school_city                                       object\n",
       "school_state                                      object\n",
       "school_metro                                      object\n",
       "school_district                                   object\n",
       "school_county                                     object\n",
       "school_charter                                    object\n",
       "school_magnet                                     object\n",
       "teacher_prefix                                    object\n",
       "primary_focus_subject                             object\n",
       "primary_focus_area                                object\n",
       "secondary_focus_subject                           object\n",
       "secondary_focus_area                              object\n",
       "resource_type                                     object\n",
       "poverty_level                                     object\n",
       "grade_level                                       object\n",
       "total_price_including_optional_support           float64\n",
       "students_reached                                 float64\n",
       "eligible_double_your_impact_match                 object\n",
       "date_posted                               datetime64[ns]\n",
       "datefullyfunded                           datetime64[ns]\n",
       "geometry                                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_transform_to_datetime = ['date_posted', 'datefullyfunded']\n",
    "preprocess.convert_to_datetime(donors, cols_to_transform_to_datetime)\n",
    "donors.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.convert_to_categorical_using_qcut(donors, 'students_reached',\n",
    "                                             'students_reached_group', 3, \n",
    "                                             ['low', 'medium', 'high'])\n",
    "preprocess.convert_to_categorical_using_qcut(donors, 'total_price_including_optional_support',\n",
    "                                             'price_group', 3, \n",
    "                                             ['low', 'medium', 'high'])\n",
    "cols_to_transform_to_binary = ['school_state', 'school_metro',\n",
    "                               'school_charter', 'school_magnet',\n",
    "                               'primary_focus_subject', 'resource_type',\n",
    "                               'poverty_level', 'grade_level', 'students_reached_group', 'price_group']\n",
    "donors = preprocess.convert_to_binary(donors, cols_to_transform_to_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors['time_to_fund'] = donors['datefullyfunded'] - donors['date_posted']\n",
    "donors['fund_within_60'] = np.where(donors['time_to_fund'] > pd.to_timedelta(60, unit='D'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school_metro_suburban',\n",
       " 'school_metro_urban',\n",
       " 'school_metro_nan',\n",
       " 'school_charter_f',\n",
       " 'school_charter_t',\n",
       " 'school_charter_nan',\n",
       " 'school_magnet_f',\n",
       " 'school_magnet_t',\n",
       " 'school_magnet_nan',\n",
       " 'primary_focus_subject_Applied Sciences',\n",
       " 'primary_focus_subject_Character Education',\n",
       " 'primary_focus_subject_Civics & Government',\n",
       " 'primary_focus_subject_College & Career Prep',\n",
       " 'primary_focus_subject_Community Service',\n",
       " 'primary_focus_subject_ESL',\n",
       " 'primary_focus_subject_Early Development',\n",
       " 'primary_focus_subject_Economics',\n",
       " 'primary_focus_subject_Environmental Science',\n",
       " 'primary_focus_subject_Extracurricular',\n",
       " 'primary_focus_subject_Foreign Languages',\n",
       " 'primary_focus_subject_Gym & Fitness',\n",
       " 'primary_focus_subject_Health & Life Science',\n",
       " 'primary_focus_subject_Health & Wellness',\n",
       " 'primary_focus_subject_History & Geography',\n",
       " 'primary_focus_subject_Literacy',\n",
       " 'primary_focus_subject_Literature & Writing',\n",
       " 'primary_focus_subject_Mathematics',\n",
       " 'primary_focus_subject_Music',\n",
       " 'primary_focus_subject_Nutrition',\n",
       " 'primary_focus_subject_Other',\n",
       " 'primary_focus_subject_Parent Involvement',\n",
       " 'primary_focus_subject_Performing Arts',\n",
       " 'primary_focus_subject_Social Sciences',\n",
       " 'primary_focus_subject_Special Needs',\n",
       " 'primary_focus_subject_Sports',\n",
       " 'primary_focus_subject_Visual Arts',\n",
       " 'primary_focus_subject_nan',\n",
       " 'resource_type_Books',\n",
       " 'resource_type_Other',\n",
       " 'resource_type_Supplies',\n",
       " 'resource_type_Technology',\n",
       " 'resource_type_Trips',\n",
       " 'resource_type_Visitors',\n",
       " 'resource_type_nan',\n",
       " 'poverty_level_high poverty',\n",
       " 'poverty_level_highest poverty',\n",
       " 'poverty_level_low poverty',\n",
       " 'poverty_level_moderate poverty',\n",
       " 'poverty_level_nan',\n",
       " 'grade_level_Grades 3-5',\n",
       " 'grade_level_Grades 6-8',\n",
       " 'grade_level_Grades 9-12',\n",
       " 'grade_level_Grades PreK-2',\n",
       " 'grade_level_nan',\n",
       " 'students_reached_group_low',\n",
       " 'students_reached_group_medium',\n",
       " 'students_reached_group_high',\n",
       " 'students_reached_group_nan',\n",
       " 'price_group_low',\n",
       " 'price_group_medium',\n",
       " 'price_group_high',\n",
       " 'price_group_nan']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = donors.columns.tolist()\n",
    "selected_features = l[72:134]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models and create a dataframe to store evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 'mini'\n",
    "clfs, grid = mlhelperfunctions.define_clfs_params(grid_size)\n",
    "models_to_run = ['RF', 'B', 'LR', 'DT', 'GB', 'SVM', 'KNN']\n",
    "clean_df = donors\n",
    "predictors = selected_features\n",
    "outcome = 'fund_within_60'\n",
    "date_col = 'date_posted'\n",
    "prediction_windows = [6]\n",
    "start_time = '2012-01-01'\n",
    "end_time = '2013-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "Added row 1\n",
      "Added row 2\n",
      "Added row 3\n",
      "Added row 4\n",
      "Added row 5\n",
      "Added row 6\n",
      "Added row 7\n",
      "Added row 8\n",
      "B\n",
      "Added row 9\n",
      "Added row 10\n",
      "Added row 11\n",
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 19\n",
      "DT\n",
      "Added row 20\n",
      "Added row 21\n",
      "Added row 22\n",
      "Added row 23\n",
      "Added row 24\n",
      "Added row 25\n",
      "Added row 26\n",
      "Added row 27\n",
      "Added row 28\n",
      "Added row 29\n",
      "Added row 30\n",
      "Added row 31\n",
      "Added row 32\n",
      "Added row 33\n",
      "Added row 34\n",
      "Added row 35\n",
      "Added row 36\n",
      "Added row 37\n",
      "Added row 38\n",
      "Added row 39\n",
      "Added row 40\n",
      "Added row 41\n",
      "Added row 42\n",
      "Added row 43\n",
      "Added row 44\n",
      "Added row 45\n",
      "Added row 46\n",
      "Added row 47\n",
      "Added row 48\n",
      "Added row 49\n",
      "Added row 50\n",
      "Added row 51\n",
      "Added row 52\n",
      "Added row 53\n",
      "Added row 54\n",
      "Added row 55\n",
      "Added row 56\n",
      "Added row 57\n",
      "Added row 58\n",
      "Added row 59\n",
      "Added row 60\n",
      "Added row 61\n",
      "Added row 62\n",
      "Added row 63\n",
      "Added row 64\n",
      "Added row 65\n",
      "Added row 66\n",
      "Added row 67\n",
      "Added row 68\n",
      "Added row 69\n",
      "Added row 70\n",
      "Added row 71\n",
      "Added row 72\n",
      "Added row 73\n",
      "Added row 74\n",
      "Added row 75\n",
      "Added row 76\n",
      "Added row 77\n",
      "Added row 78\n",
      "Added row 79\n",
      "Added row 80\n",
      "Added row 81\n",
      "Added row 82\n",
      "Added row 83\n",
      "Added row 84\n",
      "Added row 85\n",
      "Added row 86\n",
      "Added row 87\n",
      "Added row 88\n",
      "Added row 89\n",
      "Added row 90\n",
      "Added row 91\n",
      "GB\n",
      "Added row 92\n",
      "Added row 93\n",
      "Added row 94\n",
      "Added row 95\n",
      "Added row 96\n",
      "Added row 97\n",
      "Added row 98\n",
      "Added row 99\n",
      "Added row 100\n",
      "Added row 101\n",
      "Added row 102\n",
      "Added row 103\n",
      "Added row 104\n",
      "Added row 105\n",
      "Added row 106\n",
      "Added row 107\n",
      "SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 112\n",
      "KNN\n",
      "Added row 113\n",
      "RF\n",
      "Added row 114\n",
      "Added row 115\n",
      "Added row 116\n",
      "Added row 117\n",
      "Added row 118\n",
      "Added row 119\n",
      "Added row 120\n",
      "Added row 121\n",
      "B\n",
      "Added row 122\n",
      "Added row 123\n",
      "Added row 124\n",
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 132\n",
      "DT\n",
      "Added row 133\n",
      "Added row 134\n",
      "Added row 135\n",
      "Added row 136\n",
      "Added row 137\n",
      "Added row 138\n",
      "Added row 139\n",
      "Added row 140\n",
      "Added row 141\n",
      "Added row 142\n",
      "Added row 143\n",
      "Added row 144\n",
      "Added row 145\n",
      "Added row 146\n",
      "Added row 147\n",
      "Added row 148\n",
      "Added row 149\n",
      "Added row 150\n",
      "Added row 151\n",
      "Added row 152\n",
      "Added row 153\n",
      "Added row 154\n",
      "Added row 155\n",
      "Added row 156\n",
      "Added row 157\n",
      "Added row 158\n",
      "Added row 159\n",
      "Added row 160\n",
      "Added row 161\n",
      "Added row 162\n",
      "Added row 163\n",
      "Added row 164\n",
      "Added row 165\n",
      "Added row 166\n",
      "Added row 167\n",
      "Added row 168\n",
      "Added row 169\n",
      "Added row 170\n",
      "Added row 171\n",
      "Added row 172\n",
      "Added row 173\n",
      "Added row 174\n",
      "Added row 175\n",
      "Added row 176\n",
      "Added row 177\n",
      "Added row 178\n",
      "Added row 179\n",
      "Added row 180\n",
      "Added row 181\n",
      "Added row 182\n",
      "Added row 183\n",
      "Added row 184\n",
      "Added row 185\n",
      "Added row 186\n",
      "Added row 187\n",
      "Added row 188\n",
      "Added row 189\n",
      "Added row 190\n",
      "Added row 191\n",
      "Added row 192\n",
      "Added row 193\n",
      "Added row 194\n",
      "Added row 195\n",
      "Added row 196\n",
      "Added row 197\n",
      "Added row 198\n",
      "Added row 199\n",
      "Added row 200\n",
      "Added row 201\n",
      "Added row 202\n",
      "Added row 203\n",
      "Added row 204\n",
      "GB\n",
      "Added row 205\n",
      "Added row 206\n",
      "Added row 207\n",
      "Added row 208\n",
      "Added row 209\n",
      "Added row 210\n",
      "Added row 211\n",
      "Added row 212\n",
      "Added row 213\n",
      "Added row 214\n",
      "Added row 215\n",
      "Added row 216\n",
      "Added row 217\n",
      "Added row 218\n",
      "Added row 219\n",
      "Added row 220\n",
      "SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 225\n",
      "KNN\n",
      "Added row 226\n",
      "RF\n",
      "Added row 227\n",
      "Added row 228\n",
      "Added row 229\n",
      "Added row 230\n",
      "Added row 231\n",
      "Added row 232\n",
      "Added row 233\n",
      "Added row 234\n",
      "B\n",
      "Added row 235\n",
      "Added row 236\n",
      "Added row 237\n",
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 245\n",
      "DT\n",
      "Added row 246\n",
      "Added row 247\n",
      "Added row 248\n",
      "Added row 249\n",
      "Added row 250\n",
      "Added row 251\n",
      "Added row 252\n",
      "Added row 253\n",
      "Added row 254\n",
      "Added row 255\n",
      "Added row 256\n",
      "Added row 257\n",
      "Added row 258\n",
      "Added row 259\n",
      "Added row 260\n",
      "Added row 261\n",
      "Added row 262\n",
      "Added row 263\n",
      "Added row 264\n",
      "Added row 265\n",
      "Added row 266\n",
      "Added row 267\n",
      "Added row 268\n",
      "Added row 269\n",
      "Added row 270\n",
      "Added row 271\n",
      "Added row 272\n",
      "Added row 273\n",
      "Added row 274\n",
      "Added row 275\n",
      "Added row 276\n",
      "Added row 277\n",
      "Added row 278\n",
      "Added row 279\n",
      "Added row 280\n",
      "Added row 281\n",
      "Added row 282\n",
      "Added row 283\n",
      "Added row 284\n",
      "Added row 285\n",
      "Added row 286\n",
      "Added row 287\n",
      "Added row 288\n",
      "Added row 289\n",
      "Added row 290\n",
      "Added row 291\n",
      "Added row 292\n",
      "Added row 293\n",
      "Added row 294\n",
      "Added row 295\n",
      "Added row 296\n",
      "Added row 297\n",
      "Added row 298\n",
      "Added row 299\n",
      "Added row 300\n",
      "Added row 301\n",
      "Added row 302\n",
      "Added row 303\n",
      "Added row 304\n",
      "Added row 305\n",
      "Added row 306\n",
      "Added row 307\n",
      "Added row 308\n",
      "Added row 309\n",
      "Added row 310\n",
      "Added row 311\n",
      "Added row 312\n",
      "Added row 313\n",
      "Added row 314\n",
      "Added row 315\n",
      "Added row 316\n",
      "Added row 317\n",
      "GB\n",
      "Added row 318\n",
      "Added row 319\n",
      "Added row 320\n",
      "Added row 321\n",
      "Added row 322\n",
      "Added row 323\n",
      "Added row 324\n",
      "Added row 325\n",
      "Added row 326\n",
      "Added row 327\n",
      "Added row 328\n",
      "Added row 329\n",
      "Added row 330\n",
      "Added row 331\n",
      "Added row 332\n",
      "Added row 333\n",
      "SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added row 338\n",
      "KNN\n",
      "Added row 339\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>split_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_50</th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>target_threshold_top_5_percent</th>\n",
       "      <th>precision_at_target</th>\n",
       "      <th>recall_at_target</th>\n",
       "      <th>f1_at_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.850191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616894</td>\n",
       "      <td>0.525412</td>\n",
       "      <td>0.296765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.405896</td>\n",
       "      <td>0.334088</td>\n",
       "      <td>0.251359</td>\n",
       "      <td>0.354539</td>\n",
       "      <td>0.420034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402592</td>\n",
       "      <td>0.713263</td>\n",
       "      <td>0.075081</td>\n",
       "      <td>0.346644</td>\n",
       "      <td>0.517540</td>\n",
       "      <td>0.656664</td>\n",
       "      <td>0.330082</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345102</td>\n",
       "      <td>0.920086</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.014852</td>\n",
       "      <td>0.667609</td>\n",
       "      <td>0.605316</td>\n",
       "      <td>0.408109</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.370328</td>\n",
       "      <td>0.409873</td>\n",
       "      <td>0.356350</td>\n",
       "      <td>0.390832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364822</td>\n",
       "      <td>0.633747</td>\n",
       "      <td>0.122430</td>\n",
       "      <td>0.322544</td>\n",
       "      <td>0.459843</td>\n",
       "      <td>0.623349</td>\n",
       "      <td>0.315469</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.378256</td>\n",
       "      <td>0.348732</td>\n",
       "      <td>0.405932</td>\n",
       "      <td>0.325297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419052</td>\n",
       "      <td>0.658158</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.268460</td>\n",
       "      <td>0.477556</td>\n",
       "      <td>0.640715</td>\n",
       "      <td>0.472475</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.463194</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.458003</td>\n",
       "      <td>0.446067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446326</td>\n",
       "      <td>0.680423</td>\n",
       "      <td>0.140016</td>\n",
       "      <td>0.368129</td>\n",
       "      <td>0.493711</td>\n",
       "      <td>0.669816</td>\n",
       "      <td>0.440785</td>\n",
       "      <td>0.427835</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.012999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.263039</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>0.380888</td>\n",
       "      <td>0.312656</td>\n",
       "      <td>0.308093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416269</td>\n",
       "      <td>0.672789</td>\n",
       "      <td>0.113772</td>\n",
       "      <td>0.254262</td>\n",
       "      <td>0.488172</td>\n",
       "      <td>0.647179</td>\n",
       "      <td>0.482684</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>0.011103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.458050</td>\n",
       "      <td>0.474519</td>\n",
       "      <td>0.466486</td>\n",
       "      <td>0.457777</td>\n",
       "      <td>0.444709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445929</td>\n",
       "      <td>0.680821</td>\n",
       "      <td>0.139340</td>\n",
       "      <td>0.367008</td>\n",
       "      <td>0.494000</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.440325</td>\n",
       "      <td>0.432990</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.029891</td>\n",
       "      <td>0.326013</td>\n",
       "      <td>0.354726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378101</td>\n",
       "      <td>0.620309</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.292747</td>\n",
       "      <td>0.450092</td>\n",
       "      <td>0.576196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.394111</td>\n",
       "      <td>0.384511</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>0.372269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397583</td>\n",
       "      <td>0.625636</td>\n",
       "      <td>0.114854</td>\n",
       "      <td>0.307225</td>\n",
       "      <td>0.453958</td>\n",
       "      <td>0.608762</td>\n",
       "      <td>0.746235</td>\n",
       "      <td>0.389058</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>0.019837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.385488</td>\n",
       "      <td>0.383918</td>\n",
       "      <td>0.374094</td>\n",
       "      <td>0.366312</td>\n",
       "      <td>0.380872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404501</td>\n",
       "      <td>0.632475</td>\n",
       "      <td>0.111742</td>\n",
       "      <td>0.314324</td>\n",
       "      <td>0.458920</td>\n",
       "      <td>0.615456</td>\n",
       "      <td>0.715011</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.019238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.321938</td>\n",
       "      <td>0.387210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411021</td>\n",
       "      <td>0.723998</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.319555</td>\n",
       "      <td>0.525329</td>\n",
       "      <td>0.648040</td>\n",
       "      <td>0.386623</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.464326</td>\n",
       "      <td>0.485960</td>\n",
       "      <td>0.470908</td>\n",
       "      <td>0.437125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440283</td>\n",
       "      <td>0.681139</td>\n",
       "      <td>0.145157</td>\n",
       "      <td>0.360749</td>\n",
       "      <td>0.494230</td>\n",
       "      <td>0.668947</td>\n",
       "      <td>0.449516</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.014561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.500566</td>\n",
       "      <td>0.485507</td>\n",
       "      <td>0.475662</td>\n",
       "      <td>0.445840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448950</td>\n",
       "      <td>0.681377</td>\n",
       "      <td>0.145022</td>\n",
       "      <td>0.367942</td>\n",
       "      <td>0.494403</td>\n",
       "      <td>0.671322</td>\n",
       "      <td>0.490285</td>\n",
       "      <td>0.587963</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.019856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.546485</td>\n",
       "      <td>0.500566</td>\n",
       "      <td>0.487772</td>\n",
       "      <td>0.474757</td>\n",
       "      <td>0.444935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447360</td>\n",
       "      <td>0.681616</td>\n",
       "      <td>0.145698</td>\n",
       "      <td>0.367194</td>\n",
       "      <td>0.494577</td>\n",
       "      <td>0.671049</td>\n",
       "      <td>0.494008</td>\n",
       "      <td>0.596330</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.020322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.548753</td>\n",
       "      <td>0.502831</td>\n",
       "      <td>0.488678</td>\n",
       "      <td>0.474530</td>\n",
       "      <td>0.446406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447281</td>\n",
       "      <td>0.681298</td>\n",
       "      <td>0.145969</td>\n",
       "      <td>0.368409</td>\n",
       "      <td>0.494346</td>\n",
       "      <td>0.670827</td>\n",
       "      <td>0.495695</td>\n",
       "      <td>0.582569</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.019853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.548753</td>\n",
       "      <td>0.494904</td>\n",
       "      <td>0.487772</td>\n",
       "      <td>0.475209</td>\n",
       "      <td>0.446067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447281</td>\n",
       "      <td>0.681139</td>\n",
       "      <td>0.145698</td>\n",
       "      <td>0.368129</td>\n",
       "      <td>0.494230</td>\n",
       "      <td>0.670778</td>\n",
       "      <td>0.496058</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.019695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.548753</td>\n",
       "      <td>0.496036</td>\n",
       "      <td>0.488225</td>\n",
       "      <td>0.475209</td>\n",
       "      <td>0.445614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448076</td>\n",
       "      <td>0.681377</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.367755</td>\n",
       "      <td>0.494403</td>\n",
       "      <td>0.670748</td>\n",
       "      <td>0.496275</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.019695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.544218</td>\n",
       "      <td>0.497169</td>\n",
       "      <td>0.488225</td>\n",
       "      <td>0.475209</td>\n",
       "      <td>0.445501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447996</td>\n",
       "      <td>0.681457</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.367661</td>\n",
       "      <td>0.494461</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.496349</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.019695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616547</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.353079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616547</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.353079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616547</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.353079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.585957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425167</td>\n",
       "      <td>0.537678</td>\n",
       "      <td>0.316439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345102</td>\n",
       "      <td>0.920086</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.014852</td>\n",
       "      <td>0.667609</td>\n",
       "      <td>0.605316</td>\n",
       "      <td>0.405735</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.757793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549850</td>\n",
       "      <td>0.541365</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.585957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425167</td>\n",
       "      <td>0.537678</td>\n",
       "      <td>0.316439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312429</td>\n",
       "      <td>0.168761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294211</td>\n",
       "      <td>0.996740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139274</td>\n",
       "      <td>0.723229</td>\n",
       "      <td>0.499604</td>\n",
       "      <td>0.290219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175493</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616547</td>\n",
       "      <td>0.610885</td>\n",
       "      <td>0.353079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.415280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341205</td>\n",
       "      <td>0.722726</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.342721</td>\n",
       "      <td>0.524406</td>\n",
       "      <td>0.656886</td>\n",
       "      <td>0.439640</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.415280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341205</td>\n",
       "      <td>0.722726</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.342721</td>\n",
       "      <td>0.524406</td>\n",
       "      <td>0.656886</td>\n",
       "      <td>0.439640</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.301278</td>\n",
       "      <td>0.311016</td>\n",
       "      <td>0.315581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376554</td>\n",
       "      <td>0.633629</td>\n",
       "      <td>0.098136</td>\n",
       "      <td>0.276220</td>\n",
       "      <td>0.430197</td>\n",
       "      <td>0.595292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.229833</td>\n",
       "      <td>0.307365</td>\n",
       "      <td>0.340231</td>\n",
       "      <td>0.328211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385435</td>\n",
       "      <td>0.633393</td>\n",
       "      <td>0.100119</td>\n",
       "      <td>0.287274</td>\n",
       "      <td>0.430036</td>\n",
       "      <td>0.602131</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.324407</td>\n",
       "      <td>0.332015</td>\n",
       "      <td>0.329276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393843</td>\n",
       "      <td>0.620367</td>\n",
       "      <td>0.105670</td>\n",
       "      <td>0.288207</td>\n",
       "      <td>0.421192</td>\n",
       "      <td>0.588519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.300670</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>0.334753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392066</td>\n",
       "      <td>0.629130</td>\n",
       "      <td>0.097938</td>\n",
       "      <td>0.293001</td>\n",
       "      <td>0.427142</td>\n",
       "      <td>0.598789</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.319635</td>\n",
       "      <td>0.303104</td>\n",
       "      <td>0.342970</td>\n",
       "      <td>0.343427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>0.629722</td>\n",
       "      <td>0.098731</td>\n",
       "      <td>0.300593</td>\n",
       "      <td>0.427544</td>\n",
       "      <td>0.603838</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.298844</td>\n",
       "      <td>0.328363</td>\n",
       "      <td>0.329124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385435</td>\n",
       "      <td>0.629840</td>\n",
       "      <td>0.097343</td>\n",
       "      <td>0.288074</td>\n",
       "      <td>0.427624</td>\n",
       "      <td>0.595058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.121766</td>\n",
       "      <td>0.311625</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.318929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397395</td>\n",
       "      <td>0.623683</td>\n",
       "      <td>0.101507</td>\n",
       "      <td>0.279150</td>\n",
       "      <td>0.423443</td>\n",
       "      <td>0.598635</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'max...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.328667</td>\n",
       "      <td>0.357882</td>\n",
       "      <td>0.340231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388040</td>\n",
       "      <td>0.618472</td>\n",
       "      <td>0.107058</td>\n",
       "      <td>0.297796</td>\n",
       "      <td>0.419906</td>\n",
       "      <td>0.599284</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.814802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>0.316643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.814802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>0.316910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.266281</td>\n",
       "      <td>0.291083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428182</td>\n",
       "      <td>0.737715</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.254778</td>\n",
       "      <td>0.500864</td>\n",
       "      <td>0.643475</td>\n",
       "      <td>0.403562</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.139988</td>\n",
       "      <td>0.346622</td>\n",
       "      <td>0.326841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434695</td>\n",
       "      <td>0.700178</td>\n",
       "      <td>0.045599</td>\n",
       "      <td>0.286076</td>\n",
       "      <td>0.475379</td>\n",
       "      <td>0.644931</td>\n",
       "      <td>0.399043</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.057839</td>\n",
       "      <td>0.254413</td>\n",
       "      <td>0.291844</td>\n",
       "      <td>0.266129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307993</td>\n",
       "      <td>0.650089</td>\n",
       "      <td>0.082871</td>\n",
       "      <td>0.232936</td>\n",
       "      <td>0.441372</td>\n",
       "      <td>0.587582</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.301829</td>\n",
       "      <td>0.304414</td>\n",
       "      <td>0.371272</td>\n",
       "      <td>0.355447</td>\n",
       "      <td>0.342666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378804</td>\n",
       "      <td>0.680521</td>\n",
       "      <td>0.120936</td>\n",
       "      <td>0.299927</td>\n",
       "      <td>0.462033</td>\n",
       "      <td>0.629531</td>\n",
       "      <td>0.332687</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.411585</td>\n",
       "      <td>0.385084</td>\n",
       "      <td>0.382836</td>\n",
       "      <td>0.374011</td>\n",
       "      <td>0.361229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406394</td>\n",
       "      <td>0.639668</td>\n",
       "      <td>0.124703</td>\n",
       "      <td>0.316175</td>\n",
       "      <td>0.434297</td>\n",
       "      <td>0.625787</td>\n",
       "      <td>0.552124</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.018780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.371951</td>\n",
       "      <td>0.362253</td>\n",
       "      <td>0.379793</td>\n",
       "      <td>0.371272</td>\n",
       "      <td>0.370055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429959</td>\n",
       "      <td>0.663233</td>\n",
       "      <td>0.123711</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.450295</td>\n",
       "      <td>0.642184</td>\n",
       "      <td>0.490721</td>\n",
       "      <td>0.335404</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>0.012549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.814802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>0.333055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.814802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>0.341629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.405488</td>\n",
       "      <td>0.398782</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>0.411747</td>\n",
       "      <td>0.391814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435524</td>\n",
       "      <td>0.671522</td>\n",
       "      <td>0.134417</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>0.455923</td>\n",
       "      <td>0.648971</td>\n",
       "      <td>0.484087</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.017201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.417683</td>\n",
       "      <td>0.418569</td>\n",
       "      <td>0.396835</td>\n",
       "      <td>0.391966</td>\n",
       "      <td>0.382836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425933</td>\n",
       "      <td>0.678982</td>\n",
       "      <td>0.129262</td>\n",
       "      <td>0.335087</td>\n",
       "      <td>0.460988</td>\n",
       "      <td>0.650671</td>\n",
       "      <td>0.466488</td>\n",
       "      <td>0.346405</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.012328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.092846</td>\n",
       "      <td>0.291540</td>\n",
       "      <td>0.317103</td>\n",
       "      <td>0.312082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396921</td>\n",
       "      <td>0.656246</td>\n",
       "      <td>0.094964</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>0.445552</td>\n",
       "      <td>0.605305</td>\n",
       "      <td>0.656023</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.307927</td>\n",
       "      <td>0.308980</td>\n",
       "      <td>0.378576</td>\n",
       "      <td>0.356056</td>\n",
       "      <td>0.341753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379159</td>\n",
       "      <td>0.680403</td>\n",
       "      <td>0.123315</td>\n",
       "      <td>0.299128</td>\n",
       "      <td>0.461953</td>\n",
       "      <td>0.629578</td>\n",
       "      <td>0.426469</td>\n",
       "      <td>0.307143</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.010017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.248935</td>\n",
       "      <td>0.269933</td>\n",
       "      <td>0.292757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349674</td>\n",
       "      <td>0.574896</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>0.256243</td>\n",
       "      <td>0.390320</td>\n",
       "      <td>0.551586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.301829</td>\n",
       "      <td>0.319635</td>\n",
       "      <td>0.339014</td>\n",
       "      <td>0.344492</td>\n",
       "      <td>0.346013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403434</td>\n",
       "      <td>0.629959</td>\n",
       "      <td>0.110428</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>0.427704</td>\n",
       "      <td>0.609748</td>\n",
       "      <td>0.719816</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.016588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.0001}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.423780</td>\n",
       "      <td>0.421613</td>\n",
       "      <td>0.423007</td>\n",
       "      <td>0.408704</td>\n",
       "      <td>0.389531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436945</td>\n",
       "      <td>0.665601</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.340947</td>\n",
       "      <td>0.451903</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>-0.141265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.454268</td>\n",
       "      <td>0.465753</td>\n",
       "      <td>0.447352</td>\n",
       "      <td>0.426659</td>\n",
       "      <td>0.403682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447010</td>\n",
       "      <td>0.675429</td>\n",
       "      <td>0.145718</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>0.458576</td>\n",
       "      <td>0.658982</td>\n",
       "      <td>-0.016446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.460366</td>\n",
       "      <td>0.467275</td>\n",
       "      <td>0.442483</td>\n",
       "      <td>0.427572</td>\n",
       "      <td>0.405052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447602</td>\n",
       "      <td>0.674837</td>\n",
       "      <td>0.144132</td>\n",
       "      <td>0.354532</td>\n",
       "      <td>0.458174</td>\n",
       "      <td>0.658578</td>\n",
       "      <td>-0.007312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.460366</td>\n",
       "      <td>0.464231</td>\n",
       "      <td>0.435788</td>\n",
       "      <td>0.426354</td>\n",
       "      <td>0.404443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447247</td>\n",
       "      <td>0.674719</td>\n",
       "      <td>0.141951</td>\n",
       "      <td>0.353999</td>\n",
       "      <td>0.458094</td>\n",
       "      <td>0.658494</td>\n",
       "      <td>-0.006635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>SVM</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.460366</td>\n",
       "      <td>0.461187</td>\n",
       "      <td>0.435180</td>\n",
       "      <td>0.424528</td>\n",
       "      <td>0.403987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446655</td>\n",
       "      <td>0.675784</td>\n",
       "      <td>0.141753</td>\n",
       "      <td>0.353599</td>\n",
       "      <td>0.458817</td>\n",
       "      <td>0.658245</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.295732</td>\n",
       "      <td>0.147641</td>\n",
       "      <td>0.328058</td>\n",
       "      <td>0.222155</td>\n",
       "      <td>0.315733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274482</td>\n",
       "      <td>0.593250</td>\n",
       "      <td>0.106860</td>\n",
       "      <td>0.276353</td>\n",
       "      <td>0.402782</td>\n",
       "      <td>0.573257</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.370229</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.022281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_type                                                clf  \\\n",
       "0           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "1           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "2           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "3           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "4           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "5           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "6           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "7           RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "8            B  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "9            B  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "10           B  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "11          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "12          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "13          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "14          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "15          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "16          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "17          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "18          LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "19          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "20          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "21          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "22          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "23          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "24          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "25          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "26          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "27          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "28          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "29          DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "..         ...                                                ...   \n",
       "309         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "310         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "311         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "312         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "313         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "314         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "315         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "316         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "317         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "318         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "319         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "320         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "321         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "322         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "323         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "324         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "325         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "326         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "327         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "328         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "329         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "330         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "331         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "332         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "333        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "334        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "335        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "336        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "337        SVM  LinearSVC(C=10, class_weight=None, dual=True, ...   \n",
       "338        KNN  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "\n",
       "                                            parameters split_date  baseline  \\\n",
       "0    {'max_depth': 1, 'max_features': 'sqrt', 'min_... 2013-06-30  0.284679   \n",
       "1    {'max_depth': 1, 'max_features': 'sqrt', 'min_... 2013-06-30  0.284679   \n",
       "2    {'max_depth': 1, 'max_features': 'sqrt', 'min_... 2013-06-30  0.284679   \n",
       "3    {'max_depth': 1, 'max_features': 'sqrt', 'min_... 2013-06-30  0.284679   \n",
       "4    {'max_depth': 10, 'max_features': 'sqrt', 'min... 2013-06-30  0.284679   \n",
       "5    {'max_depth': 10, 'max_features': 'sqrt', 'min... 2013-06-30  0.284679   \n",
       "6    {'max_depth': 10, 'max_features': 'sqrt', 'min... 2013-06-30  0.284679   \n",
       "7    {'max_depth': 10, 'max_features': 'sqrt', 'min... 2013-06-30  0.284679   \n",
       "8                                  {'n_estimators': 1} 2013-06-30  0.284679   \n",
       "9                                 {'n_estimators': 10} 2013-06-30  0.284679   \n",
       "10                               {'n_estimators': 100} 2013-06-30  0.284679   \n",
       "11                       {'C': 0.001, 'penalty': 'l1'} 2013-06-30  0.284679   \n",
       "12                       {'C': 0.001, 'penalty': 'l2'} 2013-06-30  0.284679   \n",
       "13                         {'C': 0.1, 'penalty': 'l1'} 2013-06-30  0.284679   \n",
       "14                         {'C': 0.1, 'penalty': 'l2'} 2013-06-30  0.284679   \n",
       "15                           {'C': 1, 'penalty': 'l1'} 2013-06-30  0.284679   \n",
       "16                           {'C': 1, 'penalty': 'l2'} 2013-06-30  0.284679   \n",
       "17                          {'C': 10, 'penalty': 'l1'} 2013-06-30  0.284679   \n",
       "18                          {'C': 10, 'penalty': 'l2'} 2013-06-30  0.284679   \n",
       "19   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.284679   \n",
       "20   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.284679   \n",
       "21   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.284679   \n",
       "22   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.284679   \n",
       "23   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.284679   \n",
       "24   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.284679   \n",
       "25   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.284679   \n",
       "26   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.284679   \n",
       "27   {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2013-06-30  0.284679   \n",
       "28   {'criterion': 'gini', 'max_depth': 5, 'max_fea... 2013-06-30  0.284679   \n",
       "29   {'criterion': 'gini', 'max_depth': 5, 'max_fea... 2013-06-30  0.284679   \n",
       "..                                                 ...        ...       ...   \n",
       "309  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.256968   \n",
       "310  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.256968   \n",
       "311  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.256968   \n",
       "312  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.256968   \n",
       "313  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.256968   \n",
       "314  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.256968   \n",
       "315  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.256968   \n",
       "316  {'criterion': 'entropy', 'max_depth': 20, 'max... 2012-06-30  0.256968   \n",
       "317  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30  0.256968   \n",
       "318  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30  0.256968   \n",
       "319  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30  0.256968   \n",
       "320  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30  0.256968   \n",
       "321  {'learning_rate': 0.1, 'max_depth': 10, 'n_est... 2012-06-30  0.256968   \n",
       "322  {'learning_rate': 0.1, 'max_depth': 10, 'n_est... 2012-06-30  0.256968   \n",
       "323  {'learning_rate': 0.1, 'max_depth': 10, 'n_est... 2012-06-30  0.256968   \n",
       "324  {'learning_rate': 0.1, 'max_depth': 10, 'n_est... 2012-06-30  0.256968   \n",
       "325  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30  0.256968   \n",
       "326  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30  0.256968   \n",
       "327  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30  0.256968   \n",
       "328  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30  0.256968   \n",
       "329  {'learning_rate': 0.5, 'max_depth': 10, 'n_est... 2012-06-30  0.256968   \n",
       "330  {'learning_rate': 0.5, 'max_depth': 10, 'n_est... 2012-06-30  0.256968   \n",
       "331  {'learning_rate': 0.5, 'max_depth': 10, 'n_est... 2012-06-30  0.256968   \n",
       "332  {'learning_rate': 0.5, 'max_depth': 10, 'n_est... 2012-06-30  0.256968   \n",
       "333                                      {'C': 0.0001} 2012-06-30  0.256968   \n",
       "334                                        {'C': 0.01} 2012-06-30  0.256968   \n",
       "335                                         {'C': 0.1} 2012-06-30  0.256968   \n",
       "336                                           {'C': 1} 2012-06-30  0.256968   \n",
       "337                                          {'C': 10} 2012-06-30  0.256968   \n",
       "338  {'algorithm': 'auto', 'n_neighbors': 5, 'weigh... 2012-06-30  0.256968   \n",
       "\n",
       "       p_at_1    p_at_2    p_at_5   p_at_10   p_at_20  ...  recall_at_30  \\\n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.175493   \n",
       "1    0.405896  0.334088  0.251359  0.354539  0.420034  ...      0.402592   \n",
       "2    0.002268  0.001133  0.000453  0.000226  0.017997  ...      0.345102   \n",
       "3    0.102041  0.370328  0.409873  0.356350  0.390832  ...      0.364822   \n",
       "4    0.346939  0.378256  0.348732  0.405932  0.325297  ...      0.419052   \n",
       "5    0.469388  0.463194  0.468750  0.458003  0.446067  ...      0.446326   \n",
       "6    0.263039  0.142695  0.380888  0.312656  0.308093  ...      0.416269   \n",
       "7    0.458050  0.474519  0.466486  0.457777  0.444709  ...      0.445929   \n",
       "8    0.002268  0.001133  0.029891  0.326013  0.354726  ...      0.378101   \n",
       "9    0.387755  0.394111  0.384511  0.372425  0.372269  ...      0.397583   \n",
       "10   0.385488  0.383918  0.374094  0.366312  0.380872  ...      0.404501   \n",
       "11   0.002268  0.001133  0.000453  0.321938  0.387210  ...      0.411021   \n",
       "12   0.460317  0.464326  0.485960  0.470908  0.437125  ...      0.440283   \n",
       "13   0.537415  0.500566  0.485507  0.475662  0.445840  ...      0.448950   \n",
       "14   0.546485  0.500566  0.487772  0.474757  0.444935  ...      0.447360   \n",
       "15   0.548753  0.502831  0.488678  0.474530  0.446406  ...      0.447281   \n",
       "16   0.548753  0.494904  0.487772  0.475209  0.446067  ...      0.447281   \n",
       "17   0.548753  0.496036  0.488225  0.475209  0.445614  ...      0.448076   \n",
       "18   0.544218  0.497169  0.488225  0.475209  0.445501  ...      0.447996   \n",
       "19   0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.175493   \n",
       "20   0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.175493   \n",
       "21   0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.175493   \n",
       "22   0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.175493   \n",
       "23   0.002268  0.001133  0.000453  0.000226  0.017997  ...      0.345102   \n",
       "24   0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.175493   \n",
       "25   0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.175493   \n",
       "26   0.000000  0.000000  0.000000  0.312429  0.168761  ...      0.294211   \n",
       "27   0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.175493   \n",
       "28   0.002268  0.001133  0.000453  0.000226  0.415280  ...      0.341205   \n",
       "29   0.002268  0.001133  0.000453  0.000226  0.415280  ...      0.341205   \n",
       "..        ...       ...       ...       ...       ...  ...           ...   \n",
       "309  0.003049  0.001522  0.301278  0.311016  0.315581  ...      0.376554   \n",
       "310  0.003049  0.229833  0.307365  0.340231  0.328211  ...      0.385435   \n",
       "311  0.003049  0.001522  0.324407  0.332015  0.329276  ...      0.393843   \n",
       "312  0.003049  0.001522  0.300670  0.325015  0.334753  ...      0.392066   \n",
       "313  0.003049  0.319635  0.303104  0.342970  0.343427  ...      0.391356   \n",
       "314  0.003049  0.001522  0.298844  0.328363  0.329124  ...      0.385435   \n",
       "315  0.003049  0.121766  0.311625  0.338710  0.318929  ...      0.397395   \n",
       "316  0.006098  0.315068  0.328667  0.357882  0.340231  ...      0.388040   \n",
       "317  0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.194435   \n",
       "318  0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.194435   \n",
       "319  0.003049  0.001522  0.000609  0.266281  0.291083  ...      0.428182   \n",
       "320  0.003049  0.001522  0.139988  0.346622  0.326841  ...      0.434695   \n",
       "321  0.003049  0.057839  0.254413  0.291844  0.266129  ...      0.307993   \n",
       "322  0.301829  0.304414  0.371272  0.355447  0.342666  ...      0.378804   \n",
       "323  0.411585  0.385084  0.382836  0.374011  0.361229  ...      0.406394   \n",
       "324  0.371951  0.362253  0.379793  0.371272  0.370055  ...      0.429959   \n",
       "325  0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.194435   \n",
       "326  0.000000  0.000000  0.000000  0.000000  0.000000  ...      0.194435   \n",
       "327  0.405488  0.398782  0.412660  0.411747  0.391814  ...      0.435524   \n",
       "328  0.417683  0.418569  0.396835  0.391966  0.382836  ...      0.425933   \n",
       "329  0.003049  0.092846  0.291540  0.317103  0.312082  ...      0.396921   \n",
       "330  0.307927  0.308980  0.378576  0.356056  0.341753  ...      0.379159   \n",
       "331  0.003049  0.001522  0.248935  0.269933  0.292757  ...      0.349674   \n",
       "332  0.301829  0.319635  0.339014  0.344492  0.346013  ...      0.403434   \n",
       "333  0.423780  0.421613  0.423007  0.408704  0.389531  ...      0.436945   \n",
       "334  0.454268  0.465753  0.447352  0.426659  0.403682  ...      0.447010   \n",
       "335  0.460366  0.467275  0.442483  0.427572  0.405052  ...      0.447602   \n",
       "336  0.460366  0.464231  0.435788  0.426354  0.404443  ...      0.447247   \n",
       "337  0.460366  0.461187  0.435180  0.424528  0.403987  ...      0.446655   \n",
       "338  0.295732  0.147641  0.328058  0.222155  0.315733  ...      0.274482   \n",
       "\n",
       "     recall_at_50   f1_at_5  f1_at_20  f1_at_50   auc-roc  \\\n",
       "0        0.850191  0.000000  0.000000  0.616894  0.525412   \n",
       "1        0.713263  0.075081  0.346644  0.517540  0.656664   \n",
       "2        0.920086  0.000135  0.014852  0.667609  0.605316   \n",
       "3        0.633747  0.122430  0.322544  0.459843  0.623349   \n",
       "4        0.658158  0.104167  0.268460  0.477556  0.640715   \n",
       "5        0.680423  0.140016  0.368129  0.493711  0.669816   \n",
       "6        0.672789  0.113772  0.254262  0.488172  0.647179   \n",
       "7        0.680821  0.139340  0.367008  0.494000  0.669000   \n",
       "8        0.620309  0.008929  0.292747  0.450092  0.576196   \n",
       "9        0.625636  0.114854  0.307225  0.453958  0.608762   \n",
       "10       0.632475  0.111742  0.314324  0.458920  0.615456   \n",
       "11       0.723998  0.000135  0.319555  0.525329  0.648040   \n",
       "12       0.681139  0.145157  0.360749  0.494230  0.668947   \n",
       "13       0.681377  0.145022  0.367942  0.494403  0.671322   \n",
       "14       0.681616  0.145698  0.367194  0.494577  0.671049   \n",
       "15       0.681298  0.145969  0.368409  0.494346  0.670827   \n",
       "16       0.681139  0.145698  0.368129  0.494230  0.670778   \n",
       "17       0.681377  0.145833  0.367755  0.494403  0.670748   \n",
       "18       0.681457  0.145833  0.367661  0.494461  0.670740   \n",
       "19       0.849714  0.000000  0.000000  0.616547  0.610885   \n",
       "20       0.849714  0.000000  0.000000  0.616547  0.610885   \n",
       "21       0.849714  0.000000  0.000000  0.616547  0.610885   \n",
       "22       0.585957  0.000000  0.000000  0.425167  0.537678   \n",
       "23       0.920086  0.000135  0.014852  0.667609  0.605316   \n",
       "24       0.757793  0.000000  0.000000  0.549850  0.541365   \n",
       "25       0.585957  0.000000  0.000000  0.425167  0.537678   \n",
       "26       0.996740  0.000000  0.139274  0.723229  0.499604   \n",
       "27       0.849714  0.000000  0.000000  0.616547  0.610885   \n",
       "28       0.722726  0.000135  0.342721  0.524406  0.656886   \n",
       "29       0.722726  0.000135  0.342721  0.524406  0.656886   \n",
       "..            ...       ...       ...       ...       ...   \n",
       "309      0.633629  0.098136  0.276220  0.430197  0.595292   \n",
       "310      0.633393  0.100119  0.287274  0.430036  0.602131   \n",
       "311      0.620367  0.105670  0.288207  0.421192  0.588519   \n",
       "312      0.629130  0.097938  0.293001  0.427142  0.598789   \n",
       "313      0.629722  0.098731  0.300593  0.427544  0.603838   \n",
       "314      0.629840  0.097343  0.288074  0.427624  0.595058   \n",
       "315      0.623683  0.101507  0.279150  0.423443  0.598635   \n",
       "316      0.618472  0.107058  0.297796  0.419906  0.599284   \n",
       "317      0.814802  0.000000  0.000000  0.553202  0.602229   \n",
       "318      0.814802  0.000000  0.000000  0.553202  0.602229   \n",
       "319      0.737715  0.000198  0.254778  0.500864  0.643475   \n",
       "320      0.700178  0.045599  0.286076  0.475379  0.644931   \n",
       "321      0.650089  0.082871  0.232936  0.441372  0.587582   \n",
       "322      0.680521  0.120936  0.299927  0.462033  0.629531   \n",
       "323      0.639668  0.124703  0.316175  0.434297  0.625787   \n",
       "324      0.663233  0.123711  0.323900  0.450295  0.642184   \n",
       "325      0.814802  0.000000  0.000000  0.553202  0.602229   \n",
       "326      0.814802  0.000000  0.000000  0.553202  0.602229   \n",
       "327      0.671522  0.134417  0.342945  0.455923  0.648971   \n",
       "328      0.678982  0.129262  0.335087  0.460988  0.650671   \n",
       "329      0.656246  0.094964  0.273157  0.445552  0.605305   \n",
       "330      0.680403  0.123315  0.299128  0.461953  0.629578   \n",
       "331      0.574896  0.081086  0.256243  0.390320  0.551586   \n",
       "332      0.629959  0.110428  0.302857  0.427704  0.609748   \n",
       "333      0.665601  0.137787  0.340947  0.451903  0.650574   \n",
       "334      0.675429  0.145718  0.353333  0.458576  0.658982   \n",
       "335      0.674837  0.144132  0.354532  0.458174  0.658578   \n",
       "336      0.674719  0.141951  0.353999  0.458094  0.658494   \n",
       "337      0.675784  0.141753  0.353599  0.458817  0.658245   \n",
       "338      0.593250  0.106860  0.276353  0.402782  0.573257   \n",
       "\n",
       "     target_threshold_top_5_percent  precision_at_target  recall_at_target  \\\n",
       "0                          0.296765             0.000000          0.000000   \n",
       "1                          0.330082             0.006897          0.000080   \n",
       "2                          0.408109             0.005556          0.000080   \n",
       "3                          0.315469             0.007194          0.000080   \n",
       "4                          0.472475             0.298077          0.004930   \n",
       "5                          0.440785             0.427835          0.006600   \n",
       "6                          0.482684             0.333333          0.005646   \n",
       "7                          0.440325             0.432990          0.006679   \n",
       "8                          1.000000             0.002268          0.000080   \n",
       "9                          0.746235             0.389058          0.010178   \n",
       "10                         0.715011             0.393651          0.009860   \n",
       "11                         0.386623             0.005882          0.000080   \n",
       "12                         0.449516             0.469697          0.007395   \n",
       "13                         0.490285             0.587963          0.010099   \n",
       "14                         0.494008             0.596330          0.010337   \n",
       "15                         0.495695             0.582569          0.010099   \n",
       "16                         0.496058             0.575342          0.010019   \n",
       "17                         0.496275             0.575342          0.010019   \n",
       "18                         0.496349             0.575342          0.010019   \n",
       "19                         0.353079             0.000000          0.000000   \n",
       "20                         0.353079             0.000000          0.000000   \n",
       "21                         0.353079             0.000000          0.000000   \n",
       "22                         0.316439             0.000000          0.000000   \n",
       "23                         0.405735             0.005587          0.000080   \n",
       "24                         0.306292             0.000000          0.000000   \n",
       "25                         0.316439             0.000000          0.000000   \n",
       "26                         0.290219             0.000000          0.000000   \n",
       "27                         0.353079             0.000000          0.000000   \n",
       "28                         0.439640             0.005155          0.000080   \n",
       "29                         0.439640             0.005155          0.000080   \n",
       "..                              ...                  ...               ...   \n",
       "309                        1.000000             0.003049          0.000118   \n",
       "310                        0.750000             0.004065          0.000118   \n",
       "311                        1.000000             0.003049          0.000118   \n",
       "312                        0.750000             0.004065          0.000118   \n",
       "313                        0.666667             0.004566          0.000118   \n",
       "314                        1.000000             0.003049          0.000118   \n",
       "315                        0.750000             0.004065          0.000118   \n",
       "316                        0.666667             0.004566          0.000118   \n",
       "317                        0.316643             0.000000          0.000000   \n",
       "318                        0.316910             0.000000          0.000000   \n",
       "319                        0.403562             0.007576          0.000118   \n",
       "320                        0.399043             0.007634          0.000118   \n",
       "321                        0.356398             0.008547          0.000118   \n",
       "322                        0.332687             0.036697          0.000474   \n",
       "323                        0.552124             0.447514          0.009591   \n",
       "324                        0.490721             0.335404          0.006394   \n",
       "325                        0.333055             0.000000          0.000000   \n",
       "326                        0.341629             0.000000          0.000000   \n",
       "327                        0.484087             0.465409          0.008763   \n",
       "328                        0.466488             0.346405          0.006276   \n",
       "329                        0.656023             0.004651          0.000118   \n",
       "330                        0.426469             0.307143          0.005092   \n",
       "331                        1.000000             0.003049          0.000118   \n",
       "332                        0.719816             0.305085          0.008526   \n",
       "333                       -0.141265             0.000000          0.000000   \n",
       "334                       -0.016446             0.000000          0.000000   \n",
       "335                       -0.007312             0.000000          0.000000   \n",
       "336                       -0.006635             0.000000          0.000000   \n",
       "337                       -0.001708             0.000000          0.000000   \n",
       "338                        0.800000             0.370229          0.011486   \n",
       "\n",
       "     f1_at_target  \n",
       "0        0.000000  \n",
       "1        0.000157  \n",
       "2        0.000157  \n",
       "3        0.000157  \n",
       "4        0.009700  \n",
       "5        0.012999  \n",
       "6        0.011103  \n",
       "7        0.013156  \n",
       "8        0.000154  \n",
       "9        0.019837  \n",
       "10       0.019238  \n",
       "11       0.000157  \n",
       "12       0.014561  \n",
       "13       0.019856  \n",
       "14       0.020322  \n",
       "15       0.019853  \n",
       "16       0.019695  \n",
       "17       0.019695  \n",
       "18       0.019695  \n",
       "19       0.000000  \n",
       "20       0.000000  \n",
       "21       0.000000  \n",
       "22       0.000000  \n",
       "23       0.000157  \n",
       "24       0.000000  \n",
       "25       0.000000  \n",
       "26       0.000000  \n",
       "27       0.000000  \n",
       "28       0.000157  \n",
       "29       0.000157  \n",
       "..            ...  \n",
       "309      0.000228  \n",
       "310      0.000230  \n",
       "311      0.000228  \n",
       "312      0.000230  \n",
       "313      0.000231  \n",
       "314      0.000228  \n",
       "315      0.000230  \n",
       "316      0.000231  \n",
       "317      0.000000  \n",
       "318      0.000000  \n",
       "319      0.000233  \n",
       "320      0.000233  \n",
       "321      0.000234  \n",
       "322      0.000935  \n",
       "323      0.018780  \n",
       "324      0.012549  \n",
       "325      0.000000  \n",
       "326      0.000000  \n",
       "327      0.017201  \n",
       "328      0.012328  \n",
       "329      0.000231  \n",
       "330      0.010017  \n",
       "331      0.000228  \n",
       "332      0.016588  \n",
       "333      0.000000  \n",
       "334      0.000000  \n",
       "335      0.000000  \n",
       "336      0.000000  \n",
       "337      0.000000  \n",
       "338      0.022281  \n",
       "\n",
       "[339 rows x 27 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = build_models.clf_loop_cross_validation(models_to_run, clfs, grid, clean_df, predictors, outcome,\n",
    "                                                    date_col, prediction_windows, start_time, end_time)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('ml_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models\n",
    "Detailed analysis - please see the write-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.pivot_table(results_df,\n",
    "                         index=['model_type', 'split_date'],\n",
    "                         aggfunc='mean',\n",
    "                         fill_value=0)\n",
    "f1_list = ['f1_at_5', 'f1_at_20', 'f1_at_50']\n",
    "p_list = ['p_at_1', 'p_at_2', 'p_at_5', \n",
    "          'p_at_10', 'p_at_20', 'p_at_30', 'p_at_50']\n",
    "recall_list = ['recall_at_1', 'recall_at_2', 'recall_at_5', \n",
    "               'recall_at_10', 'recall_at_20', 'recall_at_30', 'recall_at_50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>baseline</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>f1_at_target</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>...</th>\n",
       "      <th>precision_at_target</th>\n",
       "      <th>recall_at_1</th>\n",
       "      <th>recall_at_10</th>\n",
       "      <th>recall_at_2</th>\n",
       "      <th>recall_at_20</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_5</th>\n",
       "      <th>recall_at_50</th>\n",
       "      <th>recall_at_target</th>\n",
       "      <th>target_threshold_top_5_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">B</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.577026</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.281326</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>0.403184</td>\n",
       "      <td>0.013016</td>\n",
       "      <td>0.231707</td>\n",
       "      <td>0.269122</td>\n",
       "      <td>0.238458</td>\n",
       "      <td>0.321414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216352</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.104717</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>0.250128</td>\n",
       "      <td>0.375252</td>\n",
       "      <td>0.045194</td>\n",
       "      <td>0.593843</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>0.867416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.582248</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.302808</td>\n",
       "      <td>0.075964</td>\n",
       "      <td>0.458896</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.400461</td>\n",
       "      <td>0.298771</td>\n",
       "      <td>0.389708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283822</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.127214</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>0.247597</td>\n",
       "      <td>0.379642</td>\n",
       "      <td>0.044015</td>\n",
       "      <td>0.593959</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.806710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.600138</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.304765</td>\n",
       "      <td>0.078508</td>\n",
       "      <td>0.454323</td>\n",
       "      <td>0.013076</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.354917</td>\n",
       "      <td>0.259721</td>\n",
       "      <td>0.369289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261659</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.124655</td>\n",
       "      <td>0.018236</td>\n",
       "      <td>0.259436</td>\n",
       "      <td>0.393395</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>0.626140</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.820416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DT</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.596734</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.071364</td>\n",
       "      <td>0.485080</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.117039</td>\n",
       "      <td>0.219995</td>\n",
       "      <td>0.159289</td>\n",
       "      <td>0.247671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105417</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.085601</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.192741</td>\n",
       "      <td>0.351643</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>0.714466</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.524383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.608715</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.237574</td>\n",
       "      <td>0.073192</td>\n",
       "      <td>0.543361</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.157578</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>0.205165</td>\n",
       "      <td>0.305754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148078</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.084419</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>0.194257</td>\n",
       "      <td>0.351827</td>\n",
       "      <td>0.042409</td>\n",
       "      <td>0.703283</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.446675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.615972</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.230988</td>\n",
       "      <td>0.060281</td>\n",
       "      <td>0.524554</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.127646</td>\n",
       "      <td>0.235671</td>\n",
       "      <td>0.161555</td>\n",
       "      <td>0.279892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118707</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.082773</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.196632</td>\n",
       "      <td>0.354490</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0.722930</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.458351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.617392</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.073218</td>\n",
       "      <td>0.476218</td>\n",
       "      <td>0.005597</td>\n",
       "      <td>0.158346</td>\n",
       "      <td>0.256048</td>\n",
       "      <td>0.165811</td>\n",
       "      <td>0.251579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142195</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.099630</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.195782</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.043731</td>\n",
       "      <td>0.701414</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.474728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.628449</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.245837</td>\n",
       "      <td>0.079396</td>\n",
       "      <td>0.529788</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.199021</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.230559</td>\n",
       "      <td>0.316388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190652</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.201014</td>\n",
       "      <td>0.342830</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>0.685716</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.422153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.636811</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.243199</td>\n",
       "      <td>0.067159</td>\n",
       "      <td>0.516090</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>0.162698</td>\n",
       "      <td>0.281271</td>\n",
       "      <td>0.191959</td>\n",
       "      <td>0.294687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.098789</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>0.207026</td>\n",
       "      <td>0.353411</td>\n",
       "      <td>0.039475</td>\n",
       "      <td>0.711266</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.428470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.573257</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.276353</td>\n",
       "      <td>0.106860</td>\n",
       "      <td>0.402782</td>\n",
       "      <td>0.022281</td>\n",
       "      <td>0.295732</td>\n",
       "      <td>0.222155</td>\n",
       "      <td>0.147641</td>\n",
       "      <td>0.315733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370229</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.086442</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.274482</td>\n",
       "      <td>0.063825</td>\n",
       "      <td>0.593250</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.585313</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.275356</td>\n",
       "      <td>0.111420</td>\n",
       "      <td>0.583272</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.299539</td>\n",
       "      <td>0.203226</td>\n",
       "      <td>0.149770</td>\n",
       "      <td>0.354378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.225150</td>\n",
       "      <td>0.226175</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.754941</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.596646</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.272103</td>\n",
       "      <td>0.101461</td>\n",
       "      <td>0.483556</td>\n",
       "      <td>0.023668</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.251755</td>\n",
       "      <td>0.174405</td>\n",
       "      <td>0.329711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433428</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.088422</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.231632</td>\n",
       "      <td>0.292541</td>\n",
       "      <td>0.059637</td>\n",
       "      <td>0.666428</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.650081</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.307601</td>\n",
       "      <td>0.126338</td>\n",
       "      <td>0.470033</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.388338</td>\n",
       "      <td>0.369294</td>\n",
       "      <td>0.400495</td>\n",
       "      <td>0.351434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395785</td>\n",
       "      <td>0.015083</td>\n",
       "      <td>0.143694</td>\n",
       "      <td>0.031157</td>\n",
       "      <td>0.273490</td>\n",
       "      <td>0.411693</td>\n",
       "      <td>0.075459</td>\n",
       "      <td>0.692303</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.481824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.655249</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.360442</td>\n",
       "      <td>0.126390</td>\n",
       "      <td>0.525519</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.470622</td>\n",
       "      <td>0.439343</td>\n",
       "      <td>0.501152</td>\n",
       "      <td>0.463882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482451</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.139566</td>\n",
       "      <td>0.031840</td>\n",
       "      <td>0.294723</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.073232</td>\n",
       "      <td>0.680190</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.452689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.667806</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.360924</td>\n",
       "      <td>0.127418</td>\n",
       "      <td>0.498247</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.467120</td>\n",
       "      <td>0.455428</td>\n",
       "      <td>0.432191</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496059</td>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.159957</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.307242</td>\n",
       "      <td>0.442281</td>\n",
       "      <td>0.074895</td>\n",
       "      <td>0.686675</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.475601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.613962</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.286708</td>\n",
       "      <td>0.095956</td>\n",
       "      <td>0.507547</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.273247</td>\n",
       "      <td>0.304588</td>\n",
       "      <td>0.287481</td>\n",
       "      <td>0.327564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287528</td>\n",
       "      <td>0.010613</td>\n",
       "      <td>0.118517</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>0.254914</td>\n",
       "      <td>0.397336</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.747558</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.411572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.607802</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.285538</td>\n",
       "      <td>0.086439</td>\n",
       "      <td>0.534864</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.312788</td>\n",
       "      <td>0.366244</td>\n",
       "      <td>0.307604</td>\n",
       "      <td>0.367483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327259</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.116345</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.381405</td>\n",
       "      <td>0.050084</td>\n",
       "      <td>0.692285</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.373708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.629681</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.242737</td>\n",
       "      <td>0.086868</td>\n",
       "      <td>0.526916</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.293185</td>\n",
       "      <td>0.270527</td>\n",
       "      <td>0.294128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188985</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.102974</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.206634</td>\n",
       "      <td>0.376948</td>\n",
       "      <td>0.051060</td>\n",
       "      <td>0.726185</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.398337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.656975</td>\n",
       "      <td>0.256968</td>\n",
       "      <td>0.351282</td>\n",
       "      <td>0.142268</td>\n",
       "      <td>0.457113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451829</td>\n",
       "      <td>0.422763</td>\n",
       "      <td>0.456012</td>\n",
       "      <td>0.401339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.312327</td>\n",
       "      <td>0.445092</td>\n",
       "      <td>0.084973</td>\n",
       "      <td>0.673274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.034673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.659071</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.367953</td>\n",
       "      <td>0.143254</td>\n",
       "      <td>0.512673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540092</td>\n",
       "      <td>0.494747</td>\n",
       "      <td>0.572811</td>\n",
       "      <td>0.473548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017157</td>\n",
       "      <td>0.157166</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.300864</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.663563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.098675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.670553</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.366839</td>\n",
       "      <td>0.145373</td>\n",
       "      <td>0.493757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526984</td>\n",
       "      <td>0.472085</td>\n",
       "      <td>0.500340</td>\n",
       "      <td>0.444505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018480</td>\n",
       "      <td>0.165808</td>\n",
       "      <td>0.035130</td>\n",
       "      <td>0.312277</td>\n",
       "      <td>0.447201</td>\n",
       "      <td>0.085448</td>\n",
       "      <td>0.680487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.056824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        auc-roc  baseline  f1_at_20   f1_at_5  f1_at_50  \\\n",
       "model_type split_date                                                     \n",
       "B          2012-06-30  0.577026  0.256968  0.281326  0.075667  0.403184   \n",
       "           2012-12-30  0.582248  0.314735  0.302808  0.075964  0.458896   \n",
       "           2013-06-30  0.600138  0.284679  0.304765  0.078508  0.454323   \n",
       "DT         2012-06-30  0.596734  0.256968  0.216780  0.071364  0.485080   \n",
       "           2012-12-30  0.608715  0.314735  0.237574  0.073192  0.543361   \n",
       "           2013-06-30  0.615972  0.284679  0.230988  0.060281  0.524554   \n",
       "GB         2012-06-30  0.617392  0.256968  0.220200  0.073218  0.476218   \n",
       "           2012-12-30  0.628449  0.314735  0.245837  0.079396  0.529788   \n",
       "           2013-06-30  0.636811  0.284679  0.243199  0.067159  0.516090   \n",
       "KNN        2012-06-30  0.573257  0.256968  0.276353  0.106860  0.402782   \n",
       "           2012-12-30  0.585313  0.314735  0.275356  0.111420  0.583272   \n",
       "           2013-06-30  0.596646  0.284679  0.272103  0.101461  0.483556   \n",
       "LR         2012-06-30  0.650081  0.256968  0.307601  0.126338  0.470033   \n",
       "           2012-12-30  0.655249  0.314735  0.360442  0.126390  0.525519   \n",
       "           2013-06-30  0.667806  0.284679  0.360924  0.127418  0.498247   \n",
       "RF         2012-06-30  0.613962  0.256968  0.286708  0.095956  0.507547   \n",
       "           2012-12-30  0.607802  0.314735  0.285538  0.086439  0.534864   \n",
       "           2013-06-30  0.629681  0.284679  0.242737  0.086868  0.526916   \n",
       "SVM        2012-06-30  0.656975  0.256968  0.351282  0.142268  0.457113   \n",
       "           2012-12-30  0.659071  0.314735  0.367953  0.143254  0.512673   \n",
       "           2013-06-30  0.670553  0.284679  0.366839  0.145373  0.493757   \n",
       "\n",
       "                       f1_at_target    p_at_1   p_at_10    p_at_2   p_at_20  \\\n",
       "model_type split_date                                                         \n",
       "B          2012-06-30      0.013016  0.231707  0.269122  0.238458  0.321414   \n",
       "           2012-12-30      0.012503  0.285714  0.400461  0.298771  0.389708   \n",
       "           2013-06-30      0.013076  0.258503  0.354917  0.259721  0.369289   \n",
       "DT         2012-06-30      0.003769  0.117039  0.219995  0.159289  0.247671   \n",
       "           2012-12-30      0.003995  0.157578  0.265745  0.205165  0.305754   \n",
       "           2013-06-30      0.003794  0.127646  0.235671  0.161555  0.279892   \n",
       "GB         2012-06-30      0.005597  0.158346  0.256048  0.165811  0.251579   \n",
       "           2012-12-30      0.005830  0.199021  0.314286  0.230559  0.316388   \n",
       "           2013-06-30      0.005732  0.162698  0.281271  0.191959  0.294687   \n",
       "KNN        2012-06-30      0.022281  0.295732  0.222155  0.147641  0.315733   \n",
       "           2012-12-30      0.013791  0.299539  0.203226  0.149770  0.354378   \n",
       "           2013-06-30      0.023668  0.349206  0.251755  0.174405  0.329711   \n",
       "LR         2012-06-30      0.015014  0.388338  0.369294  0.400495  0.351434   \n",
       "           2012-12-30      0.014029  0.470622  0.439343  0.501152  0.463882   \n",
       "           2013-06-30      0.016729  0.467120  0.455428  0.432191  0.437337   \n",
       "RF         2012-06-30      0.009344  0.273247  0.304588  0.287481  0.327564   \n",
       "           2012-12-30      0.008094  0.312788  0.366244  0.307604  0.367483   \n",
       "           2013-06-30      0.005929  0.255952  0.293185  0.270527  0.294128   \n",
       "SVM        2012-06-30      0.000000  0.451829  0.422763  0.456012  0.401339   \n",
       "           2012-12-30      0.000000  0.540092  0.494747  0.572811  0.473548   \n",
       "           2013-06-30      0.000000  0.526984  0.472085  0.500340  0.444505   \n",
       "\n",
       "                       ...  precision_at_target  recall_at_1  recall_at_10  \\\n",
       "model_type split_date  ...                                                   \n",
       "B          2012-06-30  ...             0.216352     0.008999      0.104717   \n",
       "           2012-12-30  ...             0.283822     0.009076      0.127214   \n",
       "           2013-06-30  ...             0.261659     0.009065      0.124655   \n",
       "DT         2012-06-30  ...             0.105417     0.004546      0.085601   \n",
       "           2012-12-30  ...             0.148078     0.005006      0.084419   \n",
       "           2013-06-30  ...             0.118707     0.004476      0.082773   \n",
       "GB         2012-06-30  ...             0.142195     0.006150      0.099630   \n",
       "           2012-12-30  ...             0.190652     0.006322      0.099839   \n",
       "           2013-06-30  ...             0.162100     0.005705      0.098789   \n",
       "KNN        2012-06-30  ...             0.370229     0.011486      0.086442   \n",
       "           2012-12-30  ...             0.369231     0.009515      0.064559   \n",
       "           2013-06-30  ...             0.433428     0.012246      0.088422   \n",
       "LR         2012-06-30  ...             0.395785     0.015083      0.143694   \n",
       "           2012-12-30  ...             0.482451     0.014950      0.139566   \n",
       "           2013-06-30  ...             0.496059     0.016380      0.159957   \n",
       "RF         2012-06-30  ...             0.287528     0.010613      0.118517   \n",
       "           2012-12-30  ...             0.327259     0.009936      0.116345   \n",
       "           2013-06-30  ...             0.188985     0.008975      0.102974   \n",
       "SVM        2012-06-30  ...             0.000000     0.017549      0.164500   \n",
       "           2012-12-30  ...             0.000000     0.017157      0.157166   \n",
       "           2013-06-30  ...             0.000000     0.018480      0.165808   \n",
       "\n",
       "                       recall_at_2  recall_at_20  recall_at_30  recall_at_5  \\\n",
       "model_type split_date                                                         \n",
       "B          2012-06-30     0.018551      0.250128      0.375252     0.045194   \n",
       "           2012-12-30     0.018982      0.247597      0.379642     0.044015   \n",
       "           2013-06-30     0.018236      0.259436      0.393395     0.046146   \n",
       "DT         2012-06-30     0.012392      0.192741      0.351643     0.042624   \n",
       "           2012-12-30     0.013035      0.194257      0.351827     0.042409   \n",
       "           2013-06-30     0.011343      0.196632      0.354490     0.035432   \n",
       "GB         2012-06-30     0.012900      0.195782      0.347151     0.043731   \n",
       "           2012-12-30     0.014648      0.201014      0.342830     0.046004   \n",
       "           2013-06-30     0.013478      0.207026      0.353411     0.039475   \n",
       "KNN        2012-06-30     0.011486      0.245708      0.274482     0.063825   \n",
       "           2012-12-30     0.009515      0.225150      0.226175     0.064559   \n",
       "           2013-06-30     0.012246      0.231632      0.292541     0.059637   \n",
       "LR         2012-06-30     0.031157      0.273490      0.411693     0.075459   \n",
       "           2012-12-30     0.031840      0.294723      0.424242     0.073232   \n",
       "           2013-06-30     0.030345      0.307242      0.442281     0.074895   \n",
       "RF         2012-06-30     0.022365      0.254914      0.397336     0.057312   \n",
       "           2012-12-30     0.019543      0.233476      0.381405     0.050084   \n",
       "           2013-06-30     0.018995      0.206634      0.376948     0.051060   \n",
       "SVM        2012-06-30     0.035477      0.312327      0.445092     0.084973   \n",
       "           2012-12-30     0.036393      0.300864      0.430771     0.083004   \n",
       "           2013-06-30     0.035130      0.312277      0.447201     0.085448   \n",
       "\n",
       "                       recall_at_50  recall_at_target  \\\n",
       "model_type split_date                                   \n",
       "B          2012-06-30      0.593843          0.006710   \n",
       "           2012-12-30      0.593959          0.006392   \n",
       "           2013-06-30      0.626140          0.006706   \n",
       "DT         2012-06-30      0.714466          0.001919   \n",
       "           2012-12-30      0.703283          0.002025   \n",
       "           2013-06-30      0.722930          0.001928   \n",
       "GB         2012-06-30      0.701414          0.002857   \n",
       "           2012-12-30      0.685716          0.002964   \n",
       "           2013-06-30      0.711266          0.002922   \n",
       "KNN        2012-06-30      0.593250          0.011486   \n",
       "           2012-12-30      0.754941          0.007027   \n",
       "           2013-06-30      0.666428          0.012166   \n",
       "LR         2012-06-30      0.692303          0.007652   \n",
       "           2012-12-30      0.680190          0.007118   \n",
       "           2013-06-30      0.686675          0.008508   \n",
       "RF         2012-06-30      0.747558          0.004751   \n",
       "           2012-12-30      0.692285          0.004099   \n",
       "           2013-06-30      0.726185          0.003012   \n",
       "SVM        2012-06-30      0.673274          0.000000   \n",
       "           2012-12-30      0.663563          0.000000   \n",
       "           2013-06-30      0.680487          0.000000   \n",
       "\n",
       "                       target_threshold_top_5_percent  \n",
       "model_type split_date                                  \n",
       "B          2012-06-30                        0.867416  \n",
       "           2012-12-30                        0.806710  \n",
       "           2013-06-30                        0.820416  \n",
       "DT         2012-06-30                        0.524383  \n",
       "           2012-12-30                        0.446675  \n",
       "           2013-06-30                        0.458351  \n",
       "GB         2012-06-30                        0.474728  \n",
       "           2012-12-30                        0.422153  \n",
       "           2013-06-30                        0.428470  \n",
       "KNN        2012-06-30                        0.800000  \n",
       "           2012-12-30                        0.600000  \n",
       "           2013-06-30                        0.800000  \n",
       "LR         2012-06-30                        0.481824  \n",
       "           2012-12-30                        0.452689  \n",
       "           2013-06-30                        0.475601  \n",
       "RF         2012-06-30                        0.411572  \n",
       "           2012-12-30                        0.373708  \n",
       "           2013-06-30                        0.398337  \n",
       "SVM        2012-06-30                       -0.034673  \n",
       "           2012-12-30                       -0.098675  \n",
       "           2013-06-30                       -0.056824  \n",
       "\n",
       "[21 rows x 23 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>f1_at_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.106860</td>\n",
       "      <td>0.276353</td>\n",
       "      <td>0.402782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">B</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.075667</td>\n",
       "      <td>0.281326</td>\n",
       "      <td>0.403184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.078508</td>\n",
       "      <td>0.304765</td>\n",
       "      <td>0.454323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.142268</td>\n",
       "      <td>0.351282</td>\n",
       "      <td>0.457113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.075964</td>\n",
       "      <td>0.302808</td>\n",
       "      <td>0.458896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.126338</td>\n",
       "      <td>0.307601</td>\n",
       "      <td>0.470033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.073218</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.476218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.101461</td>\n",
       "      <td>0.272103</td>\n",
       "      <td>0.483556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.071364</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.485080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.145373</td>\n",
       "      <td>0.366839</td>\n",
       "      <td>0.493757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.127418</td>\n",
       "      <td>0.360924</td>\n",
       "      <td>0.498247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.095956</td>\n",
       "      <td>0.286708</td>\n",
       "      <td>0.507547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.143254</td>\n",
       "      <td>0.367953</td>\n",
       "      <td>0.512673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.067159</td>\n",
       "      <td>0.243199</td>\n",
       "      <td>0.516090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.060281</td>\n",
       "      <td>0.230988</td>\n",
       "      <td>0.524554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.126390</td>\n",
       "      <td>0.360442</td>\n",
       "      <td>0.525519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.086868</td>\n",
       "      <td>0.242737</td>\n",
       "      <td>0.526916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.079396</td>\n",
       "      <td>0.245837</td>\n",
       "      <td>0.529788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.086439</td>\n",
       "      <td>0.285538</td>\n",
       "      <td>0.534864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.073192</td>\n",
       "      <td>0.237574</td>\n",
       "      <td>0.543361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.111420</td>\n",
       "      <td>0.275356</td>\n",
       "      <td>0.583272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        f1_at_5  f1_at_20  f1_at_50\n",
       "model_type split_date                              \n",
       "KNN        2012-06-30  0.106860  0.276353  0.402782\n",
       "B          2012-06-30  0.075667  0.281326  0.403184\n",
       "           2013-06-30  0.078508  0.304765  0.454323\n",
       "SVM        2012-06-30  0.142268  0.351282  0.457113\n",
       "B          2012-12-30  0.075964  0.302808  0.458896\n",
       "LR         2012-06-30  0.126338  0.307601  0.470033\n",
       "GB         2012-06-30  0.073218  0.220200  0.476218\n",
       "KNN        2013-06-30  0.101461  0.272103  0.483556\n",
       "DT         2012-06-30  0.071364  0.216780  0.485080\n",
       "SVM        2013-06-30  0.145373  0.366839  0.493757\n",
       "LR         2013-06-30  0.127418  0.360924  0.498247\n",
       "RF         2012-06-30  0.095956  0.286708  0.507547\n",
       "SVM        2012-12-30  0.143254  0.367953  0.512673\n",
       "GB         2013-06-30  0.067159  0.243199  0.516090\n",
       "DT         2013-06-30  0.060281  0.230988  0.524554\n",
       "LR         2012-12-30  0.126390  0.360442  0.525519\n",
       "RF         2013-06-30  0.086868  0.242737  0.526916\n",
       "GB         2012-12-30  0.079396  0.245837  0.529788\n",
       "RF         2012-12-30  0.086439  0.285538  0.534864\n",
       "DT         2012-12-30  0.073192  0.237574  0.543361\n",
       "KNN        2012-12-30  0.111420  0.275356  0.583272"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[f1_list].sort_values(by='f1_at_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">B</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.231707</td>\n",
       "      <td>0.238458</td>\n",
       "      <td>0.232299</td>\n",
       "      <td>0.269122</td>\n",
       "      <td>0.321414</td>\n",
       "      <td>0.321432</td>\n",
       "      <td>0.305197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.298771</td>\n",
       "      <td>0.277112</td>\n",
       "      <td>0.400461</td>\n",
       "      <td>0.389708</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.373879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.259721</td>\n",
       "      <td>0.262832</td>\n",
       "      <td>0.354917</td>\n",
       "      <td>0.369289</td>\n",
       "      <td>0.373327</td>\n",
       "      <td>0.356498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DT</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.117039</td>\n",
       "      <td>0.159289</td>\n",
       "      <td>0.219086</td>\n",
       "      <td>0.219995</td>\n",
       "      <td>0.247671</td>\n",
       "      <td>0.301210</td>\n",
       "      <td>0.367190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.157578</td>\n",
       "      <td>0.205165</td>\n",
       "      <td>0.266999</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>0.305754</td>\n",
       "      <td>0.369119</td>\n",
       "      <td>0.442695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.127646</td>\n",
       "      <td>0.161555</td>\n",
       "      <td>0.201810</td>\n",
       "      <td>0.235671</td>\n",
       "      <td>0.279892</td>\n",
       "      <td>0.336407</td>\n",
       "      <td>0.411607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.158346</td>\n",
       "      <td>0.165811</td>\n",
       "      <td>0.224779</td>\n",
       "      <td>0.256048</td>\n",
       "      <td>0.251579</td>\n",
       "      <td>0.297362</td>\n",
       "      <td>0.360482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.199021</td>\n",
       "      <td>0.230559</td>\n",
       "      <td>0.289631</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.316388</td>\n",
       "      <td>0.359680</td>\n",
       "      <td>0.431637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.162698</td>\n",
       "      <td>0.191959</td>\n",
       "      <td>0.224836</td>\n",
       "      <td>0.281271</td>\n",
       "      <td>0.294687</td>\n",
       "      <td>0.335383</td>\n",
       "      <td>0.404965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.295732</td>\n",
       "      <td>0.147641</td>\n",
       "      <td>0.328058</td>\n",
       "      <td>0.222155</td>\n",
       "      <td>0.315733</td>\n",
       "      <td>0.235115</td>\n",
       "      <td>0.304893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.299539</td>\n",
       "      <td>0.149770</td>\n",
       "      <td>0.406452</td>\n",
       "      <td>0.203226</td>\n",
       "      <td>0.354378</td>\n",
       "      <td>0.237291</td>\n",
       "      <td>0.475212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.174405</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.251755</td>\n",
       "      <td>0.329711</td>\n",
       "      <td>0.277618</td>\n",
       "      <td>0.379437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.388338</td>\n",
       "      <td>0.400495</td>\n",
       "      <td>0.387858</td>\n",
       "      <td>0.369294</td>\n",
       "      <td>0.351434</td>\n",
       "      <td>0.352647</td>\n",
       "      <td>0.355800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.470622</td>\n",
       "      <td>0.501152</td>\n",
       "      <td>0.461060</td>\n",
       "      <td>0.439343</td>\n",
       "      <td>0.463882</td>\n",
       "      <td>0.445093</td>\n",
       "      <td>0.428158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.467120</td>\n",
       "      <td>0.432191</td>\n",
       "      <td>0.426574</td>\n",
       "      <td>0.455428</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>0.419720</td>\n",
       "      <td>0.390965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.273247</td>\n",
       "      <td>0.287481</td>\n",
       "      <td>0.294583</td>\n",
       "      <td>0.304588</td>\n",
       "      <td>0.327564</td>\n",
       "      <td>0.340349</td>\n",
       "      <td>0.384197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.312788</td>\n",
       "      <td>0.307604</td>\n",
       "      <td>0.315323</td>\n",
       "      <td>0.366244</td>\n",
       "      <td>0.367483</td>\n",
       "      <td>0.400150</td>\n",
       "      <td>0.435772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.270527</td>\n",
       "      <td>0.290817</td>\n",
       "      <td>0.293185</td>\n",
       "      <td>0.294128</td>\n",
       "      <td>0.357720</td>\n",
       "      <td>0.413460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.451829</td>\n",
       "      <td>0.456012</td>\n",
       "      <td>0.436762</td>\n",
       "      <td>0.422763</td>\n",
       "      <td>0.401339</td>\n",
       "      <td>0.381256</td>\n",
       "      <td>0.346020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.540092</td>\n",
       "      <td>0.572811</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.494747</td>\n",
       "      <td>0.473548</td>\n",
       "      <td>0.451943</td>\n",
       "      <td>0.417693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.526984</td>\n",
       "      <td>0.500340</td>\n",
       "      <td>0.486685</td>\n",
       "      <td>0.472085</td>\n",
       "      <td>0.444505</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.387441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         p_at_1    p_at_2    p_at_5   p_at_10   p_at_20  \\\n",
       "model_type split_date                                                     \n",
       "B          2012-06-30  0.231707  0.238458  0.232299  0.269122  0.321414   \n",
       "           2012-12-30  0.285714  0.298771  0.277112  0.400461  0.389708   \n",
       "           2013-06-30  0.258503  0.259721  0.262832  0.354917  0.369289   \n",
       "DT         2012-06-30  0.117039  0.159289  0.219086  0.219995  0.247671   \n",
       "           2012-12-30  0.157578  0.205165  0.266999  0.265745  0.305754   \n",
       "           2013-06-30  0.127646  0.161555  0.201810  0.235671  0.279892   \n",
       "GB         2012-06-30  0.158346  0.165811  0.224779  0.256048  0.251579   \n",
       "           2012-12-30  0.199021  0.230559  0.289631  0.314286  0.316388   \n",
       "           2013-06-30  0.162698  0.191959  0.224836  0.281271  0.294687   \n",
       "KNN        2012-06-30  0.295732  0.147641  0.328058  0.222155  0.315733   \n",
       "           2012-12-30  0.299539  0.149770  0.406452  0.203226  0.354378   \n",
       "           2013-06-30  0.349206  0.174405  0.339674  0.251755  0.329711   \n",
       "LR         2012-06-30  0.388338  0.400495  0.387858  0.369294  0.351434   \n",
       "           2012-12-30  0.470622  0.501152  0.461060  0.439343  0.463882   \n",
       "           2013-06-30  0.467120  0.432191  0.426574  0.455428  0.437337   \n",
       "RF         2012-06-30  0.273247  0.287481  0.294583  0.304588  0.327564   \n",
       "           2012-12-30  0.312788  0.307604  0.315323  0.366244  0.367483   \n",
       "           2013-06-30  0.255952  0.270527  0.290817  0.293185  0.294128   \n",
       "SVM        2012-06-30  0.451829  0.456012  0.436762  0.422763  0.401339   \n",
       "           2012-12-30  0.540092  0.572811  0.522581  0.494747  0.473548   \n",
       "           2013-06-30  0.526984  0.500340  0.486685  0.472085  0.444505   \n",
       "\n",
       "                        p_at_30   p_at_50  \n",
       "model_type split_date                      \n",
       "B          2012-06-30  0.321432  0.305197  \n",
       "           2012-12-30  0.398300  0.373879  \n",
       "           2013-06-30  0.373327  0.356498  \n",
       "DT         2012-06-30  0.301210  0.367190  \n",
       "           2012-12-30  0.369119  0.442695  \n",
       "           2013-06-30  0.336407  0.411607  \n",
       "GB         2012-06-30  0.297362  0.360482  \n",
       "           2012-12-30  0.359680  0.431637  \n",
       "           2013-06-30  0.335383  0.404965  \n",
       "KNN        2012-06-30  0.235115  0.304893  \n",
       "           2012-12-30  0.237291  0.475212  \n",
       "           2013-06-30  0.277618  0.379437  \n",
       "LR         2012-06-30  0.352647  0.355800  \n",
       "           2012-12-30  0.445093  0.428158  \n",
       "           2013-06-30  0.419720  0.390965  \n",
       "RF         2012-06-30  0.340349  0.384197  \n",
       "           2012-12-30  0.400150  0.435772  \n",
       "           2013-06-30  0.357720  0.413460  \n",
       "SVM        2012-06-30  0.381256  0.346020  \n",
       "           2012-12-30  0.451943  0.417693  \n",
       "           2013-06-30  0.424389  0.387441  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[p_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.299539</td>\n",
       "      <td>0.149770</td>\n",
       "      <td>0.406452</td>\n",
       "      <td>0.203226</td>\n",
       "      <td>0.354378</td>\n",
       "      <td>0.237291</td>\n",
       "      <td>0.475212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.157578</td>\n",
       "      <td>0.205165</td>\n",
       "      <td>0.266999</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>0.305754</td>\n",
       "      <td>0.369119</td>\n",
       "      <td>0.442695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.312788</td>\n",
       "      <td>0.307604</td>\n",
       "      <td>0.315323</td>\n",
       "      <td>0.366244</td>\n",
       "      <td>0.367483</td>\n",
       "      <td>0.400150</td>\n",
       "      <td>0.435772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.199021</td>\n",
       "      <td>0.230559</td>\n",
       "      <td>0.289631</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.316388</td>\n",
       "      <td>0.359680</td>\n",
       "      <td>0.431637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.470622</td>\n",
       "      <td>0.501152</td>\n",
       "      <td>0.461060</td>\n",
       "      <td>0.439343</td>\n",
       "      <td>0.463882</td>\n",
       "      <td>0.445093</td>\n",
       "      <td>0.428158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.540092</td>\n",
       "      <td>0.572811</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.494747</td>\n",
       "      <td>0.473548</td>\n",
       "      <td>0.451943</td>\n",
       "      <td>0.417693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.270527</td>\n",
       "      <td>0.290817</td>\n",
       "      <td>0.293185</td>\n",
       "      <td>0.294128</td>\n",
       "      <td>0.357720</td>\n",
       "      <td>0.413460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.127646</td>\n",
       "      <td>0.161555</td>\n",
       "      <td>0.201810</td>\n",
       "      <td>0.235671</td>\n",
       "      <td>0.279892</td>\n",
       "      <td>0.336407</td>\n",
       "      <td>0.411607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.162698</td>\n",
       "      <td>0.191959</td>\n",
       "      <td>0.224836</td>\n",
       "      <td>0.281271</td>\n",
       "      <td>0.294687</td>\n",
       "      <td>0.335383</td>\n",
       "      <td>0.404965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.467120</td>\n",
       "      <td>0.432191</td>\n",
       "      <td>0.426574</td>\n",
       "      <td>0.455428</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>0.419720</td>\n",
       "      <td>0.390965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.526984</td>\n",
       "      <td>0.500340</td>\n",
       "      <td>0.486685</td>\n",
       "      <td>0.472085</td>\n",
       "      <td>0.444505</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.387441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.273247</td>\n",
       "      <td>0.287481</td>\n",
       "      <td>0.294583</td>\n",
       "      <td>0.304588</td>\n",
       "      <td>0.327564</td>\n",
       "      <td>0.340349</td>\n",
       "      <td>0.384197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.174405</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.251755</td>\n",
       "      <td>0.329711</td>\n",
       "      <td>0.277618</td>\n",
       "      <td>0.379437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.298771</td>\n",
       "      <td>0.277112</td>\n",
       "      <td>0.400461</td>\n",
       "      <td>0.389708</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.373879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.117039</td>\n",
       "      <td>0.159289</td>\n",
       "      <td>0.219086</td>\n",
       "      <td>0.219995</td>\n",
       "      <td>0.247671</td>\n",
       "      <td>0.301210</td>\n",
       "      <td>0.367190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.158346</td>\n",
       "      <td>0.165811</td>\n",
       "      <td>0.224779</td>\n",
       "      <td>0.256048</td>\n",
       "      <td>0.251579</td>\n",
       "      <td>0.297362</td>\n",
       "      <td>0.360482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.259721</td>\n",
       "      <td>0.262832</td>\n",
       "      <td>0.354917</td>\n",
       "      <td>0.369289</td>\n",
       "      <td>0.373327</td>\n",
       "      <td>0.356498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.388338</td>\n",
       "      <td>0.400495</td>\n",
       "      <td>0.387858</td>\n",
       "      <td>0.369294</td>\n",
       "      <td>0.351434</td>\n",
       "      <td>0.352647</td>\n",
       "      <td>0.355800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.451829</td>\n",
       "      <td>0.456012</td>\n",
       "      <td>0.436762</td>\n",
       "      <td>0.422763</td>\n",
       "      <td>0.401339</td>\n",
       "      <td>0.381256</td>\n",
       "      <td>0.346020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.231707</td>\n",
       "      <td>0.238458</td>\n",
       "      <td>0.232299</td>\n",
       "      <td>0.269122</td>\n",
       "      <td>0.321414</td>\n",
       "      <td>0.321432</td>\n",
       "      <td>0.305197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.295732</td>\n",
       "      <td>0.147641</td>\n",
       "      <td>0.328058</td>\n",
       "      <td>0.222155</td>\n",
       "      <td>0.315733</td>\n",
       "      <td>0.235115</td>\n",
       "      <td>0.304893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         p_at_1    p_at_2    p_at_5   p_at_10   p_at_20  \\\n",
       "model_type split_date                                                     \n",
       "KNN        2012-12-30  0.299539  0.149770  0.406452  0.203226  0.354378   \n",
       "DT         2012-12-30  0.157578  0.205165  0.266999  0.265745  0.305754   \n",
       "RF         2012-12-30  0.312788  0.307604  0.315323  0.366244  0.367483   \n",
       "GB         2012-12-30  0.199021  0.230559  0.289631  0.314286  0.316388   \n",
       "LR         2012-12-30  0.470622  0.501152  0.461060  0.439343  0.463882   \n",
       "SVM        2012-12-30  0.540092  0.572811  0.522581  0.494747  0.473548   \n",
       "RF         2013-06-30  0.255952  0.270527  0.290817  0.293185  0.294128   \n",
       "DT         2013-06-30  0.127646  0.161555  0.201810  0.235671  0.279892   \n",
       "GB         2013-06-30  0.162698  0.191959  0.224836  0.281271  0.294687   \n",
       "LR         2013-06-30  0.467120  0.432191  0.426574  0.455428  0.437337   \n",
       "SVM        2013-06-30  0.526984  0.500340  0.486685  0.472085  0.444505   \n",
       "RF         2012-06-30  0.273247  0.287481  0.294583  0.304588  0.327564   \n",
       "KNN        2013-06-30  0.349206  0.174405  0.339674  0.251755  0.329711   \n",
       "B          2012-12-30  0.285714  0.298771  0.277112  0.400461  0.389708   \n",
       "DT         2012-06-30  0.117039  0.159289  0.219086  0.219995  0.247671   \n",
       "GB         2012-06-30  0.158346  0.165811  0.224779  0.256048  0.251579   \n",
       "B          2013-06-30  0.258503  0.259721  0.262832  0.354917  0.369289   \n",
       "LR         2012-06-30  0.388338  0.400495  0.387858  0.369294  0.351434   \n",
       "SVM        2012-06-30  0.451829  0.456012  0.436762  0.422763  0.401339   \n",
       "B          2012-06-30  0.231707  0.238458  0.232299  0.269122  0.321414   \n",
       "KNN        2012-06-30  0.295732  0.147641  0.328058  0.222155  0.315733   \n",
       "\n",
       "                        p_at_30   p_at_50  \n",
       "model_type split_date                      \n",
       "KNN        2012-12-30  0.237291  0.475212  \n",
       "DT         2012-12-30  0.369119  0.442695  \n",
       "RF         2012-12-30  0.400150  0.435772  \n",
       "GB         2012-12-30  0.359680  0.431637  \n",
       "LR         2012-12-30  0.445093  0.428158  \n",
       "SVM        2012-12-30  0.451943  0.417693  \n",
       "RF         2013-06-30  0.357720  0.413460  \n",
       "DT         2013-06-30  0.336407  0.411607  \n",
       "GB         2013-06-30  0.335383  0.404965  \n",
       "LR         2013-06-30  0.419720  0.390965  \n",
       "SVM        2013-06-30  0.424389  0.387441  \n",
       "RF         2012-06-30  0.340349  0.384197  \n",
       "KNN        2013-06-30  0.277618  0.379437  \n",
       "B          2012-12-30  0.398300  0.373879  \n",
       "DT         2012-06-30  0.301210  0.367190  \n",
       "GB         2012-06-30  0.297362  0.360482  \n",
       "B          2013-06-30  0.373327  0.356498  \n",
       "LR         2012-06-30  0.352647  0.355800  \n",
       "SVM        2012-06-30  0.381256  0.346020  \n",
       "B          2012-06-30  0.321432  0.305197  \n",
       "KNN        2012-06-30  0.235115  0.304893  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[p_list].sort_values(by='p_at_50', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>recall_at_1</th>\n",
       "      <th>recall_at_2</th>\n",
       "      <th>recall_at_5</th>\n",
       "      <th>recall_at_10</th>\n",
       "      <th>recall_at_20</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">B</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>0.045194</td>\n",
       "      <td>0.104717</td>\n",
       "      <td>0.250128</td>\n",
       "      <td>0.375252</td>\n",
       "      <td>0.593843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>0.044015</td>\n",
       "      <td>0.127214</td>\n",
       "      <td>0.247597</td>\n",
       "      <td>0.379642</td>\n",
       "      <td>0.593959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.018236</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>0.124655</td>\n",
       "      <td>0.259436</td>\n",
       "      <td>0.393395</td>\n",
       "      <td>0.626140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DT</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>0.085601</td>\n",
       "      <td>0.192741</td>\n",
       "      <td>0.351643</td>\n",
       "      <td>0.714466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>0.042409</td>\n",
       "      <td>0.084419</td>\n",
       "      <td>0.194257</td>\n",
       "      <td>0.351827</td>\n",
       "      <td>0.703283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0.082773</td>\n",
       "      <td>0.196632</td>\n",
       "      <td>0.354490</td>\n",
       "      <td>0.722930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.043731</td>\n",
       "      <td>0.099630</td>\n",
       "      <td>0.195782</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.701414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.201014</td>\n",
       "      <td>0.342830</td>\n",
       "      <td>0.685716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>0.039475</td>\n",
       "      <td>0.098789</td>\n",
       "      <td>0.207026</td>\n",
       "      <td>0.353411</td>\n",
       "      <td>0.711266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.063825</td>\n",
       "      <td>0.086442</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.274482</td>\n",
       "      <td>0.593250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.225150</td>\n",
       "      <td>0.226175</td>\n",
       "      <td>0.754941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.059637</td>\n",
       "      <td>0.088422</td>\n",
       "      <td>0.231632</td>\n",
       "      <td>0.292541</td>\n",
       "      <td>0.666428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.015083</td>\n",
       "      <td>0.031157</td>\n",
       "      <td>0.075459</td>\n",
       "      <td>0.143694</td>\n",
       "      <td>0.273490</td>\n",
       "      <td>0.411693</td>\n",
       "      <td>0.692303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.031840</td>\n",
       "      <td>0.073232</td>\n",
       "      <td>0.139566</td>\n",
       "      <td>0.294723</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.680190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.074895</td>\n",
       "      <td>0.159957</td>\n",
       "      <td>0.307242</td>\n",
       "      <td>0.442281</td>\n",
       "      <td>0.686675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.010613</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.118517</td>\n",
       "      <td>0.254914</td>\n",
       "      <td>0.397336</td>\n",
       "      <td>0.747558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.050084</td>\n",
       "      <td>0.116345</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.381405</td>\n",
       "      <td>0.692285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.051060</td>\n",
       "      <td>0.102974</td>\n",
       "      <td>0.206634</td>\n",
       "      <td>0.376948</td>\n",
       "      <td>0.726185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.084973</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.312327</td>\n",
       "      <td>0.445092</td>\n",
       "      <td>0.673274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.017157</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.157166</td>\n",
       "      <td>0.300864</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>0.663563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.018480</td>\n",
       "      <td>0.035130</td>\n",
       "      <td>0.085448</td>\n",
       "      <td>0.165808</td>\n",
       "      <td>0.312277</td>\n",
       "      <td>0.447201</td>\n",
       "      <td>0.680487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       recall_at_1  recall_at_2  recall_at_5  recall_at_10  \\\n",
       "model_type split_date                                                        \n",
       "B          2012-06-30     0.008999     0.018551     0.045194      0.104717   \n",
       "           2012-12-30     0.009076     0.018982     0.044015      0.127214   \n",
       "           2013-06-30     0.009065     0.018236     0.046146      0.124655   \n",
       "DT         2012-06-30     0.004546     0.012392     0.042624      0.085601   \n",
       "           2012-12-30     0.005006     0.013035     0.042409      0.084419   \n",
       "           2013-06-30     0.004476     0.011343     0.035432      0.082773   \n",
       "GB         2012-06-30     0.006150     0.012900     0.043731      0.099630   \n",
       "           2012-12-30     0.006322     0.014648     0.046004      0.099839   \n",
       "           2013-06-30     0.005705     0.013478     0.039475      0.098789   \n",
       "KNN        2012-06-30     0.011486     0.011486     0.063825      0.086442   \n",
       "           2012-12-30     0.009515     0.009515     0.064559      0.064559   \n",
       "           2013-06-30     0.012246     0.012246     0.059637      0.088422   \n",
       "LR         2012-06-30     0.015083     0.031157     0.075459      0.143694   \n",
       "           2012-12-30     0.014950     0.031840     0.073232      0.139566   \n",
       "           2013-06-30     0.016380     0.030345     0.074895      0.159957   \n",
       "RF         2012-06-30     0.010613     0.022365     0.057312      0.118517   \n",
       "           2012-12-30     0.009936     0.019543     0.050084      0.116345   \n",
       "           2013-06-30     0.008975     0.018995     0.051060      0.102974   \n",
       "SVM        2012-06-30     0.017549     0.035477     0.084973      0.164500   \n",
       "           2012-12-30     0.017157     0.036393     0.083004      0.157166   \n",
       "           2013-06-30     0.018480     0.035130     0.085448      0.165808   \n",
       "\n",
       "                       recall_at_20  recall_at_30  recall_at_50  \n",
       "model_type split_date                                            \n",
       "B          2012-06-30      0.250128      0.375252      0.593843  \n",
       "           2012-12-30      0.247597      0.379642      0.593959  \n",
       "           2013-06-30      0.259436      0.393395      0.626140  \n",
       "DT         2012-06-30      0.192741      0.351643      0.714466  \n",
       "           2012-12-30      0.194257      0.351827      0.703283  \n",
       "           2013-06-30      0.196632      0.354490      0.722930  \n",
       "GB         2012-06-30      0.195782      0.347151      0.701414  \n",
       "           2012-12-30      0.201014      0.342830      0.685716  \n",
       "           2013-06-30      0.207026      0.353411      0.711266  \n",
       "KNN        2012-06-30      0.245708      0.274482      0.593250  \n",
       "           2012-12-30      0.225150      0.226175      0.754941  \n",
       "           2013-06-30      0.231632      0.292541      0.666428  \n",
       "LR         2012-06-30      0.273490      0.411693      0.692303  \n",
       "           2012-12-30      0.294723      0.424242      0.680190  \n",
       "           2013-06-30      0.307242      0.442281      0.686675  \n",
       "RF         2012-06-30      0.254914      0.397336      0.747558  \n",
       "           2012-12-30      0.233476      0.381405      0.692285  \n",
       "           2013-06-30      0.206634      0.376948      0.726185  \n",
       "SVM        2012-06-30      0.312327      0.445092      0.673274  \n",
       "           2012-12-30      0.300864      0.430771      0.663563  \n",
       "           2013-06-30      0.312277      0.447201      0.680487  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[recall_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>recall_at_1</th>\n",
       "      <th>recall_at_2</th>\n",
       "      <th>recall_at_5</th>\n",
       "      <th>recall_at_10</th>\n",
       "      <th>recall_at_20</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_type</th>\n",
       "      <th>split_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.064559</td>\n",
       "      <td>0.225150</td>\n",
       "      <td>0.226175</td>\n",
       "      <td>0.754941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RF</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.010613</td>\n",
       "      <td>0.022365</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.118517</td>\n",
       "      <td>0.254914</td>\n",
       "      <td>0.397336</td>\n",
       "      <td>0.747558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.051060</td>\n",
       "      <td>0.102974</td>\n",
       "      <td>0.206634</td>\n",
       "      <td>0.376948</td>\n",
       "      <td>0.726185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DT</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0.082773</td>\n",
       "      <td>0.196632</td>\n",
       "      <td>0.354490</td>\n",
       "      <td>0.722930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>0.085601</td>\n",
       "      <td>0.192741</td>\n",
       "      <td>0.351643</td>\n",
       "      <td>0.714466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>0.039475</td>\n",
       "      <td>0.098789</td>\n",
       "      <td>0.207026</td>\n",
       "      <td>0.353411</td>\n",
       "      <td>0.711266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>0.042409</td>\n",
       "      <td>0.084419</td>\n",
       "      <td>0.194257</td>\n",
       "      <td>0.351827</td>\n",
       "      <td>0.703283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.043731</td>\n",
       "      <td>0.099630</td>\n",
       "      <td>0.195782</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.701414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.015083</td>\n",
       "      <td>0.031157</td>\n",
       "      <td>0.075459</td>\n",
       "      <td>0.143694</td>\n",
       "      <td>0.273490</td>\n",
       "      <td>0.411693</td>\n",
       "      <td>0.692303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.050084</td>\n",
       "      <td>0.116345</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.381405</td>\n",
       "      <td>0.692285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.016380</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.074895</td>\n",
       "      <td>0.159957</td>\n",
       "      <td>0.307242</td>\n",
       "      <td>0.442281</td>\n",
       "      <td>0.686675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.201014</td>\n",
       "      <td>0.342830</td>\n",
       "      <td>0.685716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.018480</td>\n",
       "      <td>0.035130</td>\n",
       "      <td>0.085448</td>\n",
       "      <td>0.165808</td>\n",
       "      <td>0.312277</td>\n",
       "      <td>0.447201</td>\n",
       "      <td>0.680487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.031840</td>\n",
       "      <td>0.073232</td>\n",
       "      <td>0.139566</td>\n",
       "      <td>0.294723</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.680190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.084973</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.312327</td>\n",
       "      <td>0.445092</td>\n",
       "      <td>0.673274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.059637</td>\n",
       "      <td>0.088422</td>\n",
       "      <td>0.231632</td>\n",
       "      <td>0.292541</td>\n",
       "      <td>0.666428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.017157</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.157166</td>\n",
       "      <td>0.300864</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>0.663563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">B</th>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.018236</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>0.124655</td>\n",
       "      <td>0.259436</td>\n",
       "      <td>0.393395</td>\n",
       "      <td>0.626140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-30</th>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>0.044015</td>\n",
       "      <td>0.127214</td>\n",
       "      <td>0.247597</td>\n",
       "      <td>0.379642</td>\n",
       "      <td>0.593959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>0.045194</td>\n",
       "      <td>0.104717</td>\n",
       "      <td>0.250128</td>\n",
       "      <td>0.375252</td>\n",
       "      <td>0.593843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.063825</td>\n",
       "      <td>0.086442</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.274482</td>\n",
       "      <td>0.593250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       recall_at_1  recall_at_2  recall_at_5  recall_at_10  \\\n",
       "model_type split_date                                                        \n",
       "KNN        2012-12-30     0.009515     0.009515     0.064559      0.064559   \n",
       "RF         2012-06-30     0.010613     0.022365     0.057312      0.118517   \n",
       "           2013-06-30     0.008975     0.018995     0.051060      0.102974   \n",
       "DT         2013-06-30     0.004476     0.011343     0.035432      0.082773   \n",
       "           2012-06-30     0.004546     0.012392     0.042624      0.085601   \n",
       "GB         2013-06-30     0.005705     0.013478     0.039475      0.098789   \n",
       "DT         2012-12-30     0.005006     0.013035     0.042409      0.084419   \n",
       "GB         2012-06-30     0.006150     0.012900     0.043731      0.099630   \n",
       "LR         2012-06-30     0.015083     0.031157     0.075459      0.143694   \n",
       "RF         2012-12-30     0.009936     0.019543     0.050084      0.116345   \n",
       "LR         2013-06-30     0.016380     0.030345     0.074895      0.159957   \n",
       "GB         2012-12-30     0.006322     0.014648     0.046004      0.099839   \n",
       "SVM        2013-06-30     0.018480     0.035130     0.085448      0.165808   \n",
       "LR         2012-12-30     0.014950     0.031840     0.073232      0.139566   \n",
       "SVM        2012-06-30     0.017549     0.035477     0.084973      0.164500   \n",
       "KNN        2013-06-30     0.012246     0.012246     0.059637      0.088422   \n",
       "SVM        2012-12-30     0.017157     0.036393     0.083004      0.157166   \n",
       "B          2013-06-30     0.009065     0.018236     0.046146      0.124655   \n",
       "           2012-12-30     0.009076     0.018982     0.044015      0.127214   \n",
       "           2012-06-30     0.008999     0.018551     0.045194      0.104717   \n",
       "KNN        2012-06-30     0.011486     0.011486     0.063825      0.086442   \n",
       "\n",
       "                       recall_at_20  recall_at_30  recall_at_50  \n",
       "model_type split_date                                            \n",
       "KNN        2012-12-30      0.225150      0.226175      0.754941  \n",
       "RF         2012-06-30      0.254914      0.397336      0.747558  \n",
       "           2013-06-30      0.206634      0.376948      0.726185  \n",
       "DT         2013-06-30      0.196632      0.354490      0.722930  \n",
       "           2012-06-30      0.192741      0.351643      0.714466  \n",
       "GB         2013-06-30      0.207026      0.353411      0.711266  \n",
       "DT         2012-12-30      0.194257      0.351827      0.703283  \n",
       "GB         2012-06-30      0.195782      0.347151      0.701414  \n",
       "LR         2012-06-30      0.273490      0.411693      0.692303  \n",
       "RF         2012-12-30      0.233476      0.381405      0.692285  \n",
       "LR         2013-06-30      0.307242      0.442281      0.686675  \n",
       "GB         2012-12-30      0.201014      0.342830      0.685716  \n",
       "SVM        2013-06-30      0.312277      0.447201      0.680487  \n",
       "LR         2012-12-30      0.294723      0.424242      0.680190  \n",
       "SVM        2012-06-30      0.312327      0.445092      0.673274  \n",
       "KNN        2013-06-30      0.231632      0.292541      0.666428  \n",
       "SVM        2012-12-30      0.300864      0.430771      0.663563  \n",
       "B          2013-06-30      0.259436      0.393395      0.626140  \n",
       "           2012-12-30      0.247597      0.379642      0.593959  \n",
       "           2012-06-30      0.250128      0.375252      0.593843  \n",
       "KNN        2012-06-30      0.245708      0.274482      0.593250  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[recall_list].sort_values(by='recall_at_50', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>split_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_50</th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>target_threshold_top_5_percent</th>\n",
       "      <th>precision_at_target</th>\n",
       "      <th>recall_at_target</th>\n",
       "      <th>f1_at_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.175454</td>\n",
       "      <td>0.772606</td>\n",
       "      <td>0.592459</td>\n",
       "      <td>0.391349</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'max_...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.188940</td>\n",
       "      <td>0.315668</td>\n",
       "      <td>0.245161</td>\n",
       "      <td>0.358065</td>\n",
       "      <td>0.363825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067206</td>\n",
       "      <td>0.282696</td>\n",
       "      <td>0.772606</td>\n",
       "      <td>0.502901</td>\n",
       "      <td>0.279830</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'max_...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.149309</td>\n",
       "      <td>0.376959</td>\n",
       "      <td>0.344700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040930</td>\n",
       "      <td>0.267836</td>\n",
       "      <td>0.772606</td>\n",
       "      <td>0.502039</td>\n",
       "      <td>0.280075</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'max_...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.314735</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.175454</td>\n",
       "      <td>0.772606</td>\n",
       "      <td>0.592459</td>\n",
       "      <td>0.391349</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_type                                                clf  \\\n",
       "140         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "171         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "174         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "175         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "\n",
       "                                            parameters split_date  baseline  \\\n",
       "140  {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2012-12-30  0.314735   \n",
       "171  {'criterion': 'entropy', 'max_depth': 1, 'max_... 2012-12-30  0.314735   \n",
       "174  {'criterion': 'entropy', 'max_depth': 1, 'max_... 2012-12-30  0.314735   \n",
       "175  {'criterion': 'entropy', 'max_depth': 1, 'max_... 2012-12-30  0.314735   \n",
       "\n",
       "       p_at_1    p_at_2    p_at_5   p_at_10   p_at_20  ...  recall_at_30  \\\n",
       "140  0.004608  0.002304  0.000922  0.000461  0.225806  ...      0.405943   \n",
       "171  0.188940  0.315668  0.245161  0.358065  0.363825  ...      0.364807   \n",
       "174  0.354839  0.177419  0.149309  0.376959  0.344700  ...      0.364807   \n",
       "175  0.004608  0.002304  0.000922  0.000461  0.225806  ...      0.405943   \n",
       "\n",
       "     recall_at_50   f1_at_5  f1_at_20  f1_at_50   auc-roc  \\\n",
       "140           1.0  0.000253  0.175454  0.772606  0.592459   \n",
       "171           1.0  0.067206  0.282696  0.772606  0.502901   \n",
       "174           1.0  0.040930  0.267836  0.772606  0.502039   \n",
       "175           1.0  0.000253  0.175454  0.772606  0.592459   \n",
       "\n",
       "     target_threshold_top_5_percent  precision_at_target  recall_at_target  \\\n",
       "140                        0.391349             0.011905          0.000146   \n",
       "171                        0.279830             0.016667          0.000146   \n",
       "174                        0.280075             0.016667          0.000146   \n",
       "175                        0.391349             0.011905          0.000146   \n",
       "\n",
       "     f1_at_target  \n",
       "140      0.000289  \n",
       "171      0.000290  \n",
       "174      0.000290  \n",
       "175      0.000289  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_f1 = results_df[results_df['f1_at_50'] == results_df['f1_at_50'].max()]\n",
    "highest_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_split': 10},\n",
       "       {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_split': 2},\n",
       "       {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_split': 2},\n",
       "       {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_split': 5}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_f1['parameters'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>split_date</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_at_30</th>\n",
       "      <th>recall_at_50</th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>f1_at_50</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>target_threshold_top_5_percent</th>\n",
       "      <th>precision_at_target</th>\n",
       "      <th>recall_at_target</th>\n",
       "      <th>f1_at_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.284679</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.500566</td>\n",
       "      <td>0.485507</td>\n",
       "      <td>0.475662</td>\n",
       "      <td>0.44584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44895</td>\n",
       "      <td>0.681377</td>\n",
       "      <td>0.145022</td>\n",
       "      <td>0.367942</td>\n",
       "      <td>0.494403</td>\n",
       "      <td>0.671322</td>\n",
       "      <td>0.490285</td>\n",
       "      <td>0.587963</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.019856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type                                                clf  \\\n",
       "13         LR  LogisticRegression(C=10, class_weight=None, du...   \n",
       "\n",
       "                     parameters split_date  baseline    p_at_1    p_at_2  \\\n",
       "13  {'C': 0.1, 'penalty': 'l1'} 2013-06-30  0.284679  0.537415  0.500566   \n",
       "\n",
       "      p_at_5   p_at_10  p_at_20  ...  recall_at_30  recall_at_50   f1_at_5  \\\n",
       "13  0.485507  0.475662  0.44584  ...       0.44895      0.681377  0.145022   \n",
       "\n",
       "    f1_at_20  f1_at_50   auc-roc  target_threshold_top_5_percent  \\\n",
       "13  0.367942  0.494403  0.671322                        0.490285   \n",
       "\n",
       "    precision_at_target  recall_at_target  f1_at_target  \n",
       "13             0.587963          0.010099      0.019856  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_auc = results_df[results_df['auc-roc'] == results_df['auc-roc'].max()]\n",
    "highest_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'C': 0.1, 'penalty': 'l1'}], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_auc['parameters'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>parameters</th>\n",
       "      <th>split_date</th>\n",
       "      <th>target_threshold_top_5_percent</th>\n",
       "      <th>precision_at_target</th>\n",
       "      <th>recall_at_target</th>\n",
       "      <th>f1_at_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.392091</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.015327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.494008</td>\n",
       "      <td>0.596330</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.020322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.490285</td>\n",
       "      <td>0.587963</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.019856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.495695</td>\n",
       "      <td>0.582569</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.019853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.496058</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.019695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.496275</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.019695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.496349</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.019695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.473420</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.016443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.474712</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.016441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.475052</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.016441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.475102</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.016441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.475111</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.016441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.013592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'max_...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.392408</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.013592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.411948</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.014162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.422904</td>\n",
       "      <td>0.549451</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>0.014447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.439568</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.015016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.422938</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.014158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.454830</td>\n",
       "      <td>0.530201</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.018385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.469938</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.015291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.458385</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.014141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.310537</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>0.009278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.506618</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.018116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>0.449516</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.014561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.436224</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.012708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.425220</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.012422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.484087</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.017201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 10, 'n_est...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.448891</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.012991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.462366</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.012421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.510022</td>\n",
       "      <td>0.461078</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>0.017882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'max_...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.293029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.287103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.286933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.310073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>0.311504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.0001}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>-0.167675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>-0.084471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>-0.081944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>-0.081857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>-0.077429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>LR</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.370869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.370850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.370850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.370850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.311608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.311982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'max_...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.370850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'max_...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.370850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'max_...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.370850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'max_...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.323425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>DT</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'max_...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.314028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.316643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.316910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.333055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>0.341629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.0001}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>-0.141265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>-0.016446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>-0.007312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>-0.006635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_type                                         parameters split_date  \\\n",
       "181         DT  {'criterion': 'entropy', 'max_depth': 5, 'max_... 2012-12-30   \n",
       "14          LR                        {'C': 0.1, 'penalty': 'l2'} 2013-06-30   \n",
       "13          LR                        {'C': 0.1, 'penalty': 'l1'} 2013-06-30   \n",
       "15          LR                          {'C': 1, 'penalty': 'l1'} 2013-06-30   \n",
       "16          LR                          {'C': 1, 'penalty': 'l2'} 2013-06-30   \n",
       "17          LR                         {'C': 10, 'penalty': 'l1'} 2013-06-30   \n",
       "18          LR                         {'C': 10, 'penalty': 'l2'} 2013-06-30   \n",
       "127         LR                        {'C': 0.1, 'penalty': 'l2'} 2012-12-30   \n",
       "128         LR                          {'C': 1, 'penalty': 'l1'} 2012-12-30   \n",
       "129         LR                          {'C': 1, 'penalty': 'l2'} 2012-12-30   \n",
       "130         LR                         {'C': 10, 'penalty': 'l1'} 2012-12-30   \n",
       "131         LR                         {'C': 10, 'penalty': 'l2'} 2012-12-30   \n",
       "147         DT  {'criterion': 'gini', 'max_depth': 5, 'max_fea... 2012-12-30   \n",
       "183         DT  {'criterion': 'entropy', 'max_depth': 5, 'max_... 2012-12-30   \n",
       "120         RF  {'max_depth': 10, 'max_features': 'sqrt', 'min... 2012-12-30   \n",
       "125         LR                      {'C': 0.001, 'penalty': 'l2'} 2012-12-30   \n",
       "158         DT  {'criterion': 'gini', 'max_depth': 10, 'max_fe... 2012-12-30   \n",
       "118         RF  {'max_depth': 10, 'max_features': 'sqrt', 'min... 2012-12-30   \n",
       "233         RF  {'max_depth': 10, 'max_features': 'sqrt', 'min... 2012-06-30   \n",
       "126         LR                        {'C': 0.1, 'penalty': 'l1'} 2012-12-30   \n",
       "214         GB  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-12-30   \n",
       "116         RF  {'max_depth': 1, 'max_features': 'sqrt', 'min_... 2012-12-30   \n",
       "240         LR                        {'C': 0.1, 'penalty': 'l2'} 2012-06-30   \n",
       "12          LR                      {'C': 0.001, 'penalty': 'l2'} 2013-06-30   \n",
       "153         DT  {'criterion': 'gini', 'max_depth': 10, 'max_fe... 2012-12-30   \n",
       "155         DT  {'criterion': 'gini', 'max_depth': 10, 'max_fe... 2012-12-30   \n",
       "327         GB  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30   \n",
       "211         GB  {'learning_rate': 0.1, 'max_depth': 10, 'n_est... 2012-12-30   \n",
       "192         DT  {'criterion': 'entropy', 'max_depth': 10, 'max... 2012-12-30   \n",
       "241         LR                          {'C': 1, 'penalty': 'l1'} 2012-06-30   \n",
       "..         ...                                                ...        ...   \n",
       "176         DT  {'criterion': 'entropy', 'max_depth': 1, 'max_... 2012-12-30   \n",
       "204         GB  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-12-30   \n",
       "205         GB  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-12-30   \n",
       "212         GB  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-12-30   \n",
       "213         GB  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-12-30   \n",
       "220        SVM                                      {'C': 0.0001} 2012-12-30   \n",
       "221        SVM                                        {'C': 0.01} 2012-12-30   \n",
       "222        SVM                                         {'C': 0.1} 2012-12-30   \n",
       "223        SVM                                           {'C': 1} 2012-12-30   \n",
       "224        SVM                                          {'C': 10} 2012-12-30   \n",
       "237         LR                      {'C': 0.001, 'penalty': 'l1'} 2012-06-30   \n",
       "245         DT  {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2012-06-30   \n",
       "246         DT  {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2012-06-30   \n",
       "247         DT  {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2012-06-30   \n",
       "249         DT  {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2012-06-30   \n",
       "250         DT  {'criterion': 'gini', 'max_depth': 1, 'max_fea... 2012-06-30   \n",
       "281         DT  {'criterion': 'entropy', 'max_depth': 1, 'max_... 2012-06-30   \n",
       "282         DT  {'criterion': 'entropy', 'max_depth': 1, 'max_... 2012-06-30   \n",
       "283         DT  {'criterion': 'entropy', 'max_depth': 1, 'max_... 2012-06-30   \n",
       "284         DT  {'criterion': 'entropy', 'max_depth': 1, 'max_... 2012-06-30   \n",
       "285         DT  {'criterion': 'entropy', 'max_depth': 1, 'max_... 2012-06-30   \n",
       "317         GB  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30   \n",
       "318         GB  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti... 2012-06-30   \n",
       "325         GB  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30   \n",
       "326         GB  {'learning_rate': 0.5, 'max_depth': 1, 'n_esti... 2012-06-30   \n",
       "333        SVM                                      {'C': 0.0001} 2012-06-30   \n",
       "334        SVM                                        {'C': 0.01} 2012-06-30   \n",
       "335        SVM                                         {'C': 0.1} 2012-06-30   \n",
       "336        SVM                                           {'C': 1} 2012-06-30   \n",
       "337        SVM                                          {'C': 10} 2012-06-30   \n",
       "\n",
       "     target_threshold_top_5_percent  precision_at_target  recall_at_target  \\\n",
       "181                        0.392091             0.623529          0.007759   \n",
       "14                         0.494008             0.596330          0.010337   \n",
       "13                         0.490285             0.587963          0.010099   \n",
       "15                         0.495695             0.582569          0.010099   \n",
       "16                         0.496058             0.575342          0.010019   \n",
       "17                         0.496275             0.575342          0.010019   \n",
       "18                         0.496349             0.575342          0.010019   \n",
       "127                        0.473420             0.558824          0.008344   \n",
       "128                        0.474712             0.553398          0.008344   \n",
       "129                        0.475052             0.553398          0.008344   \n",
       "130                        0.475102             0.553398          0.008344   \n",
       "131                        0.475111             0.553398          0.008344   \n",
       "147                        0.394439             0.552941          0.006880   \n",
       "183                        0.392408             0.552941          0.006880   \n",
       "120                        0.411948             0.550562          0.007173   \n",
       "125                        0.422904             0.549451          0.007320   \n",
       "158                        0.439568             0.547368          0.007612   \n",
       "118                        0.422938             0.538462          0.007173   \n",
       "233                        0.454830             0.530201          0.009355   \n",
       "126                        0.469938             0.524752          0.007759   \n",
       "214                        0.458385             0.494949          0.007173   \n",
       "116                        0.310537             0.477612          0.004685   \n",
       "240                        0.506618             0.469880          0.009236   \n",
       "12                         0.449516             0.469697          0.007395   \n",
       "153                        0.436224             0.468085          0.006441   \n",
       "155                        0.425220             0.467391          0.006295   \n",
       "327                        0.484087             0.465409          0.008763   \n",
       "211                        0.448891             0.463918          0.006588   \n",
       "192                        0.428571             0.462366          0.006295   \n",
       "241                        0.510022             0.461078          0.009118   \n",
       "..                              ...                  ...               ...   \n",
       "176                        0.293029             0.000000          0.000000   \n",
       "204                        0.287103             0.000000          0.000000   \n",
       "205                        0.286933             0.000000          0.000000   \n",
       "212                        0.310073             0.000000          0.000000   \n",
       "213                        0.311504             0.000000          0.000000   \n",
       "220                       -0.167675             0.000000          0.000000   \n",
       "221                       -0.084471             0.000000          0.000000   \n",
       "222                       -0.081944             0.000000          0.000000   \n",
       "223                       -0.081857             0.000000          0.000000   \n",
       "224                       -0.077429             0.000000          0.000000   \n",
       "237                        0.370869             0.000000          0.000000   \n",
       "245                        0.370850             0.000000          0.000000   \n",
       "246                        0.370850             0.000000          0.000000   \n",
       "247                        0.370850             0.000000          0.000000   \n",
       "249                        0.311608             0.000000          0.000000   \n",
       "250                        0.311982             0.000000          0.000000   \n",
       "281                        0.370850             0.000000          0.000000   \n",
       "282                        0.370850             0.000000          0.000000   \n",
       "283                        0.370850             0.000000          0.000000   \n",
       "284                        0.323425             0.000000          0.000000   \n",
       "285                        0.314028             0.000000          0.000000   \n",
       "317                        0.316643             0.000000          0.000000   \n",
       "318                        0.316910             0.000000          0.000000   \n",
       "325                        0.333055             0.000000          0.000000   \n",
       "326                        0.341629             0.000000          0.000000   \n",
       "333                       -0.141265             0.000000          0.000000   \n",
       "334                       -0.016446             0.000000          0.000000   \n",
       "335                       -0.007312             0.000000          0.000000   \n",
       "336                       -0.006635             0.000000          0.000000   \n",
       "337                       -0.001708             0.000000          0.000000   \n",
       "\n",
       "     f1_at_target  \n",
       "181      0.015327  \n",
       "14       0.020322  \n",
       "13       0.019856  \n",
       "15       0.019853  \n",
       "16       0.019695  \n",
       "17       0.019695  \n",
       "18       0.019695  \n",
       "127      0.016443  \n",
       "128      0.016441  \n",
       "129      0.016441  \n",
       "130      0.016441  \n",
       "131      0.016441  \n",
       "147      0.013592  \n",
       "183      0.013592  \n",
       "120      0.014162  \n",
       "125      0.014447  \n",
       "158      0.015016  \n",
       "118      0.014158  \n",
       "233      0.018385  \n",
       "126      0.015291  \n",
       "214      0.014141  \n",
       "116      0.009278  \n",
       "240      0.018116  \n",
       "12       0.014561  \n",
       "153      0.012708  \n",
       "155      0.012422  \n",
       "327      0.017201  \n",
       "211      0.012991  \n",
       "192      0.012421  \n",
       "241      0.017882  \n",
       "..            ...  \n",
       "176      0.000000  \n",
       "204      0.000000  \n",
       "205      0.000000  \n",
       "212      0.000000  \n",
       "213      0.000000  \n",
       "220      0.000000  \n",
       "221      0.000000  \n",
       "222      0.000000  \n",
       "223      0.000000  \n",
       "224      0.000000  \n",
       "237      0.000000  \n",
       "245      0.000000  \n",
       "246      0.000000  \n",
       "247      0.000000  \n",
       "249      0.000000  \n",
       "250      0.000000  \n",
       "281      0.000000  \n",
       "282      0.000000  \n",
       "283      0.000000  \n",
       "284      0.000000  \n",
       "285      0.000000  \n",
       "317      0.000000  \n",
       "318      0.000000  \n",
       "325      0.000000  \n",
       "326      0.000000  \n",
       "333      0.000000  \n",
       "334      0.000000  \n",
       "335      0.000000  \n",
       "336      0.000000  \n",
       "337      0.000000  \n",
       "\n",
       "[339 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5 = results_df[['model_type', 'parameters', 'split_date', 'target_threshold_top_5_percent', 'precision_at_target', 'recall_at_target', 'f1_at_target']]\n",
    "top_5.sort_values(by = ['precision_at_target', 'f1_at_target'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
